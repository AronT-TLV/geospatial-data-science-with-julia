[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geospatial Data Science with Julia",
    "section": "",
    "text": "Welcome\nGeospatial Data Science with Julia presents a fresh approach to data science with geospatial data and the  programming language. It contains best practices for writing clean, readable and performant code in geoscientific applications involving sophisticated representations of the (sub)surface of the Earth such as unstructured meshes made of 2D and 3D geometries.\nBy reading this book, you will:\nMost importantly, you will learn a set of geospatial features that is much richer than the simple features implemented in traditional geographic information systems (GIS).\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License."
  },
  {
    "objectID": "index.html#how-to-contribute",
    "href": "index.html#how-to-contribute",
    "title": "Geospatial Data Science with Julia",
    "section": "How to contribute?",
    "text": "How to contribute?\nFirst off, thank you for considering contributing to this book. It’s people like you that make this project so much fun. Below are a few suggestions to facilitate the review process:\n\nPlease be polite, we are here to help and learn from each other\nTry to explain your contribution with simple language\nReferences to textbooks and papers are always welcome\nFollow the code style in the examples as much as possible\n\nThis book is open source and fully reproducible thanks to the amazing Quarto project. You can edit the pages directly on GitHub and submit a pull request for review. If you are not familiar with this process, consider reading the first contributions guide.\nAlternatively, you can render the book locally with the Quarto VS Code Extension, which is the recommended method for reviewing more elaborate changes."
  },
  {
    "objectID": "index.html#getting-involved",
    "href": "index.html#getting-involved",
    "title": "Geospatial Data Science with Julia",
    "section": "Getting involved",
    "text": "Getting involved\nIf you would like to get involved with the project, you can start by\n\nJoining our community channel: \nStarring or sponsoring our book and software on GitHub: \nSharing the book on social media (LinkedIn, Twitter, …)\nAsking questions and making suggestions\nOrganizing training courses and workshops\nCiting the work in publications:\n@book{Hoffimann2023,\n  title = {Geospatial Data Science with {{Julia}}},\n  author = {Hoffimann, Júlio},\n  year = {2023}\n}"
  },
  {
    "objectID": "foreword.html",
    "href": "foreword.html",
    "title": "Foreword",
    "section": "",
    "text": "I’ve always felt that something was off with existing approaches to geospatial data science in other programming languages. I remember sitting in the beautiful Stanford’s Green library after a short introductory course on GIS with R, and wondering why it had to be so “computer sciency”:\n\nWhat on Earth is a “LineString”? Isn’t a “Line” a geometric object with infinite length?\nWhy do I need to learn this low-level distinction between “raster” and “vector” data?\nAnd many other questions…\n\nAfter years of my PhD, I finally envisioned a more general approach, through the continuous design and development of the  framework for the  programming language. This book is the first attempt to share this vision with the broader scientific community.\nThere is a long journey until the technology reaches its full potential, but it is getting there! I hope that the book will enlighten your understanding of some of those issues and that you can benefit from the open source software we built over the years."
  },
  {
    "objectID": "preface.html#who-this-book-is-for",
    "href": "preface.html#who-this-book-is-for",
    "title": "Preface",
    "section": "Who this book is for",
    "text": "Who this book is for\nAnyone interested in geospatial data science will benefit from reading this book. If you are a student with basic-to-intermediate programming experience, you will learn a valuable set of tools for your career. If you are an experienced data scientist, you can still be surprised by the generality of the framework presented here.\nThis is not a book on geostatistics. Although some chapters and examples will cover concepts from geostatistical theory, that is only to illustrate what is possible after you master geospatial data science with the  programming language."
  },
  {
    "objectID": "preface.html#why-julia",
    "href": "preface.html#why-julia",
    "title": "Preface",
    "section": "Why Julia?",
    "text": "Why Julia?\nAn effective implementation of the framework presented in this book requires a language that can:\n\nGenerate high-performance code\nSpecialize on multiple arguments\nEvaluate code interactively\nExploit parallel hardware\n\nThis list of requirements eliminates Python, R and other mainstream languages used for data science."
  },
  {
    "objectID": "preface.html#how-to-read-this-book",
    "href": "preface.html#how-to-read-this-book",
    "title": "Preface",
    "section": "How to read this book",
    "text": "How to read this book\nIf this is your first encounter with  or with programming in general, consider reading the open source book Think Julia: How to Think Like a Computer Scientist by Lauwens and Downey (2018). It introduces the language to first-time programmers and explains basic concepts that you will need to know to master the material here.\nIf you are an experienced programmer who just wants to quickly learn the syntax of the language, consider checking the Learn Julia in Y minutes website. If you are seeking more detailed information, consider reading the official documentation.\nAssuming that you learned the basics of the language, you can proceed and read this book. It is organized in five parts as follows:\n\n\n\n\nflowchart LR\n  preread[\"Julia basics ✅\"] --&gt; partI\n  subgraph partI[\"Part I: Foundations\"]\n    chapter1[\"1. What is geospatial data?\"]\n    chapter2[\"2. Scientific visualization\"]\n    chapter3[\"3. Interfacing with GIS\"]\n    chapter4[\"4. Geometric processing\"]\n    chapter1 --&gt; chapter2\n    chapter2 --&gt; chapter3\n    chapter3 --&gt; chapter4\n  end\n  subgraph partII[\"Part II: Transforms\"]\n    chapter5[\"5. What are transforms?\"]\n    chapter6[\"6. Map projections\"]\n    chapter7[\"7. Building pipelines\"]\n    chapter5 --&gt; chapter6\n    chapter6 --&gt; chapter7\n  end\n  subgraph partIII[\"Part III: Queries\"]\n    chapter8[\"8. Split-apply-combine\"]\n    chapter9[\"9. Geospatial joins\"]\n    chapter8 --&gt; chapter9\n  end\n  subgraph partIV[\"Part IV: Interpolation\"]\n    chapter10[\"10. Geospatial correlation\"]\n    chapter11[\"11. Simple interpolation\"]\n    chapter10 --&gt; chapter11\n  end\n  subgraph partV[\"Part V: Applications\"]\n    chapter12[\"12. Mineral deposits\"]\n    chapter13[\"13. Agricultural fields\"]\n    chapter14[\"14. Petroleum reservoirs\"]\n    chapter12 --&gt; chapter13\n    chapter13 --&gt; chapter14\n  end\n  partI --&gt; partII\n  partI --&gt; partIII\n  partI --&gt; partIV\n  partII --&gt; partV\n  partIII --&gt; partV\n  partIV --&gt; partV\n\n\n\n\n\nThe chapters were written to be read in sequence, but there is some flexibility on how to read the parts. I recommend reading Part I first to understand the framework and vision. After that, you will have the necessary background to follow the code examples in Part II, Part III and Part IV. Finally, you can explore the applications in Part V to solidify the concepts."
  },
  {
    "objectID": "preface.html#software-installation",
    "href": "preface.html#software-installation",
    "title": "Preface",
    "section": "Software installation",
    "text": "Software installation\nIf you want to reproduce the examples in the book, copy and paste the code below in the Julia REPL:\nusing Pkg\n\n# assert Julia version\n@assert VERSION ≥ v\"1.9\" \"requires Julia v1.9 or later\"\n\n# create fresh environment\npkg\"activate @gdsbook\"\n\n# install framework\npkg\"add GeoStats@0.45.3\"\n\n# install IO module\npkg\"add GeoIO@1.1.4\"\n\n# install dataset module\npkg\"add GeoStatsImages@1.1.0\"\n\n# install viz modules\npkg\"add CairoMakie@0.10.10\"\npkg\"add PairPlots@1.1.1\"\n\n# install other modules\npkg\"add CoDa@1.0.8\"\npkg\"add DataFrames@1.6.1\"\npkg\"add CSV@0.10.11\"\nSome examples require data files that are stored on GitHub at this link.\nClick on any file of interest and press the download button."
  },
  {
    "objectID": "preface.html#acknowledgements",
    "href": "preface.html#acknowledgements",
    "title": "Preface",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nI would like to acknowledge all the contributors of the  framework. You are the reason this book exists!  The implementation of the framework is only possible thanks to the amazing programming language advances by Bezanson et al. (2017).\nA special thanks to Elias Carvalho for his outstanding contributions to the software stack, to Prof. Douglas Mazzinghy (UFMG), Prof. Leandro Martínez (UNICAMP) and Prof. Fernando Moraes (UENF) for organizing the first training courses at universities, to Prof. Francisco Heron (UFC) for his contributions on high-performance computing, to Dr. João Pinelo (AIRCentre) for organizing the JuliaEO workshop, and to colleagues in industry who support this work through research and development projects, including Patrice Mazzoni, Keila Gonçalves, Fabio Duarte, Mariana Menezes, Givago Azevedo, Fernando Villanova, Luis Gomide, Rodrigo Leione.\nThanks to all the reviewers of the first draft, including Maciel Zortea, Max de Bayser, Bogumił Kamiński, Ronan Arraes, Erick Chacón Montalván, Kyle Beggs.\n\n\n\n\nBezanson, Jeff, Alan Edelman, Stefan Karpinski, and Viral B Shah. 2017. “Julia: A Fresh Approach to Numerical Computing.” SIAM Review 59 (1): 65–98. https://doi.org/10.1137/141000671.\n\n\nLauwens, Ben, and Allen Downey. 2018. Think Julia: How to Think Like a Computer Scientist. https://benlauwens.github.io/ThinkJulia.jl/latest/book.html."
  },
  {
    "objectID": "01-geodata.html#definition",
    "href": "01-geodata.html#definition",
    "title": "1  What is geospatial data?",
    "section": "1.1 Definition",
    "text": "1.1 Definition\n\n\n\n\n\n\nDefinition\n\n\n\n(Discrete) geospatial data is the combination of a table of attributes (or features) with a discretization of a geospatial domain. For each row (or measurement) in the table there corresponds an element (or geometry) in the discretization of the geospatial domain.\n\n\nThe definition depends on two other definitions that we clarify next.\n\n1.1.1 Table\nIn data science the most natural data structure for working with data is the table. Without big formalities, a table is any object that can be structured into rows containing measurements and columns representing variables. For example, Table 1.1 has 5 measurements of 4 variables:\n\n\nTable 1.1: Example of table\n\n\nNAME\nAGE\nHEIGHT\nGENDER\n\n\n\n\nJohn\n34\n1.78m\nmale\n\n\nMary\n12\n1.56m\nfemale\n\n\nPaul\n23\n1.70m\nmale\n\n\nAnne\n39\n1.80m\nfemale\n\n\nKate\n28\n1.72m\nfemale\n\n\n\n\nIn Julia, the concept of table is formalized in Tables.jl by Quinn et al. (2023). The definition is independent of the machine representation, and various representations can co-exist in the language.\n\n\n1.1.2 Domain\nThe second definition that we need is that of a geospatial domain. In geosciences, questions are often formulated within a physical region of interest. This physical region can cover a small area of the surface of the Earth, the entire Earth surface, or any region of finite measure that can be discretized into smaller geometries (a.k.a. elements):\n\n\n\n\n\n\n\n(a) Coast line in Islay Province, Peru. View on Google Maps\n\n\n\n\n\n\n\n(b) Synthetic carbonate reservoir model by Correia et al. (2015). See UNISIM-II for more details\n\n\n\n\nFigure 1.1: Example of geospatial domains\n\n\nFigure 1.1 illustrates two very different examples of geospatial domains. The domain in Figure 1.1 (a) is widely studied in GIS books. It is a 2D domain that contemplates a small area near Islay Province, Peru. The domain in Figure 1.1 (b) on the other hand is not considered in traditional GIS literature. It is a 3D domain that has been discretized into hexahedron geometries.\nThe concept of geospatial domain is formalized in Meshes.jl by Hoffimann et al. (2021).\n\n\n1.1.3 Remarks\n\nImages like the one depicted in Figure 1.1 (a) are often implemented in terms of the array data structure. GIS books call it “raster data”, but we will avoid this term in our framework in order to obtain a more general set of tools.\nAccording to our definition of geospatial data, “raster data” is simply a table with colors as variables (e.g., RGB values) combined with a Cartesian grid of quadrangle geometries. We illustrate this concept in Figure 1.2 by zooming in a satellite image of the Lena delta:\n\n\n\n\n\n\n\n(a) “Raster data” of Lena delta\n\n\n\n\n\n\n\n(b) Zoom reveals quadrangle geometries\n\n\n\n\nFigure 1.2: Quadrangle geometries in “raster data”\n\n\nThere are no constraints on the geometries used in the discretization of the geospatial domain. In Figure 1.3, Brazil is discretized into complex polygonal geometries that represent country states:\n\n\n\nFigure 1.3: Brazil’s states represented with complex polygonal geometries. View on Google Maps.\n\n\nGIS books call it “vector data” because the geometries are stored as vectors of coordinates in memory. We will also avoid this term in our framework given that it only highlights an implementation detail.\n\nBefore we start discussing machine representation with actual Julia code, let’s make a final (pedantic) distinction between the words geospatial and spatial. These words mean different things in different communities:\n\nIn geosciences, an object is geospatial if it lives in physical space.\nIn statistics, a model is spatial if it exploits the vicinity of samples in the sample space.\n\nGiven that geospatial data science deals with both concepts, we must use these words carefully.\n\n\n\n\n\n\nNote\n\n\n\nIn Geostatistical Learning, models can exploit both spaces to improve prediction performance, but that is out of the scope for this book."
  },
  {
    "objectID": "01-geodata.html#representation",
    "href": "01-geodata.html#representation",
    "title": "1  What is geospatial data?",
    "section": "1.2 Representation",
    "text": "1.2 Representation\nBased on the definition of geospatial data given in the previous section, we are now ready to proceed and discuss an efficient machine representation for it with actual Julia code.\n\n1.2.1 Table\nThe Julia language comes with two built-in table representations:\n\nNamed tuple of vectors\nVector of named tuples\n\nThe first representation focuses on the columns of the table:\n\ncoltable = (\n  NAME=[\"John\", \"Mary\", \"Paul\", \"Anne\", \"Kate\"],\n  AGE=[34, 12, 23, 39, 28],\n  HEIGHT=[1.78, 1.56, 1.70, 1.80, 1.72],\n  GENDER=[:male, :female, :male, :female, :female]\n)\n\n(NAME = [\"John\", \"Mary\", \"Paul\", \"Anne\", \"Kate\"], AGE = [34, 12, 23, 39, 28], HEIGHT = [1.78, 1.56, 1.7, 1.8, 1.72], GENDER = [:male, :female, :male, :female, :female])\n\n\nGiven that data science is often performed with entire columns, this column-major representation of a table is very convenient. The second representation focuses on the rows of the table:\n\nrowtable = [\n  (NAME=\"John\", AGE=34, HEIGHT=1.78, GENDER=:male),\n  (NAME=\"Mary\", AGE=12, HEIGHT=1.56, GENDER=:female),\n  (NAME=\"Paul\", AGE=23, HEIGHT=1.70, GENDER=:male),\n  (NAME=\"Anne\", AGE=39, HEIGHT=1.80, GENDER=:female),\n  (NAME=\"Kate\", AGE=28, HEIGHT=1.72, GENDER=:female)\n]\n\n5-element Vector{NamedTuple{(:NAME, :AGE, :HEIGHT, :GENDER), Tuple{String, Int64, Float64, Symbol}}}:\n (NAME = \"John\", AGE = 34, HEIGHT = 1.78, GENDER = :male)\n (NAME = \"Mary\", AGE = 12, HEIGHT = 1.56, GENDER = :female)\n (NAME = \"Paul\", AGE = 23, HEIGHT = 1.7, GENDER = :male)\n (NAME = \"Anne\", AGE = 39, HEIGHT = 1.8, GENDER = :female)\n (NAME = \"Kate\", AGE = 28, HEIGHT = 1.72, GENDER = :female)\n\n\nThe row-major representation can be useful to process data that is potentially larger than the available computer memory, or infinite streams of data.\nAlthough these two representations come built-in with Julia, they lack basic functionality for data science. The most widely used table representation for data science in Julia is available in DataFrames.jl by Bouchet-Valat and Kamiński (2023).\n\nusing DataFrames\n\ndf = DataFrame(\n  NAME=[\"John\", \"Mary\", \"Paul\", \"Anne\", \"Kate\"],\n  AGE=[34, 12, 23, 39, 28],\n  HEIGHT=[1.78, 1.56, 1.70, 1.80, 1.72],\n  GENDER=[:male, :female, :male, :female, :female]\n)\n\n5×4 DataFrame\n\n\n\nRow\nNAME\nAGE\nHEIGHT\nGENDER\n\n\n\nString\nInt64\nFloat64\nSymbol\n\n\n\n\n1\nJohn\n34\n1.78\nmale\n\n\n2\nMary\n12\n1.56\nfemale\n\n\n3\nPaul\n23\n1.7\nmale\n\n\n4\nAnne\n39\n1.8\nfemale\n\n\n5\nKate\n28\n1.72\nfemale\n\n\n\n\n\n\nThis representation provides additional syntax for accessing rows and columns of the table:\n\ndf[1,:]\n\nDataFrameRow (4 columns)\n\n\n\nRow\nNAME\nAGE\nHEIGHT\nGENDER\n\n\n\nString\nInt64\nFloat64\nSymbol\n\n\n\n\n1\nJohn\n34\n1.78\nmale\n\n\n\n\n\n\n\ndf[:,\"NAME\"]\n\n5-element Vector{String}:\n \"John\"\n \"Mary\"\n \"Paul\"\n \"Anne\"\n \"Kate\"\n\n\n\ndf[1:3,[\"NAME\",\"AGE\"]]\n\n3×2 DataFrame\n\n\n\nRow\nNAME\nAGE\n\n\n\nString\nInt64\n\n\n\n\n1\nJohn\n34\n\n\n2\nMary\n12\n\n\n3\nPaul\n23\n\n\n\n\n\n\n\ndf.HEIGHT\n\n5-element Vector{Float64}:\n 1.78\n 1.56\n 1.7\n 1.8\n 1.72\n\n\n\ndf.\"HEIGHT\"\n\n5-element Vector{Float64}:\n 1.78\n 1.56\n 1.7\n 1.8\n 1.72\n\n\n\n\n\n\n\n\nNote\n\n\n\nUnlike other languages, Julia makes a distinction between the the symbol :HEIGHT and the string \"HEIGHT\". The DataFrame representation supports both types for column names, but that is not always the case with other table representations.\n\n\nOther popular table representations in Julia are associated with specific file formats:\n\nCSV.File from CSV.jl (Quinn et al. 2023)\nXLSX.Worksheet from XLSX.jl\nDatabases from JuliaDatabases\n\nAs an example, we consider the table representation of a table.csv file stored on disk:\n\nusing CSV\n\nCSV.File(\"data/table.csv\")\n\n5-element CSV.File:\n CSV.Row: (NAME = String7(\"John\"), AGE = 34, HEIGHT = 1.78, GENDER = String7(\"male\"))\n CSV.Row: (NAME = String7(\"Mary\"), AGE = 12, HEIGHT = 1.56, GENDER = String7(\"female\"))\n CSV.Row: (NAME = String7(\"Paul\"), AGE = 23, HEIGHT = 1.7, GENDER = String7(\"male\"))\n CSV.Row: (NAME = String7(\"Anne\"), AGE = 39, HEIGHT = 1.8, GENDER = String7(\"female\"))\n CSV.Row: (NAME = String7(\"Kate\"), AGE = 28, HEIGHT = 1.72, GENDER = String7(\"female\"))\n\n\nThe choice of table representation is a function of the application.\n\n\n1.2.2 Domain\nAll available domain representations come from the Meshes.jl module. Let’s start illustrating the most common domains in GIS, which are collections of disconnected 2D geometries:\n\nusing GeoStats\n\np = Point(1, 2)\ns = Segment((0, 2), (1, 3))\nt = Triangle((0, 0), (1, 0), (1, 1))\nb = Ball((2, 2), 1)\n\ngeoms = [p, s, t, b]\n\n4-element Vector{Geometry{2, Float64}}:\n Point(1.0, 2.0)\n Segment((0.0, 2.0), (1.0, 3.0))\n Triangle((0.0, 0.0), (1.0, 0.0), (1.0, 1.0))\n Ball(center: (2.0, 2.0), radius: 1.0)\n\n\nBecause these geometries are unaware of each other, we place them into a GeometrySet, informally known in computational geometry as the “soup of geometries” data structure:\n\ngset = GeometrySet(geoms)\n\n4 GeometrySet{2,Float64}\n├─ Point(1.0, 2.0)\n├─ Segment((0.0, 2.0), (1.0, 3.0))\n├─ Triangle((0.0, 0.0), (1.0, 0.0), (1.0, 1.0))\n└─ Ball(center: (2.0, 2.0), radius: 1.0)\n\n\nNo advanced knowledge is required to start working with these geometries. For example, we can compute the length of the Segment, the area of the Triangle and the area of the Ball with:\n\nlength(s), area(t), area(b)\n\n(1.4142135623730951, 0.5, 3.141592653589793)\n\n\nMore generally, we can compute the measure of the geometries in the domain:\n\n[measure(g) for g in gset]\n\n4-element Vector{Float64}:\n 0.0\n 1.4142135623730951\n 0.5\n 3.141592653589793\n\n\nIn the example above, we iterated over the domain to apply the function of interest, but we could have used Julia’s dot syntax for broadcasting the function over the geometries:\n\nmeasure.(gset)\n\n4-element Vector{Float64}:\n 0.0\n 1.4142135623730951\n 0.5\n 3.141592653589793\n\n\nThe list of supported geometries is very comprehensive. It encompasses all geometries from the simple features standard and more. We will see more examples in the following chapters.\nOne of the main limitations of GIS software today is the lack of explicit representation of topology. A GeometrySet does not provide efficient topological relations (Floriani and Hui 2007), yet advanced geospatial data science requires the definition of geospatial domains where geometries are aware of their neighbors. Let’s illustrate this concept with the CartesianGrid domain:\n\ngrid = CartesianGrid(10, 10)\n\n10×10 CartesianGrid{2,Float64}\n  minimum: Point(0.0, 0.0)\n  maximum: Point(10.0, 10.0)\n  spacing: (1.0, 1.0)\n\n\nWe can access the individual geometries of the domain as before:\n\ngrid[1]\n\nQuadrangle{2,Float64}\n├─ Point(0.0, 0.0)\n├─ Point(1.0, 0.0)\n├─ Point(1.0, 1.0)\n└─ Point(0.0, 1.0)\n\n\nAnd even though we can manipulate this domain as if it was a “soup of geometries”, the major advantage in this abstraction is the underlying topology:\n\ntopo = topology(grid)\n\n10×10 GridTopology(aperiodic, aperiodic)\n\n\nThis data structure can be used by advanced users who wish to design algorithms with neighborhood information. We will cover this topic in a separate chapter. For now, keep in mind that working with the entire domain as opposed to with a vector or “soup of geometries” has major benefits.\n\n\n\n\n\n\nNote\n\n\n\nThe CartesianGrid domain is lazy meaning it only stores the start and end points of the grid together with the spacing between the elements. Therefore, we can easily create large 3D grids of Hexahedron geometries without consuming all available memory:\n\ngrid = CartesianGrid(10000, 10000, 10000)\n\n10000×10000×10000 CartesianGrid{3,Float64}\n  minimum: Point(0.0, 0.0, 0.0)\n  maximum: Point(10000.0, 10000.0, 10000.0)\n  spacing: (1.0, 1.0, 1.0)\n\n\n\ngrid[1]\n\nHexahedron{3,Float64}\n├─ Point(0.0, 0.0, 0.0)\n├─ Point(1.0, 0.0, 0.0)\n├─ Point(1.0, 1.0, 0.0)\n├─ Point(0.0, 1.0, 0.0)\n├─ Point(0.0, 0.0, 1.0)\n├─ Point(1.0, 0.0, 1.0)\n├─ Point(1.0, 1.0, 1.0)\n└─ Point(0.0, 1.0, 1.0)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nGeometries in a domain can be accessed with a single index domain[ind] or with a collection of indices domain[inds]. Even though it is tempting to use domain[i,j] and domain[i,j,k] in the case of 2D and 3D CartesianGrid, this syntax is not supported. Many domains do not have GridTopology.\n\n\nIn computational geometry, a CartesianGrid is a specific type of mesh. It can only represent “flat” domains sampled regularly along each dimension (e.g., images). To represent domains with curvature such as terrain elevation models or complex 3D domains like the one in Figure 1.1 (b), we can use the SimpleMesh domain:\n\n# global vector of 2D points\npoints = [(0.0, 0.0), (1.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.25, 0.5), (0.75, 0.5)]\n\n# connect the points into N-gons\nconnec = connect.([(1, 2, 6, 5), (2, 4, 6), (4, 3, 5, 6), (3, 1, 5)])\n\n# 2D mesh made of N-gon elements\nmesh = SimpleMesh(points, connec)\n\n4 SimpleMesh{2,Float64}\n  6 vertices\n  ├─ Point(0.0, 0.0)\n  ├─ Point(1.0, 0.0)\n  ├─ Point(0.0, 1.0)\n  ├─ Point(1.0, 1.0)\n  ├─ Point(0.25, 0.5)\n  └─ Point(0.75, 0.5)\n  4 elements\n  ├─ Quadrangle(1, 2, 6, 5)\n  ├─ Triangle(2, 4, 6)\n  ├─ Quadrangle(4, 3, 5, 6)\n  └─ Triangle(3, 1, 5)\n\n\nThe connect function takes a tuple of indices and a geometry type, and produces a connectivity object. The geometry type can be omitted, in which case it is assumed to be a Ngon, i.e., a polygon with N sides:\n\nc = connect((1, 2, 3))\n\nTriangle(1, 2, 3)\n\n\nThis connectivity object can be materialized into an actual geometry with a vector of points:\n\nmaterialize(c, [Point(0, 0), Point(1, 0), Point(1, 1)])\n\nTriangle{2,Float64}\n├─ Point(0.0, 0.0)\n├─ Point(1.0, 0.0)\n└─ Point(1.0, 1.0)\n\n\nThe SimpleMesh uses the materialize function above to construct geometries on the fly, similar to what we have seen with the CartesianGrid:\n\nmesh[1]\n\nQuadrangle{2,Float64}\n├─ Point(0.0, 0.0)\n├─ Point(1.0, 0.0)\n├─ Point(0.75, 0.5)\n└─ Point(0.25, 0.5)\n\n\nDon’t worry if you feel overwhelmed by these concepts. We are only sharing them here to give you an idea of how complex 3D domains are represented in the framework. You can do geospatial data science without ever having to operate with these concepts explicitly.\nLet’s make a few important remarks:\n\nFlexibility comes with a price. To construct a SimpleMesh of connected geometries we need to explicitly create a vector of vertices, and connect these vertices into geometries using their indices in the vector.\nGeometries in a SimpleMesh can be of different type. In the example, we have both Triangle and Quadrangle geometries in the domain. This is similar to what we had with GeometrySet, but now the geometries are connected.\nSimpleMesh are rarely constructed by hand. They are often the result of a sophisticated geometric processing pipeline that is already stored in a file on disk.\n\nThe last missing piece of the puzzle is the combination of tables with domains into geospatial data, which we discuss next.\n\n\n1.2.3 Data\nWouldn’t it be nice if we had a representation of geospatial data that behaved like a table as discussed in the Tables section, but preserved topological information as discussed in the Domains section? In the GeoStats.jl framework, this is precisely what we get with the georef function:\n\nusing GeoStats\n\ndf = DataFrame(\n  NAME=[\"John\", \"Mary\", \"Paul\", \"Anne\"],\n  AGE=[34, 12, 23, 39],\n  HEIGHT=[1.78, 1.56, 1.70, 1.80],\n  GENDER=[:male, :female, :male, :female]\n)\n\ngrid = CartesianGrid(2, 2)\n\ngeotable = georef(df, grid)\n\n\n4×5 GeoTable over 2×2 CartesianGrid{2,Float64}\n\n\nNAME\nAGE\nHEIGHT\nGENDER\ngeometry\n\n\nTextual\nCount\nContinuous\nUnknown\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\nJohn\n34\n1.78\nmale\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\nMary\n12\n1.56\nfemale\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\nPaul\n23\n1.7\nmale\nQuadrangle((0.0, 1.0), ..., (0.0, 2.0))\n\n\nAnne\n39\n1.8\nfemale\nQuadrangle((1.0, 1.0), ..., (1.0, 2.0))\n\n\n\n\n\nThe function combines any table with any domain into a geospatial data representation that adheres to the Tables.jl interface. We call this representation a GeoTable to distinguish it from a standard table. Besides the original columns, the GeoTable has a special geometry column with the underlying domain:\n\nnames(geotable)\n\n5-element Vector{String}:\n \"NAME\"\n \"AGE\"\n \"HEIGHT\"\n \"GENDER\"\n \"geometry\"\n\n\nUnlike a standard table, the GeoTable creates geometries on the fly depending on the data access pattern. For example, we can request the first measurement of the GeoTable and it will automatically construct the corresponding Quadrangle:\n\ngeotable[1,:]\n\n(NAME = \"John\", AGE = 34, HEIGHT = 1.78, GENDER = :male, geometry = Quadrangle((0.0, 0.0), ..., (0.0, 1.0)))\n\n\nIf we request a subset of measurements, the GeoTable will avoid unnecessary creation of geometries, and will instead return a view into the original data:\n\ngeotable[1:3,[\"NAME\",\"AGE\"]]\n\n\n3×3 GeoTable over 3 view(::CartesianGrid{2,Float64}, 1:3)\n\n\nNAME\nAGE\ngeometry\n\n\nTextual\nCount\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\nJohn\n34\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\nMary\n12\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\nPaul\n23\nQuadrangle((0.0, 1.0), ..., (0.0, 2.0))\n\n\n\n\n\nFinally, if we request the entire geometry column, we get back the original domain:\n\ngeotable[:,\"geometry\"]\n\n2×2 CartesianGrid{2,Float64}\n  minimum: Point(0.0, 0.0)\n  maximum: Point(2.0, 2.0)\n  spacing: (1.0, 1.0)\n\n\nBesides the data access patterns of the DataFrame, the GeoTable also provides an advanced method for retrieving all rows that intersect with a given geometry:\n\ngeotable[Segment((0, 0), (2, 0)), :]\n\n\n2×5 GeoTable over 2 view(::CartesianGrid{2,Float64}, [1, 2])\n\n\nNAME\nAGE\nHEIGHT\nGENDER\ngeometry\n\n\nTextual\nCount\nContinuous\nUnknown\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\nJohn\n34\n1.78\nmale\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\nMary\n12\n1.56\nfemale\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n\n\n\nThis method is very useful to narrow the region of interest and quickly discard all measurements that are outside of it. For instance, it is common to discard all “pixels” outside of a polygon before exporting the geotable to a file on disk.\nNotice that the GeoTable representation is general enough to accommodate both “raster data” and “vector data” in traditional GIS. We can create very large rasters because the CartesianGrid is lazy:\n\ngeoref(\n  (\n    R=rand(1000000),\n    G=rand(1000000),\n    B=rand(1000000)\n  ),\n  CartesianGrid(1000, 1000)\n)\n\n\n1000000×4 GeoTable over 1000×1000 CartesianGrid{2,Float64}\n\n\nR\nG\nB\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n0.682401\n0.124174\n0.453496\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n0.931743\n0.658216\n0.757798\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n0.592649\n0.0113913\n0.501532\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n0.392873\n0.360744\n0.525625\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n0.167322\n0.485464\n0.811077\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n0.343891\n0.456413\n0.549521\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n0.945741\n0.804747\n0.549775\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n0.700724\n0.467132\n0.501922\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n0.346681\n0.273198\n0.99561\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n0.41829\n0.488219\n0.690411\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nAnd can load vector geometries from files that store simple features using the GeoIO.jl module:\n\nusing GeoIO\n\nGeoIO.load(\"data/geotable.geojson\")\n\n\n4×2 GeoTable over 4 GeometrySet{2,Float32}\n\n\nNAME\ngeometry\n\n\nTextual\nMultiPolygon\n\n\n[NoUnits]\n\n\n\n\n\nEstuario\nMulti(21×PolyArea)\n\n\nFronteiras Antigas\nMulti(1×PolyArea)\n\n\nFronteiras Intermediarias\nMulti(1×PolyArea)\n\n\nFronteiras Novas\nMulti(2×PolyArea)\n\n\n\n\n\nWe will see more examples of “vector data” in the chapter Interfacing with GIS, and will explain why file formats like Shapefile.jl and GeoJSON.jl are not enough for advanced geospatial data science.\n\n\n\n\n\n\nTip for all users\n\n\n\nThe GeoStats.jl module reexports the full stack of modules for geospatial data science in Julia. There is no need to import modules like Meshes.jl explicitly. You are all set if you start your script with\nusing GeoStats\n\n\n\n\n\n\n\n\nTip for advanced users\n\n\n\nIn Julia, a function is type-stable if the return type is known at compile time. Since the GeoTable has columns from the original table (e.g., numbers) and an additional special geometry column, the access to the data with the DataFrame syntax is not type stable. If you need to write type-stable code, use the functions values and domain instead:\n\nvalues(geotable)\n\n4×4 DataFrame\n\n\n\nRow\nNAME\nAGE\nHEIGHT\nGENDER\n\n\n\nString\nInt64\nFloat64\nSymbol\n\n\n\n\n1\nJohn\n34\n1.78\nmale\n\n\n2\nMary\n12\n1.56\nfemale\n\n\n3\nPaul\n23\n1.7\nmale\n\n\n4\nAnne\n39\n1.8\nfemale\n\n\n\n\n\n\n\ndomain(geotable)\n\n2×2 CartesianGrid{2,Float64}\n  minimum: Point(0.0, 0.0)\n  maximum: Point(2.0, 2.0)\n  spacing: (1.0, 1.0)"
  },
  {
    "objectID": "01-geodata.html#remarks-1",
    "href": "01-geodata.html#remarks-1",
    "title": "1  What is geospatial data?",
    "section": "1.3 Remarks",
    "text": "1.3 Remarks\nWhat we learned in this chapter?\n\nGeospatial data can be efficiently represented as a GeoTable. This representation is universal meaning that it combines the “raster” and “vector” representations found in traditional GIS.\nA GeoTable provides all the data access patterns of a DataFrame. In particular, it supports the syntax geotable[rows,cols] without expensive copies of geometries.\nWorking with geospatial domains as opposed to working with vectors of disconnected geometries has major benefits. In particular, it preserves topological information.\n\nIt is very convenient to manipulate a GeoTable as if it was a DataFrame. Nevertheless, we will learn that advanced geospatial data science requires higher-level constructs to preserve geospatial information. We will cover these constructs in Part II and Part III of the book.\n\n\n\n\nBouchet-Valat, Milan, and Bogumił Kamiński. 2023. “DataFrames.jl: Flexible and Fast Tabular Data in Julia.” Journal of Statistical Software 107 (4): 1–32. https://doi.org/10.18637/jss.v107.i04.\n\n\nCorreia, M.., J.. Hohendorff, A. T. Gaspar, and D.. Schiozer. 2015. UNISIM-II-D: Benchmark Case Proposal Based on a Carbonate Reservoir. Vol. Day 3 Fri, November 20, 2015. SPE Latin America and Caribbean Petroleum Engineering Conference. https://doi.org/10.2118/177140-MS.\n\n\nFloriani, L. De, and A. Hui. 2007. “Shape Representations Based on Simplicial and Cell Complexes.” In Eurographics 2007 - State of the Art Reports, edited by Dieter Schmalstieg and Jiri Bittner. The Eurographics Association. https://doi.org/10.2312/egst.20071055.\n\n\nHoffimann, Júlio, Maciel Zortea, Breno de Carvalho, and Bianca Zadrozny. 2021. “Geostatistical Learning: Challenges and Opportunities.” Frontiers in Applied Mathematics and Statistics 7. https://doi.org/10.3389/fams.2021.689393.\n\n\nQuinn, Jacob, Bogumił Kamiński, David Anthoff, Milan Bouchet-Valat, Tamas K. Papp, Takafumi Arakaki, Rafael Schouten, et al. 2023. “JuliaData/Tables.jl: V1.10.1.” Zenodo. https://doi.org/10.5281/zenodo.7730968."
  },
  {
    "objectID": "02-geoviz.html#vizviz",
    "href": "02-geoviz.html#vizviz",
    "title": "2  Scientific visualization",
    "section": "2.1 viz/viz!",
    "text": "2.1 viz/viz!\nThe main visualization function that the framework provides is the viz/viz! function. The viz function creates a scene and displays geometries within a geospatial domain. On the other hand, the viz! function adds more geometries to an existing scene.\nLet’s create a small geotable over a Cartesian grid for illustration purposes:\n\nimg = georef((A=rand(10, 10), B=rand(10, 10)))\n\n\n100×3 GeoTable over 10×10 CartesianGrid{2,Float64}\n\n\nA\nB\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n0.154891\n0.545623\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n0.390015\n0.317483\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n0.663189\n0.796639\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n0.904042\n0.143451\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n0.155311\n0.235206\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n0.186985\n0.723993\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n0.635989\n0.398677\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n0.925139\n0.966304\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n0.519598\n0.89264\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n0.152451\n0.636895\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe georef function will create a CartesianGrid starting at the origin whenever the domain is omitted. The size of the grid is taken as the size of the first array in the named tuple:\n\nimg.geometry\n\n10×10 CartesianGrid{2,Float64}\n  minimum: Point(0.0, 0.0)\n  maximum: Point(10.0, 10.0)\n  spacing: (1.0, 1.0)\n\n\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nTo create a named tuple with a single key in Julia, we need an extra comma after the key/value pair:\n\n(A=rand(10, 10),)\n\n(A = [0.2902918719588352 0.6507449014997297 … 0.51170899103371 0.4197774751322675; 0.0815484627455847 0.13981071297775827 … 0.5825035273968379 0.31435335977464585; … ; 0.5709125717569872 0.7166564471716489 … 0.5249785247176243 0.35342043655224165; 0.6079381261443683 0.035550618267976786 … 0.9217843089589471 0.8480303836914921],)\n\n\nor a semicolon before the key/value pair:\n\n(; A=rand(10, 10))\n\n(A = [0.17499424594752933 0.6898191810063717 … 0.4021900263946282 0.6727811787121722; 0.5455090349530727 0.48336513306441864 … 0.7153792784691133 0.656642091433946; … ; 0.8524446677956828 0.7439023184326088 … 0.84017162558508 0.16173061519326581; 0.4223956526392122 0.17467728394482063 … 0.5473201647484285 0.9688922681672983],)\n\n\n\n\nBy default, all geometries are displayed with a single color:\n\nviz(img.geometry)\n\n\n\n\nWe can pass any vector of Colors.jl or numbers (automatically converted to colors) to the function via the color option. It is common to pass colors from another column of the geotable:\n\nviz(img.geometry, color = img.A)\n\n\n\n\nbut any vector with the same length can be passed:\n\nviz(img.geometry, color = 1:length(img.A))\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAny vector of Julia objects implementing the ascolors function can be passed to the color option.\n\n\nThe alpha option can be used to control the transparency of each geometry in the domain:\n\nviz(img.geometry, color = img.B, alpha = rand(length(img.B)))\n\n\n\n\nOther aesthetic options are available in the official documentation. To really see the benefits of the framework, let’s load data from a GeoJSON file and visualize it:\n\nusing GeoIO\n\ngis = GeoIO.load(\"data/geotable.geojson\")\n\nviz(gis.geometry, color = 1:4)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe “data” folder is stored on GitHub. Check the Preface for download instructions.\n\n\nAs already mentioned, the viz! function can be used to add more geometries to an existing scene. We can create a scene with the geometries from the first geotable (“raster data”), and then add the geometries from the second geotable (“vector data”):\n\nviz(img.geometry, color = 1:100)\nviz!(gis.geometry, color = 1:4)\n\n# display current figure\nMke.current_figure()\n\n\n\n\nLet’s add an additional set of points:\n\npts = [Point(-20, -10), Point(-20, 0), Point(-40, 10)]\n\nviz!(pts, color = 1:3)\n\nMke.current_figure()\n\n\n\n\nAnd a set of line segments to conclude the example:\n\nseg = [Segment((-40, -10), (0, 0)), Segment((-40, 0), (-20, 10))]\n\nviz!(seg, color = 1:2)\n\nMke.current_figure()\n\n\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nMakie.jl can set the aspect ratio of the axis after the visualization is created. The following code can be used to adjust the aspect ratio for the data in the scene:\n\nax = Mke.current_axis()\nax.aspect = Mke.DataAspect()\nMke.current_figure()\n\n\n\n\n\n\n\n\n\n\n\n\nTip for advanced users\n\n\n\nMakie.jl dispatches the viz and viz! functions whenever it encounters a geospatial domain, a vector of geometries or a single geometry from Meshes.jl. This means that you can replace viz with Mke.plot and viz! with Mke.plot! in scripts and the result will be the same."
  },
  {
    "objectID": "02-geoviz.html#viewer",
    "href": "02-geoviz.html#viewer",
    "title": "2  Scientific visualization",
    "section": "2.2 viewer",
    "text": "2.2 viewer\nAs geospatial data scientists we are often interested in quick inspection of intermediate results from multivariate geostatistical analysis. Visualizing all the variables manually with viz/viz! can be very time consuming. To address this issue, the framework provides a basic viewer that displays all variables stored in a geotable:\n\ngeotable = georef((A=rand(1000), B=rand(1000)), rand(3, 1000))\n\nviewer(geotable)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe georef function will create a PointSet whenever its second argument is a Matrix of coordinates. In this case, the points are represented in the columns of the matrix:\n\ngeotable.geometry\n\n1000 PointSet{3,Float64}\n├─ Point(0.7008285103443138, 0.5697315442055545, 0.8208937074472232)\n├─ Point(0.5725721468532451, 0.17965599970901924, 0.0624888010952247)\n├─ Point(0.7360224508218605, 0.2602316177472017, 0.1576043109861861)\n├─ Point(0.3302329790747268, 0.945113809269687, 0.18221199056448456)\n├─ Point(0.51443620566902, 0.06326562867475027, 0.2195058077259493)\n⋮\n├─ Point(0.9050583620642022, 0.8699041139019877, 0.612186600153967)\n├─ Point(0.8589688234490012, 0.6275738237072522, 0.9036781676616202)\n├─ Point(0.36639270077810027, 0.8740722652739178, 0.6962632210384139)\n├─ Point(0.5460928125585156, 0.77727551232173, 0.8474812222732634)\n└─ Point(0.9224828117304301, 0.3131345410864649, 0.7691827474698678)\n\n\n\n\nIt adds interactive elements to the scene, including a menu to select the variable used as color, and a color bar that automatically updates upon menu selection. The viewer will be particularly useful when we start to work with geospatial transforms in Part II of the book. The pipe operator (|&gt;) in Julia will be preferred for reasons that will become clearer later:\n\ngeotable = georef((A=rand(1000), B=rand(1000)), CartesianGrid(10, 10, 10))\n\ngeotable |&gt; viewer\n\n\n\n\nWe are now equipped with a set of visualization functions that can really improve the speed at which we explore and analyze geospatial data. These functions provide a consistent set of aesthetic options that we will cover in more detail with future examples.\nBefore we start learning the advanced features of the framework, we would like to say a few words about integration with existing GIS technology.\n\n\n\n\nBreloff, Tom. 2023. “Plots.jl.” Zenodo. https://doi.org/10.5281/zenodo.8183938.\n\n\nDanisch, Simon, and Julius Krumbiegel. 2021. “Makie.jl: Flexible High-Performance Data Visualization for Julia.” Journal of Open Source Software 6 (65): 3349. https://doi.org/10.21105/joss.03349."
  },
  {
    "objectID": "03-geoio.html#geoio.jl",
    "href": "03-geoio.html#geoio.jl",
    "title": "3  Interfacing with GIS",
    "section": "3.1 GeoIO.jl",
    "text": "3.1 GeoIO.jl\nThe GeoIO.jl module can load and save geospatial data on disk in a variety of formats, including the most popular formats in GIS (e.g., .shp, .geojson, .kml, .parquet) thanks to various backend packages spread across various Julia organizations. It is designed for users who just want to get their data ready for geospatial data science.\nTo load a file from disk, we use GeoIO.load:\nusing GeoIO\n\ngeotable = GeoIO.load(\"file.shp\")\nThe function automatically selects the backend based on the file extension, converts the simple features into a geospatial domain, and returns a GeoTable.\nTo save the GeoTable to disk, possibly in a different format, we use GeoIO.save:\nGeoIO.save(\"file.geojson\", geotable)\nThe module fixes inconsistencies between formats whenever possible. For example, the GeoJSON format writes Date columns as String because the JSON format has no date types. The Shapefile format has its own limitations, etc.\nOver time, we expect to improve the ecosystem as a whole by highlighting various issues with available standards and backend implementations."
  },
  {
    "objectID": "03-geoio.html#file-formats",
    "href": "03-geoio.html#file-formats",
    "title": "3  Interfacing with GIS",
    "section": "3.2 File formats",
    "text": "3.2 File formats\nMost GIS file formats do not preserve topological information. This means that neighborhood information is lost as soon as geometries are saved to disk. To illustrate this issue, we consider a geotable over a CartesianGrid:\n\ngeotable = georef((A=rand(10, 10), B=rand(10, 10)))\n\n\n100×3 GeoTable over 10×10 CartesianGrid{2,Float64}\n\n\nA\nB\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n0.95673\n0.595056\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n0.433142\n0.209471\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n0.896968\n0.563392\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n0.0964118\n0.294216\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n0.522508\n0.44894\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n0.74053\n0.741531\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n0.751469\n0.710199\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n0.575362\n0.843582\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n0.120594\n0.424802\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n0.359452\n0.0203108\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nIf we save the geotable to a .geojson file on disk, and then load it back, we observe that the CartesianGrid gets replaced by a GeometrySet:\n\nusing GeoIO\n\nfname = tempname() * \".geojson\"\n\nGeoIO.save(fname, geotable)\n\nGeoIO.load(fname)\n\n\n100×3 GeoTable over 100 GeometrySet{2,Float32}\n\n\nA\nB\ngeometry\n\n\nContinuous\nContinuous\nPolyArea\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n0.95673\n0.595056\nPolyArea((0.0, 0.0), ..., (0.0, 1.0))\n\n\n0.433142\n0.209471\nPolyArea((1.0, 0.0), ..., (1.0, 1.0))\n\n\n0.896968\n0.563392\nPolyArea((2.0, 0.0), ..., (2.0, 1.0))\n\n\n0.0964118\n0.294216\nPolyArea((3.0, 0.0), ..., (3.0, 1.0))\n\n\n0.522508\n0.44894\nPolyArea((4.0, 0.0), ..., (4.0, 1.0))\n\n\n0.74053\n0.741531\nPolyArea((5.0, 0.0), ..., (5.0, 1.0))\n\n\n0.751469\n0.710199\nPolyArea((6.0, 0.0), ..., (6.0, 1.0))\n\n\n0.575362\n0.843582\nPolyArea((7.0, 0.0), ..., (7.0, 1.0))\n\n\n0.120594\n0.424802\nPolyArea((8.0, 0.0), ..., (8.0, 1.0))\n\n\n0.359452\n0.0203108\nPolyArea((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nOther file formats such as .ply and .msh are widely used in computer graphics to save geospatial data over meshes, and preserve topological information:\n\nbeethoven = GeoIO.load(\"data/beethoven.ply\")\n\nviz(beethoven.geometry)"
  },
  {
    "objectID": "03-geoio.html#rationale",
    "href": "03-geoio.html#rationale",
    "title": "3  Interfacing with GIS",
    "section": "3.3 Rationale",
    "text": "3.3 Rationale\nNow that we did set the right expectations on our interface with GIS, let’s address an important question that many readers might have coming from other communities:\n\nDo we gain anything by not adhering to programming interfaces?\n\nThe answer is an emphatic YES! It means that we have total freedom to innovate and improve the representation of various geometries and geospatial domains with Julia’s amazing type system. To give a simple example, let’s take a look at the Triangle geometry:\n\nt = Triangle((0, 0), (1, 0), (1, 1))\n\nTriangle{2,Float64}\n├─ Point(0.0, 0.0)\n├─ Point(1.0, 0.0)\n└─ Point(1.0, 1.0)\n\n\nIf we treated this geometry as a generic polygon represented by a vector of vertices in memory, like it is done in GeoInterface.jl for example, we wouldn’t be able to dispatch optimized code that is only valid for a triangle:\n\n@code_llvm isconvex(t)\n\n;  @ /home/runner/.julia/packages/Meshes/qdc2V/src/predicates/isconvex.jl:57 within `isconvex`\ndefine i8 @julia_isconvex_4184([1 x [3 x [1 x [1 x [2 x double]]]]]* nocapture readonly %0) #0 {\ntop:\n  ret i8 1\n}\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn Julia, the macro @code_llvm shows the underlying code sent to the LLVM compiler. In this case, the code is the single line ret i8 1, which is the instruction to return the constant integer 1.\n\n\nNotice how the isconvex function is compiled away to the constant 1 (i.e. true) when called on the triangle. The code for a generic polygon is much more evolved and requires runtime checks that are too expensive to afford, specially in 3D.\nHaving cleared that up, we will now proceed to the last foundational chapter of the book, which covers the advanced geometric processing features of the framework."
  },
  {
    "objectID": "04-geoproc.html#geometries",
    "href": "04-geoproc.html#geometries",
    "title": "4  Geometric processing",
    "section": "4.1 Geometries",
    "text": "4.1 Geometries\nWe provide a vast list of geometries, which are organized into two main classes, Primitive and Polytope geometries. A geometry is a Primitive if it can be represented efficiently without discretization. For example, we can represent a Box with two corner points or a Ball with center and radius:\n\nbox = Box((0, 0, 0), (1, 1, 1))\nball = Ball((0, 0, 2), 0.5)\n\nviz([box, ball], color = [\"teal\", \"slategray3\"])\n\n\n\n\nOther examples include the Cylinder:\n\ncyl = Cylinder(1.0)\n\nviz(cyl)\n\n\n\n\nAnd the Torus:\n\ntorus = Torus((1, 1, 0), (-1, -1, 0), (1, -1, 0), 0.5)\n\nviz(torus)\n\n\n\n\nThe full list can be obtained with Julia’s subtypes function:\n\nsubtypes(Primitive)\n\n17-element Vector{Any}:\n Ball\n BezierCurve\n Box\n Circle\n Cone\n ConeSurface\n Cylinder\n CylinderSurface\n Disk\n Frustum\n FrustumSurface\n Line\n Plane\n Point\n Ray\n Sphere\n Torus\n\n\n\n\n\n\n\n\nNote\n\n\n\nGeometries have their own documentation. For example, to learn more about the Cylinder geometry, its parameters and defaults, we can type the following in the Julia REPL:\n?Cylinder\n\n\nA geometry is a Polytope if it can be represented as a combination of “flat sides”, which are also Polytope themselves. A 3D Polytope is called a Polyhedron, a 2D Polytope is called a Polygon and a 1D Polytope is called a polygonal Chain. All these geometries are represented internally with a list of vertices.\nFirst, let’s take a look into the Polyhedron geometries:\n\nsubtypes(Polyhedron)\n\n3-element Vector{Any}:\n Hexahedron\n Pyramid\n Tetrahedron\n\n\nThe Hexahedron is a generalization of a 3D Box in the sense that it doesn’t need to be aligned with the coordinate system:\n\nhex = Hexahedron((0, 0, 0), (1, 0, 0), (1, 1, 0), (0, 1, 0),\n                 (0, 0, 1), (1, 0, 1), (1, 1, 1), (0, 1, 1))\n\nviz(hex)\n\n\n\n\nIn this case, we need to store all the 8 vertices instead of just the corner points. Other examples of Polyhedron include the Tetrahedron and the Pyramid.\nNow, let’s move to the Polygon geometries:\n\nsubtypes(Polygon)\n\n2-element Vector{Any}:\n Ngon\n PolyArea\n\n\nWe provide two types of Polygon that meet different application requirements.\nThe Ngon is a polygon without holes. Its vertices are stored in static memory, and they are mostly used for discretization of other geometries and geospatial domains. We provide type aliases to construct Ngon with a specific number N of vertices:\nTriangle, Quadrangle, Pentagon, …, Decagon\nThe Quadrangle is a generalization of the 2D Box in the sense that it doesn’t need to be aligned with the coordinate system:\n\nt = Triangle((0, 0), (1, 0), (1, 1))\nq = Quadrangle((1, 1), (2, 1), (2, 2), (1, 2))\n\nviz([t, q], color = [\"teal\", \"slategray3\"])\n\n\n\n\nThe PolyArea is a polygon with or without holes. Its vertices are stored in dynamic memory, and they are mostly used for representation of polygonal areas in GIS:\n\nouter = [(0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 1.0)]\nhole1 = [(0.2, 0.2), (0.4, 0.2), (0.4, 0.4), (0.2, 0.4)]\nhole2 = [(0.6, 0.2), (0.8, 0.2), (0.8, 0.4), (0.6, 0.4)]\npoly  = PolyArea([outer, hole1, hole2])\n\nviz(poly)\n\n\n\n\nIn the example above, the first list of vertices represents the external boundary of the PolyArea, also known as the outer Ring. The other two lists represent the two internal boundaries, or inner rings. A single list of vertices can be used, in which case the PolyArea doesn’t have holes.\nFinally, let’s take a look into the polygonal Chain:\n\nsubtypes(Chain)\n\n3-element Vector{Any}:\n Ring\n Rope\n Segment\n\n\nThese are 1-dimensional polytopes connecting Points in sequence. We’ve seen the Rings in the PolyArea and Ngon geometries:\n\nr = rings(poly)\n\nviz(r)\n\n\n\n\nA Ring is closed meaning that its first and last Points are connected with a Segment. A Rope is an open Ring without the closing Segment:\n\nviz(open.(r))\n\n\n\n\nWe can obtain the list of segments of a Chain with the segments function:\n\ncollect(segments(first(r)))\n\n4-element Vector{Segment{2, Float64}}:\n Segment((0.0, 0.0), (1.0, 0.0))\n Segment((1.0, 0.0), (1.0, 1.0))\n Segment((1.0, 1.0), (0.0, 1.0))\n Segment((0.0, 1.0), (0.0, 0.0))\n\n\nThe Segment geometry is a Chain with just 2 vertices:\n\nviz(Segment((0, 0), (1, 1)))\n\n\n\n\nFinally, there is the Multi-geometry, which is a set of geometries seen as a single geometry. This is very common in GIS to represent disconnected areas on a geographic map that are related to each other (e.g., political areas):\n\nMulti([Point(1, 2), Point(2, 3)])\n\nMultiPoint2{2,Float64}\n├─ Point(1.0, 2.0)\n└─ Point(2.0, 3.0)\n\n\n\nMulti(r)\n\nMultiRing{2,Float64}\n├─ Ring((0.0, 0.0), ..., (0.0, 1.0))\n├─ Ring((0.2, 0.2), ..., (0.4, 0.2))\n└─ Ring((0.6, 0.2), ..., (0.8, 0.2))\n\n\n\nMulti([t, q])\n\nMultiNgon{2,Float64}\n├─ Triangle((0.0, 0.0), (1.0, 0.0), (1.0, 1.0))\n└─ Quadrangle((1.0, 1.0), ..., (1.0, 2.0))"
  },
  {
    "objectID": "04-geoproc.html#predicates",
    "href": "04-geoproc.html#predicates",
    "title": "4  Geometric processing",
    "section": "4.2 Predicates",
    "text": "4.2 Predicates\nJulia provides support for unicode characters in variable and function names. We leverage this feature to define commonly used geometric predicates with intuitive mathematical notation:\n\np = Point(0.0, 0.0)\nb = Ball((0.5, 0.5), 1.0)\n\nviz([p, b], color = [\"teal\", \"slategray3\"])\n\n\n\n\n\np ∈ b\n\ntrue\n\n\n\nb1 = Box((0, 0), (1, 1))\nb2 = Box((0.5, 0.5), (2, 2))\n\nviz([b1, b2], color = [\"teal\", \"slategray3\"])\n\n\n\n\n\nb1 ⊆ b2\n\nfalse\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nThe symbol ∈ is obtained in Julia by typing \\in and pressing the TAB key on the keyboard. We could have used the syntax p in b or in(p, b) as well. Similarly, the symbol ⊆ is obtained by typing \\subseteq. We could have used the syntax issubseteq(b1, b2) as well.\nIf you don’t know the \\(\\LaTeX\\) name of a symbol, you can copy/paste it in the Julia REPL in help mode:\n?∈\n\n\nSome predicates don’t have well-established mathematical notation. For example, a polygon issimple if it doesn’t have holes nor self-intersections:\n\nq = Quadrangle((0, 0), (1, 0), (1, 1), (0.6, 0.4))\n\nviz(q)\n\n\n\n\n\nissimple(q)\n\ntrue\n\n\nIt isconvex if all line segments connecting two points of the polygon are inside the polygon:\n\nisconvex(q)\n\nfalse\n\n\nA very useful predicate is intersects (with a “s” at the end):\n\nouter = [(0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 1.0)]\nhole1 = [(0.2, 0.2), (0.4, 0.2), (0.4, 0.4), (0.2, 0.4)]\nhole2 = [(0.6, 0.2), (0.8, 0.2), (0.8, 0.4), (0.6, 0.4)]\npoly  = PolyArea([outer, hole1, hole2])\nball1 = Ball((0.5, 0.5), 0.05)\nball2 = Ball((0.3, 0.3), 0.05)\n\nviz([poly, ball1, ball2], color = [\"slategray3\", \"teal\", \"brown\"])\n\n\n\n\n\nintersects(poly, ball1)\n\ntrue\n\n\n\nintersects(poly, ball2)\n\nfalse\n\n\nIt tells whether or not the geometries intersect, without actually computing the intersection. The intersection itself is considered a geometric operation as discussed in the next section.\nPlease consult the official documentation for the full list of predicates."
  },
  {
    "objectID": "04-geoproc.html#operations",
    "href": "04-geoproc.html#operations",
    "title": "4  Geometric processing",
    "section": "4.3 Operations",
    "text": "4.3 Operations\nGeometric operations transform a geometry or a set of geometries into a new geometry or number. For example, the intersection of two segments can be a Point, a Segment or nothing:\n\ns1 = Segment((0.0, 0.0), (1.0, 0.0))\ns2 = Segment((0.5, 0.0), (2.0, 0.0))\n\ns1 ∩ s2\n\nSegment{2,Float64}\n├─ Point(0.5, 0.0)\n└─ Point(1.0, 0.0)\n\n\n\n\n\n\n\n\nTip for advanced users\n\n\n\nFor performance-sensitive applications, it is wise to replace the ∩ operation by its the 3-argument version named intersection:\n\nintersection(s1, s2) do I\n  if I == Crossing\n    return 1\n  else\n    return 0\n  end\nend\n\n0\n\n\nThe example above uses Julia’s do-syntax to define a function in place. The function takes the intersection type I and creates branches that return the same type (Int in this case) for type stability. The more we reduce the number of branches and types, the more the Julia compiler will be able to infer the output type.\n\n\nLikewise, the intersection of two 2D geometries can be obtained with:\n\nouter = [(8, 0), (4, 8), (2, 8), (-2, 0), (0, 0), (1, 2), (5, 2), (6, 0)]\ninner = [(4, 4), (2, 4), (3, 6)]\npoly  = PolyArea([outer, inner])\nquad  = Quadrangle((0, 1), (3, 1), (3, 7), (0, 7))\n\nint = poly ∩ quad\n\nviz([poly, quad, boundary(int)],\n    color = [\"slategray3\", \"teal\", \"red\"],\n    alpha = [1.0, 0.2, 1.0])\n\n\n\n\nThe previous example makes use of the boundary of a geometry, which is very useful to know:\n\nboundary(poly)\n\nMultiRing{2,Float64}\n├─ Ring((8.0, 0.0), ..., (6.0, 0.0))\n└─ Ring((4.0, 4.0), (2.0, 4.0), (3.0, 6.0))\n\n\nSome operations like measure (length, area or volume) produce numbers instead of geometries. For example, the area of the letter “A” above is:\n\narea(poly)\n\n36.0\n\n\nThe measure of the boundary is known as the perimeter of the geometry:\n\nperimeter(poly)\n\n38.83281572999748\n\n\nAll Polytope geometries have vertices:\n\nvertices(poly)\n\n11-element CircularVector(::Vector{Point2}):\n Point(8.0, 0.0)\n Point(4.0, 8.0)\n Point(2.0, 8.0)\n Point(-2.0, 0.0)\n Point(0.0, 0.0)\n Point(1.0, 2.0)\n Point(5.0, 2.0)\n Point(6.0, 0.0)\n Point(4.0, 4.0)\n Point(2.0, 4.0)\n Point(3.0, 6.0)\n\n\nPlease consult the official documentation for the full list of operations."
  },
  {
    "objectID": "04-geoproc.html#algorithms",
    "href": "04-geoproc.html#algorithms",
    "title": "4  Geometric processing",
    "section": "4.4 Algorithms",
    "text": "4.4 Algorithms\nAny other function that is not a predicate nor an operation is called a geometric processing “algorithm” in the framework. We provide a list of advanced algorithms for discretization, simplification, refinement, convex hull, etc.\nBelow we illustrate some of these algorithms, which will be useful in future examples:\n\npoints = rand(Point2, 100)\n\n100-element Vector{Point2}:\n Point(0.23713393598654087, 0.12211325951886864)\n Point(0.9329176912016844, 0.17203021246317474)\n Point(0.09818868474837006, 0.5029111210772352)\n Point(0.9129430843108838, 0.3025816269109134)\n Point(0.5171078481358156, 0.4415336408865772)\n Point(0.8390120225518903, 0.8561313102165401)\n Point(0.30785276055389943, 0.14320375147041975)\n Point(0.9530568642406114, 0.439839854699385)\n Point(0.05584711728064318, 0.7449496681140154)\n Point(0.8211831340738126, 0.23489154443060423)\n Point(0.838972454999383, 0.4599194199597376)\n Point(0.7514622481688811, 0.6220032261185178)\n Point(0.03147088150069677, 0.8443862730921441)\n ⋮\n Point(0.6496272485520778, 0.79945470079812)\n Point(0.40470096498803665, 0.39566683709287875)\n Point(0.708166841222558, 0.6609915846507547)\n Point(0.4216039113326888, 0.11151740449543146)\n Point(0.7057434870928334, 0.021826080951048543)\n Point(0.6335032494353775, 0.07648749756924644)\n Point(0.8406557874855966, 0.22035181484955935)\n Point(0.1661797898167835, 0.30713867001389905)\n Point(0.33119180572831486, 0.5063986310128352)\n Point(0.8777472999864798, 0.3055448096006139)\n Point(0.3331569142467248, 0.9249404597454444)\n Point(0.3339839632970468, 0.5575874978008882)\n\n\n\nviz(boundingbox(points))\nviz!(points, color = \"black\")\nMke.current_figure()\n\n\n\n\n\nviz(convexhull(points))\nviz!(points, color = \"black\")\nMke.current_figure()\n\n\n\n\nWe will have the chance to see more algorithms in action as we advance in the chapters of the book."
  },
  {
    "objectID": "04-geoproc.html#domains",
    "href": "04-geoproc.html#domains",
    "title": "4  Geometric processing",
    "section": "4.5 Domains",
    "text": "4.5 Domains\nGeometries can be discretized into geospatial domains (i.e., collections of geometries). We have seen some of these domains in previous chapters, including the GeometrySet and the CartesianGrid. Here, we will focus on the Mesh subtypes:\n\nsubtypes(Mesh)\n\n2-element Vector{Any}:\n Grid\n SimpleMesh\n\n\n\nsubtypes(Grid)\n\n2-element Vector{Any}:\n CartesianGrid\n RectilinearGrid\n\n\nFor most purposes, these domains can be manipulated as if they were Julia vectors of geometries. As an example, we can compute the centroid of each geometry in the domain by broadcasting the function:\n\ngrid = CartesianGrid(2, 3)\n\ncentroid.(grid)\n\n6-element Vector{Point2}:\n Point(0.5, 0.5)\n Point(1.5, 0.5)\n Point(0.5, 1.5)\n Point(1.5, 1.5)\n Point(0.5, 2.5)\n Point(1.5, 2.5)\n\n\nIn some cases, however, it is important to know which geometries are adjacent to a given geometry; or which geometries make up the boundary of a given geometry. This is where the topology is useful:\n\ntopo = topology(grid)\n\n2×3 GridTopology(aperiodic, aperiodic)\n\n\nWe can create an Adjacency topological relation to find which quadrangles are adjacent to quadrangle 1 in the domain:\n\nA = Adjacency{2}(topo)\n\nA(1)\n\n2-element Vector{Int64}:\n 2\n 3\n\n\nThe number 2 that appears in the Adjacency relation is known as the parametric dimension. In this case, we are interested in the adjacency of 2D geometries. The quadrangle 1 is the first quadrangle in the bottom-left corner of the grid, and it is adjacent to quadrangles 2 and 3. As another example, the quadrangle 3 is adjacent to quadrangles 4, 1 and 5:\n\nA(3)\n\n3-element Vector{Int64}:\n 4\n 1\n 5\n\n\nWe can also query the adjacency of vertices, which have parametric dimension 0:\n\nA = Adjacency{0}(topo)\n\nA(1)\n\n2-element Vector{Int64}:\n 2\n 4\n\n\nOr query the vertices that are on the boundary of a given quadrangle with the Boundary topological relation. In this case, we specify the parametric dimension of the input and output geometries:\n\nB = Boundary{2,0}(topo)\n\nB(1)\n\n4-element Vector{Int64}:\n 1\n 2\n 5\n 4\n\n\nTopological relations are an advanced feature of the framework. They are mostly used by developers of geostatistical algorithms, or in geospatial queries that will be covered in Part III of the book."
  },
  {
    "objectID": "04-geoproc.html#congratulations",
    "href": "04-geoproc.html#congratulations",
    "title": "4  Geometric processing",
    "section": "4.6 Congratulations!",
    "text": "4.6 Congratulations!\nCongratulations on finishing Part I of the book. Let’s quickly review what we learned so far:\n\nThe main concept in geospatial data science is the concept of geospatial data, represented in the GeoStats.jl framework as geotables over geospatial domains.\nThe geotable representation generalizes traditional GIS representations (“raster” vs. “vector”), and enables an unified approach to visualization and manipulation of geospatial data.\nIt is still possible to interface with existing GIS technology via input and output of files using the GeoIO.jl module. A typical workflow will load GIS data at the beginning of a script, and save the result of the analysis at the end of the script.\nGeometric processing doesn’t need to be complicated. It should be fun and read like math. If it feels “computer sciency”, that is a limitation of the software and programming language.\n\nWe are finally ready to learn the advanced features of the framework. Let’s get it started."
  },
  {
    "objectID": "05-transforms.html#motivation",
    "href": "05-transforms.html#motivation",
    "title": "5  What are transforms?",
    "section": "5.1 Motivation",
    "text": "5.1 Motivation\nIn Part I of the book, we learned that our GeoTable representation of geospatial data provides the data access pattern of the DataFrame, a feature that is very convenient for data science. To recap, let’s consider the following geotable with four random variables:\n\nN = 10000\na = [2randn(N÷2) .+ 6; randn(N÷2)]\nb = [3randn(N÷2); 2randn(N÷2)]\nc = randn(N)\nd = c .+ 0.6randn(N)\n\ntable = (; a, b, c, d)\n\ngt = georef(table, CartesianGrid(100, 100))\n\n\n10000×5 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\na\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n6.98484\n0.0341826\n0.413454\n0.203462\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n7.62208\n-6.91411\n1.22577\n1.53608\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n1.07675\n-3.81989\n0.989168\n1.00495\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n7.19464\n4.02289\n-0.52071\n-0.574699\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n8.18491\n0.737772\n-0.580056\n-0.541137\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n7.31731\n-4.54177\n1.81154\n1.56883\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n4.35514\n-1.78341\n-0.579144\n-1.06321\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n2.90295\n-0.951305\n-0.913929\n-1.51364\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n3.01593\n-0.475414\n-1.31362\n-1.15284\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n9.02692\n-4.50934\n-0.215652\n0.639203\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nWe can easily retrieve the “a” column of the geotable as a vector, and plot its histogram:\n\nMke.hist(gt.a, color = \"gray80\")\n\n\n\n\nWe can compute the cross-correlation between columns “a” and “b”:\n\ncor(gt.a, gt.b)\n\n0.020681984348962134\n\n\nAnd inspect bivariate distributions of the values of the geotable with PairPlots.jl by Thompson (2023):\n\nusing PairPlots\n\npairplot(values(gt))\n\n\n\n\nThe pattern is certainly useful to answer geoscientific questions that can be answered on the basis of marginal analysis (i.e. entire columns treated as measurements of a single random variable). However, the answers to many questions in geosciences depend on where the measurements were made.\nAttempting to answer geoscientific questions with basic access to rows and columns can be very frustrating. In particular, this approach is prone to unintentional removal of geospatial information:\n\ngt.a\n\n10000-element Vector{Float64}:\n  6.984838248866237\n  7.622075745122871\n  1.0767453866537577\n  7.194643126886785\n  8.184912171426157\n  7.317308110675463\n  4.355142171345252\n  2.9029493422321972\n  3.0159302667376635\n  9.026924953090235\n  5.907164167021759\n  8.142895411807652\n  4.011794760151991\n  ⋮\n  0.7057489944814195\n -1.08030560064309\n  0.0782903329879583\n  0.8477768497005204\n  0.42849746287499263\n  1.139760057052696\n  1.4548996095800997\n -1.885954754552489\n  0.45865960500304254\n -0.022302961118284437\n -0.761290364769084\n -0.38675725990411997\n\n\n\n\n\n\n\n\nNote\n\n\n\nAny script that is written in terms of direct column access has the potential to discard the special geometry column, and become unreadable very quickly with the use of auxiliary indices for rows.\n\n\nWe propose a new approach to geospatial data science with the concept of transforms, which we introduce in three classes with practical examples:\n\nFeature transforms\nGeometric transforms\nGeospatial transforms"
  },
  {
    "objectID": "05-transforms.html#feature-transforms",
    "href": "05-transforms.html#feature-transforms",
    "title": "5  What are transforms?",
    "section": "5.2 Feature transforms",
    "text": "5.2 Feature transforms\nA feature transform is a function that takes the values of the geotable and produces a new set of values over the same geospatial domain. The framework provides over 30 such transforms, ranging from basic selection of columns, to data cleaning, to advanced multivariate statistical transforms.\n\n5.2.1 Basic\nLet’s start with two basic and important transforms, Select and Reject. The Select transform can be used to select columns of interest from a geotable:\n\ngt |&gt; Select(\"a\", \"b\") # select columns \"a\" and \"b\"\n\n\n10000×3 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\na\nb\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n6.98484\n0.0341826\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n7.62208\n-6.91411\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n1.07675\n-3.81989\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n7.19464\n4.02289\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n8.18491\n0.737772\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n7.31731\n-4.54177\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n4.35514\n-1.78341\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n2.90295\n-0.951305\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n3.01593\n-0.475414\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n9.02692\n-4.50934\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nIn the example above, we selected the columns “a” and “b” explicitly, but Select has various methods for more flexible column selection:\n\ngt |&gt; Select(1:3) # select columns 1 to 3\n\n\n10000×4 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\na\nb\nc\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n6.98484\n0.0341826\n0.413454\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n7.62208\n-6.91411\n1.22577\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n1.07675\n-3.81989\n0.989168\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n7.19464\n4.02289\n-0.52071\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n8.18491\n0.737772\n-0.580056\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n7.31731\n-4.54177\n1.81154\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n4.35514\n-1.78341\n-0.579144\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n2.90295\n-0.951305\n-0.913929\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n3.01593\n-0.475414\n-1.31362\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n9.02692\n-4.50934\n-0.215652\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\ngt |&gt; Select(r\"[bcd]\") # columns matching regular expression\n\n\n10000×4 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n0.0341826\n0.413454\n0.203462\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n-6.91411\n1.22577\n1.53608\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n-3.81989\n0.989168\n1.00495\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n4.02289\n-0.52071\n-0.574699\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n0.737772\n-0.580056\n-0.541137\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n-4.54177\n1.81154\n1.56883\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n-1.78341\n-0.579144\n-1.06321\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n-0.951305\n-0.913929\n-1.51364\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n-0.475414\n-1.31362\n-1.15284\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n-4.50934\n-0.215652\n0.639203\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nA convenient method is also provided to select and rename columns:\n\ngt |&gt; Select(\"a\" =&gt; \"A\", \"b\" =&gt; \"B\")\n\n\n10000×3 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\nA\nB\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n6.98484\n0.0341826\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n7.62208\n-6.91411\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n1.07675\n-3.81989\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n7.19464\n4.02289\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n8.18491\n0.737772\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n7.31731\n-4.54177\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n4.35514\n-1.78341\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n2.90295\n-0.951305\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n3.01593\n-0.475414\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n9.02692\n-4.50934\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nThe Reject transform can be used to reject columns from a geotable that are not relevant for a given analysis. It supports the same column specification of Select:\n\ngt |&gt; Reject(\"b\") # reject column \"b\"\n\n\n10000×4 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\na\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n6.98484\n0.413454\n0.203462\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n7.62208\n1.22577\n1.53608\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n1.07675\n0.989168\n1.00495\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n7.19464\n-0.52071\n-0.574699\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n8.18491\n-0.580056\n-0.541137\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n7.31731\n1.81154\n1.56883\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n4.35514\n-0.579144\n-1.06321\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n2.90295\n-0.913929\n-1.51364\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n3.01593\n-1.31362\n-1.15284\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n9.02692\n-0.215652\n0.639203\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nUnlike direct column access, the Select and Reject transforms preserve geospatial information.\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nThe Select transform can be used in conjunction with the viewer to quickly visualize a specific variable:\n\ngt |&gt; Select(\"a\") |&gt; viewer\n\n\n\n\n\n\nThe Rename transform can be used to rename specific columns of a geotable. It preserves all other columns that are not part of the column specification:\n\ngt |&gt; Rename(\"a\" =&gt; \"A\", \"b\" =&gt; \"B\")\n\n\n10000×5 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\nA\nB\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n6.98484\n0.0341826\n0.413454\n0.203462\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n7.62208\n-6.91411\n1.22577\n1.53608\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n1.07675\n-3.81989\n0.989168\n1.00495\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n7.19464\n4.02289\n-0.52071\n-0.574699\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n8.18491\n0.737772\n-0.580056\n-0.541137\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n7.31731\n-4.54177\n1.81154\n1.56883\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n4.35514\n-1.78341\n-0.579144\n-1.06321\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n2.90295\n-0.951305\n-0.913929\n-1.51364\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n3.01593\n-0.475414\n-1.31362\n-1.15284\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n9.02692\n-4.50934\n-0.215652\n0.639203\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nThe Identity transform can be used as a placeholder to forward the geotable without modifications to the next transform:\n\ngt |&gt; Identity()\n\n\n10000×5 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\na\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n6.98484\n0.0341826\n0.413454\n0.203462\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n7.62208\n-6.91411\n1.22577\n1.53608\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n1.07675\n-3.81989\n0.989168\n1.00495\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n7.19464\n4.02289\n-0.52071\n-0.574699\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n8.18491\n0.737772\n-0.580056\n-0.541137\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n7.31731\n-4.54177\n1.81154\n1.56883\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n4.35514\n-1.78341\n-0.579144\n-1.06321\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n2.90295\n-0.951305\n-0.913929\n-1.51364\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n3.01593\n-0.475414\n-1.31362\n-1.15284\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n9.02692\n-4.50934\n-0.215652\n0.639203\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nThe RowTable and ColTable transforms change the underlying table representation of the values of the geotable as discussed in the first chapter of the book:\n\nrt = gt |&gt; RowTable()\n\n\n10000×5 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\na\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n6.98484\n0.0341826\n0.413454\n0.203462\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n7.62208\n-6.91411\n1.22577\n1.53608\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n1.07675\n-3.81989\n0.989168\n1.00495\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n7.19464\n4.02289\n-0.52071\n-0.574699\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n8.18491\n0.737772\n-0.580056\n-0.541137\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n7.31731\n-4.54177\n1.81154\n1.56883\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n4.35514\n-1.78341\n-0.579144\n-1.06321\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n2.90295\n-0.951305\n-0.913929\n-1.51364\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n3.01593\n-0.475414\n-1.31362\n-1.15284\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n9.02692\n-4.50934\n-0.215652\n0.639203\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\nrt |&gt; values |&gt; typeof\n\n\nVector{NamedTuple{(:a, :b, :c, :d), NTuple{4, Float64}}} (alias for Array{NamedTuple{(:a, :b, :c, :d), NTuple{4, Float64}}, 1})\n\n\n\nThe Functional transform can be used to apply a function to columns of a geotable in place:\n\ngt |&gt; Functional(cos) |&gt; values |&gt; pairplot\n\n\n\n\n\ngt |&gt; Functional(\"a\" =&gt; cos, \"b\" =&gt; sin) |&gt; values |&gt; pairplot\n\n\n\n\nThe Map transform can be used to create new columns from existing columns in the geotable. It takes a column specification, calls a function on the selected columns row-by-row, and returns the result as a new column:\n\ngt |&gt; Map(\"a\" =&gt; sin, \"b\" =&gt; cos =&gt; \"cos(b)\")\n\n\n10000×7 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\na\nb\nc\nd\na_sin\ncos(b)\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n6.98484\n0.0341826\n0.413454\n0.203462\n0.645481\n0.999416\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n7.62208\n-6.91411\n1.22577\n1.53608\n0.97323\n0.807483\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n1.07675\n-3.81989\n0.989168\n1.00495\n0.880419\n-0.778645\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n7.19464\n4.02289\n-0.52071\n-0.574699\n0.790398\n-0.636149\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n8.18491\n0.737772\n-0.580056\n-0.541137\n0.94574\n0.739969\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n7.31731\n-4.54177\n1.81154\n1.56883\n0.859414\n-0.169797\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n4.35514\n-1.78341\n-0.579144\n-1.06321\n-0.936863\n-0.211017\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n2.90295\n-0.951305\n-0.913929\n-1.51364\n0.236385\n0.580621\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n3.01593\n-0.475414\n-1.31362\n-1.15284\n0.125332\n0.889103\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n9.02692\n-4.50934\n-0.215652\n0.639203\n0.38744\n-0.201654\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\ngt |&gt; Map([2, 3] =&gt; ((b, c) -&gt; 2b + c) =&gt; \"f(b, c)\")\n\n\n10000×6 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\na\nb\nc\nd\nf(b, c)\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n6.98484\n0.0341826\n0.413454\n0.203462\n0.481819\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n7.62208\n-6.91411\n1.22577\n1.53608\n-12.6024\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n1.07675\n-3.81989\n0.989168\n1.00495\n-6.6506\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n7.19464\n4.02289\n-0.52071\n-0.574699\n7.52507\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n8.18491\n0.737772\n-0.580056\n-0.541137\n0.895489\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n7.31731\n-4.54177\n1.81154\n1.56883\n-7.27199\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n4.35514\n-1.78341\n-0.579144\n-1.06321\n-4.14597\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n2.90295\n-0.951305\n-0.913929\n-1.51364\n-2.81654\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n3.01593\n-0.475414\n-1.31362\n-1.15284\n-2.26445\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n9.02692\n-4.50934\n-0.215652\n0.639203\n-9.23434\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nThe name of the resulting column can be provided or omitted. If the name is omitted like in the example above with the column “a”, it is created by concatenation of column and function names.\n\n\n\n\n\n\nNote\n\n\n\nThe Map transform mimics the behavior of the transform function in DataFrames.jl, except that it always broadcasts the functions to the rows of the selected columns and always produces a single column for each function.\n\n\nTo filter rows in the geotable based on a given predicate (i.e., a function that returns true or false), we can use the Filter transform:\n\ngt |&gt; Filter(row -&gt; row.a &lt; 0 && row.b &gt; 0)\n\n\n1299×5 GeoTable over 1299 view(::CartesianGrid{2,Float64}, [165, 3007, 4406, 5015, ..., 9996, 9998, 9999, 10000])\n\n\na\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n-0.168806\n3.1911\n2.34139\n2.94913\nQuadrangle((64.0, 1.0), ..., (64.0, 2.0))\n\n\n-0.657453\n2.38995\n-0.930194\n-0.461321\nQuadrangle((6.0, 30.0), ..., (6.0, 31.0))\n\n\n-0.0767223\n5.20546\n0.0579718\n0.153198\nQuadrangle((5.0, 44.0), ..., (5.0, 45.0))\n\n\n-1.43795\n0.410942\n0.398839\n0.126614\nQuadrangle((14.0, 50.0), ..., (14.0, 51.0))\n\n\n-0.723913\n2.42866\n0.784727\n1.16992\nQuadrangle((15.0, 50.0), ..., (15.0, 51.0))\n\n\n-0.0590989\n2.68622\n1.33679\n2.10909\nQuadrangle((22.0, 50.0), ..., (22.0, 51.0))\n\n\n-0.644966\n2.11815\n0.952599\n1.67868\nQuadrangle((23.0, 50.0), ..., (23.0, 51.0))\n\n\n-0.748535\n0.538293\n-0.612198\n-0.687015\nQuadrangle((24.0, 50.0), ..., (24.0, 51.0))\n\n\n-1.92414\n0.800529\n0.0323194\n-0.0645794\nQuadrangle((33.0, 50.0), ..., (33.0, 51.0))\n\n\n-0.336818\n0.102804\n-0.244382\n-0.786237\nQuadrangle((34.0, 50.0), ..., (34.0, 51.0))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nTo sort rows based on specific columns we can use the Sort transform:\n\ngt |&gt; Sort(\"a\", \"b\")\n\n\n10000×5 GeoTable over 10000 view(::CartesianGrid{2,Float64}, [6241, 9027, 5150, 9797, ..., 2460, 4904, 231, 3809])\n\n\na\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n-3.34343\n1.29855\n0.942431\n1.20178\nQuadrangle((40.0, 62.0), ..., (40.0, 63.0))\n\n\n-3.19009\n2.80169\n-0.802429\n-0.223875\nQuadrangle((26.0, 90.0), ..., (26.0, 91.0))\n\n\n-3.17163\n1.30201\n0.384205\n0.898489\nQuadrangle((49.0, 51.0), ..., (49.0, 52.0))\n\n\n-3.15446\n-1.16615\n0.662375\n0.146827\nQuadrangle((96.0, 97.0), ..., (96.0, 98.0))\n\n\n-3.02117\n-0.178384\n-1.11474\n-1.30934\nQuadrangle((44.0, 70.0), ..., (44.0, 71.0))\n\n\n-3.01695\n-2.02199\n-0.601168\n-1.15869\nQuadrangle((87.0, 88.0), ..., (87.0, 89.0))\n\n\n-2.97088\n-1.47881\n0.577583\n0.87073\nQuadrangle((13.0, 87.0), ..., (13.0, 88.0))\n\n\n-2.96375\n1.52573\n1.4759\n1.24844\nQuadrangle((43.0, 88.0), ..., (43.0, 89.0))\n\n\n-2.94834\n1.02418\n1.35101\n1.69183\nQuadrangle((52.0, 54.0), ..., (52.0, 55.0))\n\n\n-2.94802\n-1.13983\n-1.00186\n-0.264548\nQuadrangle((70.0, 89.0), ..., (70.0, 90.0))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nThis transform accepts all options of the sortperm function in Julia, including the option to sort in reverse order:\n\ngt |&gt; Sort(\"a\", \"b\", rev=true)\n\n\n10000×5 GeoTable over 10000 view(::CartesianGrid{2,Float64}, [3809, 231, 4904, 2460, ..., 9797, 5150, 9027, 6241])\n\n\na\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n13.2426\n-1.31104\n0.0176874\n0.153822\nQuadrangle((8.0, 38.0), ..., (8.0, 39.0))\n\n\n12.7754\n5.76736\n2.379\n2.37213\nQuadrangle((30.0, 2.0), ..., (30.0, 3.0))\n\n\n12.4384\n5.66928\n0.67864\n0.893031\nQuadrangle((3.0, 49.0), ..., (3.0, 50.0))\n\n\n12.0793\n1.53046\n2.08203\n2.66965\nQuadrangle((59.0, 24.0), ..., (59.0, 25.0))\n\n\n11.961\n0.804589\n1.45858\n1.65855\nQuadrangle((61.0, 23.0), ..., (61.0, 24.0))\n\n\n11.9552\n-4.62306\n0.880598\n-0.00540866\nQuadrangle((59.0, 47.0), ..., (59.0, 48.0))\n\n\n11.9397\n-1.89096\n-0.243373\n-0.506512\nQuadrangle((17.0, 41.0), ..., (17.0, 42.0))\n\n\n11.9397\n2.4938\n1.47133\n0.934706\nQuadrangle((17.0, 47.0), ..., (17.0, 48.0))\n\n\n11.8585\n-3.99108\n0.719185\n0.763016\nQuadrangle((19.0, 44.0), ..., (19.0, 45.0))\n\n\n11.6784\n-3.94576\n0.670165\n0.342244\nQuadrangle((4.0, 42.0), ..., (4.0, 43.0))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\n\n5.2.2 Cleaning\nSome feature transforms are used to clean the data before geostatistical analysis. For example, the StdNames transform can be used to standardize variable names that are not very readable due to file format limitations. To illustrate this transform, let’s create a geotable with unreadable variable names:\n\nut = gt |&gt; Select(\"a\" =&gt; \"aBc De-F\", \"b\" =&gt; \"b_2 (1)\")\n\n\n10000×3 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\naBc De-F\nb_2 (1)\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n6.98484\n0.0341826\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n7.62208\n-6.91411\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n1.07675\n-3.81989\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n7.19464\n4.02289\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n8.18491\n0.737772\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n7.31731\n-4.54177\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n4.35514\n-1.78341\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n2.90295\n-0.951305\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n3.01593\n-0.475414\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n9.02692\n-4.50934\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nWe can standardize the names with:\n\nut |&gt; StdNames()\n\n\n10000×3 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\nABC_DE_F\nB_2_1\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n6.98484\n0.0341826\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n7.62208\n-6.91411\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n1.07675\n-3.81989\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n7.19464\n4.02289\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n8.18491\n0.737772\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n7.31731\n-4.54177\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n4.35514\n-1.78341\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n2.90295\n-0.951305\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n3.01593\n-0.475414\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n9.02692\n-4.50934\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nBy default the transform, uses the :uppersnake naming convention. Other conventions can be specified depending on personal preference:\n\nut |&gt; StdNames(:uppercamel)\n\n\n10000×3 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\nAbcDeF\nB21\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n6.98484\n0.0341826\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n7.62208\n-6.91411\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n1.07675\n-3.81989\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n7.19464\n4.02289\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n8.18491\n0.737772\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n7.31731\n-4.54177\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n4.35514\n-1.78341\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n2.90295\n-0.951305\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n3.01593\n-0.475414\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n9.02692\n-4.50934\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\n\nut |&gt; StdNames(:upperflat)\n\n\n10000×3 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\nABCDEF\nB21\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n6.98484\n0.0341826\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n7.62208\n-6.91411\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n1.07675\n-3.81989\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n7.19464\n4.02289\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n8.18491\n0.737772\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n7.31731\n-4.54177\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n4.35514\n-1.78341\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n2.90295\n-0.951305\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n3.01593\n-0.475414\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n9.02692\n-4.50934\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nThe Replace transform can be used to replace specific values in the geotable by new values that are meaningful to the analysis:\n\ngt |&gt; Replace(-999 =&gt; missing, NaN =&gt; missing)\n\n\n10000×5 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\na\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n6.98484\n0.0341826\n0.413454\n0.203462\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n7.62208\n-6.91411\n1.22577\n1.53608\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n1.07675\n-3.81989\n0.989168\n1.00495\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n7.19464\n4.02289\n-0.52071\n-0.574699\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n8.18491\n0.737772\n-0.580056\n-0.541137\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n7.31731\n-4.54177\n1.81154\n1.56883\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n4.35514\n-1.78341\n-0.579144\n-1.06321\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n2.90295\n-0.951305\n-0.913929\n-1.51364\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n3.01593\n-0.475414\n-1.31362\n-1.15284\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n9.02692\n-4.50934\n-0.215652\n0.639203\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nAlthough it could be used to replace missing values by new values, there is a specific transform for this purpose named Coalesce:\n\nct = georef((a=[1,missing,3], b=[4,5,6])) |&gt; Coalesce(value=2)\n\n\n3×3 GeoTable over 3 CartesianGrid{1,Float64}\n\n\na\nb\ngeometry\n\n\nCount\nCount\nSegment\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n1\n4\nSegment((0.0,), (1.0,))\n\n\n2\n5\nSegment((1.0,), (2.0,))\n\n\n3\n6\nSegment((2.0,), (3.0,))\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nUnlike Replace, the Coalesce transform also changes the column type to make sure that no missing values can be stored in the future:\n\ntypeof(ct.a)\n\n\nVector{Int64} (alias for Array{Int64, 1})\n\n\n\n\n\nIn many applications, it is enough to simply drop all rows for which the selected column values are missing. This is the purpose of the DropMissing transform:\n\ngeoref((a=[1,missing,3], b=[4,5,6])) |&gt; DropMissing()\n\n\n2×3 GeoTable over 2 view(::CartesianGrid{1,Float64}, [1, 3])\n\n\na\nb\ngeometry\n\n\nCount\nCount\nSegment\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n1\n4\nSegment((0.0,), (1.0,))\n\n\n3\n6\nSegment((2.0,), (3.0,))\n\n\n\n\n\n\n\n5.2.3 Statistical\nThe framework provides various feature transforms for statistical analysis. We will cover some of these transforms in more detail in Part V of the book with real data. In the following examples we illustrate the most basic statistical transforms with synthetic data.\nThe Sample transform can be used to sample rows of the geotable at random, with or without replacement depending on the replace option. Other options are available such as rng to set the random number generator and ordered to preserve the order of rows in the original geotable:\n\ngt |&gt; Sample(1000, replace=false) |&gt; viewer\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSimilar to Filter and Sort, the Sample transform is lazy. It simply stores the indices of sampled rows for future construction of the new geotable.\n\n\nThe Center and Scale transforms can be used to standardize the range of values in a geotable. Aliases are provides for specific types of Scale such as MinMax and Interquartile. We can use the describe function to visualize basic statistics before and after the transforms:\n\ngt |&gt; describe\n\nTable with 6 columns and 4 rows:\n     variable  mean          minimum   median       maximum  nmissing\n   ┌─────────────────────────────────────────────────────────────────\n 1 │ a         2.99994       -3.34343  2.07112      13.2426  0\n 2 │ b         0.062872      -10.351   0.0381054    11.3182  0\n 3 │ c         -0.00449614   -3.85412  -0.0070347   3.42319  0\n 4 │ d         -0.000842125  -4.08132  -0.00440962  4.20215  0\n\n\n\ngt |&gt; Center(\"a\") |&gt; describe\n\nTable with 6 columns and 4 rows:\n     variable  mean          minimum   median       maximum  nmissing\n   ┌─────────────────────────────────────────────────────────────────\n 1 │ a         -5.23874e-15  -6.34336  -0.928814    10.2427  0\n 2 │ b         0.062872      -10.351   0.0381054    11.3182  0\n 3 │ c         -0.00449614   -3.85412  -0.0070347   3.42319  0\n 4 │ d         -0.000842125  -4.08132  -0.00440962  4.20215  0\n\n\n\ngt |&gt; MinMax() |&gt; describe\n\nTable with 6 columns and 4 rows:\n     variable  mean      minimum  median    maximum  nmissing\n   ┌─────────────────────────────────────────────────────────\n 1 │ a         0.382452  0.0      0.326452  1.0      0\n 2 │ b         0.480586  0.0      0.479443  1.0      0\n 3 │ c         0.52899   0.0      0.528641  1.0      0\n 4 │ d         0.492605  0.0      0.492174  1.0      0\n\n\nThe ZScore transform is similar to the Scale transform, but it uses the mean and the standard deviation to standardize the range:\n\ngt |&gt; ZScore() |&gt; describe\n\nTable with 6 columns and 4 rows:\n     variable  mean          minimum   median       maximum  nmissing\n   ┌─────────────────────────────────────────────────────────────────\n 1 │ a         -3.47278e-17  -1.87545  -0.274609    3.02831  0\n 2 │ b         1.35503e-17   -4.06508  -0.00966767  4.39351  0\n 3 │ c         2.03393e-17   -3.82186  -0.00252025  3.40297  0\n 4 │ d         1.57485e-17   -3.49279  -0.0030537   3.59766  0\n\n\nAnother important univariate transform is the Quantile transform, which can be used to convert empirical distribution in a column of the geotable to any given distribution from Distributions.jl by Lin et al. (2023). Selected columns are converted to a Normal distribution by default, but more than 60 distributions are available:\n\ngt |&gt; Quantile() |&gt; values |&gt; pairplot\n\n\n\n\nIn statistics, scientific types are used to link data types to adequate statistical algorithms. The most popular scientific types encountered in geoscientific applications are the Continuous and the Categorical scientific types. The latter can be further divided into Ordered and Multiclass. To convert (or coerce) the scientific types of columns in a geotable, we can use the Coerce transform:\n\nst = georef((a=[1,2,2,2,3,3], b=[1,2,3,4,5,6])) |&gt;\n     Coerce(\"a\" =&gt; Multiclass, \"b\" =&gt; Continuous)\n\n\n6×3 GeoTable over 6 CartesianGrid{1,Float64}\n\n\na\nb\ngeometry\n\n\nMulticlass\nContinuous\nSegment\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n1\n1.0\nSegment((0.0,), (1.0,))\n\n\n2\n2.0\nSegment((1.0,), (2.0,))\n\n\n2\n3.0\nSegment((2.0,), (3.0,))\n\n\n2\n4.0\nSegment((3.0,), (4.0,))\n\n\n3\n5.0\nSegment((4.0,), (5.0,))\n\n\n3\n6.0\nSegment((5.0,), (6.0,))\n\n\n\n\n\n\neltype(st.a)\n\nCategoricalValue{Int64, UInt32}\n\n\n\neltype(st.b)\n\nFloat64\n\n\n\n\n\n\n\n\nNote\n\n\n\nAll scientific types are documented in the ScientificTypes.jl module. We will see more examples in future chapters with real data from geoscientific applications.\n\n\nThe Levels transform can be used to adjust the categories (or levels) of Categorical columns in case the sampling process does not include all possible values:\n\nst = st |&gt; Levels(\"a\" =&gt; [1,2,3,4])\n\n\n6×3 GeoTable over 6 CartesianGrid{1,Float64}\n\n\na\nb\ngeometry\n\n\nMulticlass\nContinuous\nSegment\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n1\n1.0\nSegment((0.0,), (1.0,))\n\n\n2\n2.0\nSegment((1.0,), (2.0,))\n\n\n2\n3.0\nSegment((2.0,), (3.0,))\n\n\n2\n4.0\nSegment((3.0,), (4.0,))\n\n\n3\n5.0\nSegment((4.0,), (5.0,))\n\n\n3\n6.0\nSegment((5.0,), (6.0,))\n\n\n\n\n\n\nlevels(st.a)\n\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\n\nAnother popular transform in statistical learning is the OneHot transform. It converts a Categorical column into multiple columns of true/false values, one column for each level:\n\nst |&gt; OneHot(\"a\")\n\n\n6×6 GeoTable over 6 CartesianGrid{1,Float64}\n\n\na_1\na_2\na_3\na_4\nb\ngeometry\n\n\nCount\nCount\nCount\nCount\nContinuous\nSegment\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\ntrue\nfalse\nfalse\nfalse\n1.0\nSegment((0.0,), (1.0,))\n\n\nfalse\ntrue\nfalse\nfalse\n2.0\nSegment((1.0,), (2.0,))\n\n\nfalse\ntrue\nfalse\nfalse\n3.0\nSegment((2.0,), (3.0,))\n\n\nfalse\ntrue\nfalse\nfalse\n4.0\nSegment((3.0,), (4.0,))\n\n\nfalse\nfalse\ntrue\nfalse\n5.0\nSegment((4.0,), (5.0,))\n\n\nfalse\nfalse\ntrue\nfalse\n6.0\nSegment((5.0,), (6.0,))\n\n\n\n\n\nA similar transform for Continuous columns is the Indicator transform. It converts the column into multiple columns based on threshold values on the support of the data. By default, the threshold values are computed on a quantile scale:\n\nst |&gt; Indicator(\"b\", k=3, scale=:quantile)\n\n\n6×5 GeoTable over 6 CartesianGrid{1,Float64}\n\n\na\nb_1\nb_2\nb_3\ngeometry\n\n\nMulticlass\nCount\nCount\nCount\nSegment\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n1\ntrue\ntrue\ntrue\nSegment((0.0,), (1.0,))\n\n\n2\ntrue\ntrue\ntrue\nSegment((1.0,), (2.0,))\n\n\n2\nfalse\ntrue\ntrue\nSegment((2.0,), (3.0,))\n\n\n2\nfalse\ntrue\ntrue\nSegment((3.0,), (4.0,))\n\n\n3\nfalse\nfalse\ntrue\nSegment((4.0,), (5.0,))\n\n\n3\nfalse\nfalse\ntrue\nSegment((5.0,), (6.0,))\n\n\n\n\n\nMore advanced statistical transforms such as EigenAnalysis, PCA, DRS, SDS, ProjectionPursuit for multivariate data analysis and Remainder, Closure, LogRatio, ALR, CLR, ILR for compositional data analysis will be covered in future chapters."
  },
  {
    "objectID": "05-transforms.html#geometric-transforms",
    "href": "05-transforms.html#geometric-transforms",
    "title": "5  What are transforms?",
    "section": "5.3 Geometric transforms",
    "text": "5.3 Geometric transforms\nWhile feature transforms operate on the values of the geotable, geometric transforms operate on the geospatial domain. The framework provides various geometric transforms for 2D and 3D space.\n\n5.3.1 Coordinate\nA coordinate transform is a geometric transform that modifies the coordinates of all points in the domain without any advanced topological modification (i.e., connectivities are preserved). The most prominent examples of coordinate transforms are Translate, Rotate and Stretch.\nLet’s load an additional geotable to see these transforms in action:\n\nusing GeoIO\n\nbt = GeoIO.load(\"data/beethoven.ply\")\n\nviz(bt.geometry)\n\n\n\n\nThe Beethoven domain has been saved in the .ply file in a position that is not ideal for visualization. We can rotate this domain with any active rotation specification from Rotations.jl by Koolen et al. (2023) to improve the visualization. For example, we can specify that we want to rotate all points in the mesh by analogy with a rotation between coordinates (0, 1, 0) and coordinates (0, 0, 1):\n\nrt = bt |&gt; Rotate((0, 1, 0), (0, 0, 1))\n\nviz(rt.geometry)\n\n\n\n\nBeethoven is now standing up, but still facing the wall. Let’s rotate it once again by analogy between coordinates (1, 0, 0) and (-1, 1, 0):\n\nrt = rt |&gt; Rotate((1, 0, 0), (-1, 1, 0))\n\nviz(rt.geometry)\n\n\n\n\nRotation specifications are also available in 2D space. As an example, we can rotate the 2D grid of our synthetic geotable by the counter clockwise angle π/4:\n\ngt |&gt; Rotate(Angle2d(π/4)) |&gt; viewer\n\n\n\n\nIn GIS, this new geotable would be called a rotated “raster”. As another example, let’s translate the geotable to the origin of the coordinate system with the Translate transform:\n\nc = centroid(gt.geometry)\n\ngt |&gt; Translate(-coordinates(c)...) |&gt; viewer\n\n\n\n\nand stretch it with a positive factor for each dimension:\n\ngt |&gt; Stretch(0.1, 0.2) |&gt; viewer\n\n\n\n\nThe StdCoords transform combines Translate and Stretch to standardize the coordinates of the domain to the interval [-0.5, 0.5]:\n\ngt |&gt; StdCoords() |&gt; viewer\n\n\n\n\nIn GIS, another very important coordinate transform is the Proj transform. We will cover this transform in the next chapter because it depends on the concept of map projection, which deserves more attention.\n\n\n\n\n\n\nNote\n\n\n\nIn our framework, the Proj transform is just another coordinate transform. It is implemented with the same code optimizations, and can be used in conjunction with many other transforms that are not available elsewhere.\n\n\n\n\n5.3.2 Advanced\nAdvanced geometric transforms are provided that change the topology of the domain besides the coordinates of points. Some of these transforms can be useful to repair problematic geometries acquired from sensors in the real world.\nThe Repair transform is parameterized by an integer K that identifies the repair to be performed. For example, Repair{0}() is a transform that removes duplicated vertices and faces in a domain represented by a mesh. The Repair{9}() on the other hand fixes the orientation of rings in polygonal areas so that the external boundary is oriented counter clockwise and the inner boundaries are oriented clockwise. The list of available repairs will continue to grow with the implementation of new geometric algorithms in the framework.\nTo understand why geometric transforms are more general than coordinate transforms, let’s consider the following polygonal area with holes:\n\nouter = [(0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 1.0)]\nhole1 = [(0.2, 0.2), (0.4, 0.2), (0.4, 0.4), (0.2, 0.4)]\nhole2 = [(0.6, 0.2), (0.8, 0.2), (0.8, 0.4), (0.6, 0.4)]\npoly  = PolyArea([outer, hole1, hole2])\n\nviz(poly)\n\n\n\n\nWe can connect the holes with the external boundary (or ring) using the Bridge transform:\n\npoly |&gt; Bridge(0.01) |&gt; viz\n\n\n\n\nBy looking at the visualization, we observe that the number of vertices changed to accommodate the so called “bridges” between the rings. The topology also changed as there are no holes in the resulting geometry.\nAs a final example of advanced geometric transform, we illustrate the TaubinSmoothing transform, which gradually removes sharp boundaries of a manifold mesh:\n\nst = bt |&gt; TaubinSmoothing(30)\n\nfig = Mke.Figure()\nviz(fig[1,1], bt.geometry)\nviz(fig[1,2], st.geometry)\nfig\n\n\n\n\nFor more advanced geometric transforms, please consult the official documentation."
  },
  {
    "objectID": "05-transforms.html#geospatial-transforms",
    "href": "05-transforms.html#geospatial-transforms",
    "title": "5  What are transforms?",
    "section": "5.4 Geospatial transforms",
    "text": "5.4 Geospatial transforms\nGeospatial transforms are those transforms that operate on both the values and the domain of the geotable. They are common in geostatistical workflows that need to remove geospatial “trends” or workflows that need to extract geometries from domains.\nAs an example, let’s consider the following geotable with a variable z that made of a trend component μ and a noise component ϵ:\n\n# quadratic + noise\nr = range(-1, stop=1, length=100)\nμ = [x^2 + y^2 for x in r, y in r]\nϵ = 0.1rand(100, 100)\nt = georef((z=μ+ϵ,))\n\nviewer(t)\n\n\n\n\nWe can use the Detrend transform to remove a trend of polynomial degree 2:\n\nt |&gt; Detrend(degree=2) |&gt; viewer\n\n\n\n\nThe remaining component can then be modeled with geostatistical models of geospatial correlation.\nModels of geospatial correlation such as variograms (Hoffimann and Zadrozny 2019) require unique coordinates in the geotable and that is the purpose of the UniqueCoords transform. It removes duplicate points in the geotable and aggregates the values with custom aggregation functions.\nLet’s consider the following geotable stored in a .png file to illustrate another geospatial transform:\n\nletters = GeoIO.load(\"data/letters.png\")\n\n\n44255×2 GeoTable over 167×265 CartesianGrid{2,Float64}\n\n\ncolor\ngeometry\n\n\nUnknown\nQuadrangle\n\n\n[NoUnits]\n\n\n\n\n\nGray{N0f8}(1.0)\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\nGray{N0f8}(1.0)\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\nGray{N0f8}(1.0)\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\nGray{N0f8}(1.0)\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\nGray{N0f8}(1.0)\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\nGray{N0f8}(1.0)\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\nGray{N0f8}(1.0)\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\nGray{N0f8}(1.0)\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\nGray{N0f8}(1.0)\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\nGray{N0f8}(1.0)\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n\n\n\n\n\nThe Potrace transform can be used to extract complex geometries from a geotable over a 2D Grid. It transforms the Grid domain into a GeometrySet based on any column that contains a discrete set of marker values. In this example, we use the color as the column with markers:\n\nAb = letters |&gt; Potrace(\"color\", ϵ=0.8)\n\n\n2×2 GeoTable over 2 GeometrySet{2,Float64}\n\n\ncolor\ngeometry\n\n\nUnknown\nMultiPolygon\n\n\n[NoUnits]\n\n\n\n\n\nGray{N0f8}(1.0)\nMulti(4×PolyArea)\n\n\nGray{N0f8}(0.0)\nMulti(2×PolyArea)\n\n\n\n\n\nThe option ϵ controls the deviation tolerance used to simplify the boundaries of the geometries. The higher is the tolerance, the less is the number of segments in the boundary:\n\nviz(Ab.geometry[2], color = \"black\")\n\n\n\n\nIn the reverse direction, we have the Rasterize transform, which takes a geotable over a GeometrySet and assigns the geometries to a Grid. In this transform, we can either provide an external grid for the the assignments, or request a grid size to discretize the boundingbox of all geometries:\n\nA = [1, 2, 3, 4, 5]\nB = [1.1, 2.2, 3.3, 4.4, 5.5]\np1 = PolyArea((2, 0), (6, 2), (2, 2))\np2 = PolyArea((0, 6), (3, 8), (0, 10))\np3 = PolyArea((3, 6), (9, 6), (9, 9), (6, 9))\np4 = PolyArea((7, 0), (10, 0), (10, 4), (7, 4))\np5 = PolyArea((1, 3), (5, 3), (6, 6), (3, 8), (0, 6))\ngt = georef((; A, B), [p1, p2, p3, p4, p5])\n\n\n5×3 GeoTable over 5 GeometrySet{2,Float64}\n\n\nA\nB\ngeometry\n\n\nCount\nContinuous\nPolyArea\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n1\n1.1\nPolyArea((2.0, 0.0), (6.0, 2.0), (2.0, 2.0))\n\n\n2\n2.2\nPolyArea((0.0, 6.0), (3.0, 8.0), (0.0, 10.0))\n\n\n3\n3.3\nPolyArea((3.0, 6.0), ..., (6.0, 9.0))\n\n\n4\n4.4\nPolyArea((7.0, 0.0), ..., (7.0, 4.0))\n\n\n5\n5.5\nPolyArea((1.0, 3.0), ..., (0.0, 6.0))\n\n\n\n\n\n\ngt |&gt; viewer\n\n\n\n\n\nnt = gt |&gt; Rasterize(20, 20)\n\n\n400×3 GeoTable over 20×20 CartesianGrid{2,Float64}\n\n\nA\nB\ngeometry\n\n\nCount\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\nmissing\nmissing\nQuadrangle((0.0, 0.0), ..., (0.0, 0.5))\n\n\nmissing\nmissing\nQuadrangle((0.5, 0.0), ..., (0.5, 0.5))\n\n\nmissing\nmissing\nQuadrangle((1.0, 0.0), ..., (1.0, 0.5))\n\n\n1\n1.1\nQuadrangle((1.5, 0.0), ..., (1.5, 0.5))\n\n\n1\n1.1\nQuadrangle((2.0, 0.0), ..., (2.0, 0.5))\n\n\nmissing\nmissing\nQuadrangle((2.5, 0.0), ..., (2.5, 0.5))\n\n\nmissing\nmissing\nQuadrangle((3.0, 0.0), ..., (3.0, 0.5))\n\n\nmissing\nmissing\nQuadrangle((3.5, 0.0), ..., (3.5, 0.5))\n\n\nmissing\nmissing\nQuadrangle((4.0, 0.0), ..., (4.0, 0.5))\n\n\nmissing\nmissing\nQuadrangle((4.5, 0.0), ..., (4.5, 0.5))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\n\nnt |&gt; viewer\n\n\n\n\nThe values of the variables are aggregated at geometric intersections using a default aggregation function, which can be overwritten with an option."
  },
  {
    "objectID": "05-transforms.html#remarks",
    "href": "05-transforms.html#remarks",
    "title": "5  What are transforms?",
    "section": "5.5 Remarks",
    "text": "5.5 Remarks\nIn this chapter we learned the important concept of transforms, and saw examples of the concept in action with synthetic data. In order to leverage the large number of transforms implemented in the framework, all we need to do is load our geospatial data as a geotable using georef or GeoIO.jl.\nSome additional remarks:\n\nOne of the major advantages of transforms compared to traditional row/column access in data science is that they preserve geospatial information. There is no need to keep track of indices in arrays to repeatedly reattach attributes to geometries.\nTransforms can be organized into three classes—feature, geometric and geospatial—depending on how they operate with the values and the domain of the geotable:\n\nFeature transforms operate on the values. They include column selection, data cleaning, statistical analysis and any transform designed for traditional Tables.jl.\nGeometric transforms operate on the domain. They include coordinate transforms that simply modify the coordinates of points as well as more advanced transforms that can change the topology of the domain.\nGeospatial transforms operate on both the values and domain. They include geostatistical transforms and transforms that use other columns besides the geometry column to produce new columns and geometries.\n\n\nIn the next chapters, we will review map projections with the Proj coordinate transform, and will introduce one of the greatest features of the framework known as transform pipelines.\n\n\n\n\nHoffimann, Júlio, and Bianca Zadrozny. 2019. “Efficient Variography with Partition Variograms.” Computers & Geosciences 131: 52–59. https://doi.org/https://doi.org/10.1016/j.cageo.2019.06.013.\n\n\nKoolen, Twan, Yuto Horikawa, Andy Ferris, Claire Foster, awbsmith, ryanelandt, Jan Weidner, et al. 2023. “JuliaGeometry/Rotations.jl: V1.6.0.” Zenodo. https://doi.org/10.5281/zenodo.8366010.\n\n\nLin, Dahua, David Widmann, Simon Byrne, John Myles White, Andreas Noack, Mathieu Besançon, Douglas Bates, et al. 2023. “JuliaStats/Distributions.jl: V0.25.100.” Zenodo. https://doi.org/10.5281/zenodo.8224988.\n\n\nThompson, William. 2023. “PairPlots.jl Beautiful and Flexible Visualizations of High Dimensional Data.” https://sefffal.github.io/PairPlots.jl/dev."
  },
  {
    "objectID": "06-projections.html#coming-soon",
    "href": "06-projections.html#coming-soon",
    "title": "6  Map projections 🚧",
    "section": "6.1 Coming soon…",
    "text": "6.1 Coming soon…"
  },
  {
    "objectID": "07-pipelines.html#motivation",
    "href": "07-pipelines.html#motivation",
    "title": "7  Building pipelines",
    "section": "7.1 Motivation",
    "text": "7.1 Motivation\nThe pipe operator |&gt; in Julia is very convenient for sequential application of functions. Given an input x, we can type x |&gt; f1 |&gt; f2 to apply functions f1 and f2 in sequence, in a way that is equivalent to f2(f1(x)) or, alternatively, to the function composition (f2 ∘ f1)(x). Its syntax can drastically improve code readability when the number of functions is large. However, the operator has a major limitation in the context of geospatial data science: it evaluates all intermediate results as soon as the data is inserted in the pipe. This is known in computer science as eager evaluation.\nTaking the expression above as an example, the operator will first evaluate f1(x) and store the result in a variable y. After f1 is completed, the operator evaluates f2(y) and produces the final (desired) result. If y requires a lot of computer memory as it is usually the case with large geotables, the application of the pipeline will be slow.\nAnother evaluation strategy known as lazy evaluation consists of building the entire pipeline without the data in it. The major advantage of this strategy is that it can analyze the functions, and potentially simplify the code before evaluation. For example, the pipeline cos → acos can be replaced by the much simpler pipeline identity for some values of the input x."
  },
  {
    "objectID": "07-pipelines.html#operator",
    "href": "07-pipelines.html#operator",
    "title": "7  Building pipelines",
    "section": "7.2 Operator →",
    "text": "7.2 Operator →\nIn our framework, the operator → (\\to) can be used in place of the pipe operator to build lazy sequential pipelines of transforms. Consider the synthetic data from previous chapters:\n\nN = 10000\na = [2randn(N÷2) .+ 6; randn(N÷2)]\nb = [3randn(N÷2); 2randn(N÷2)]\nc = randn(N)\nd = c .+ 0.6randn(N)\n\ntable = (; a, b, c, d)\n\ngt = georef(table, CartesianGrid(100, 100))\n\n\n10000×5 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\na\nb\nc\nd\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n8.5109\n0.995941\n1.71858\n2.50795\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n3.49437\n-3.1502\n2.13328\n2.60452\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n8.84509\n-2.06269\n-0.452039\n0.426248\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n7.62549\n-6.38564\n0.864074\n0.159124\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n8.00415\n-1.24954\n2.21769\n2.38668\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n6.55002\n-3.15018\n-0.279288\n-1.35894\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n1.71931\n-1.40909\n1.55002\n2.18869\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n4.82119\n0.302061\n-1.72918\n-2.08988\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n4.84219\n0.494943\n-0.17475\n-0.037001\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n7.94907\n5.54154\n0.176957\n0.671871\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nAnd suppose that we are interested in converting the columns “a”, “b” and “c” of the geotable with the Quantile transform. Instead of creating the intermediate geotable with the Select transform, and then sending the result to the Quantile transform, we can create the entire pipeline without reference to the data:\n\npipeline = Select(\"a\", \"b\", \"c\") → Quantile()\n\nSequentialTransform\n├─ Select([:a, :b, :c], nothing)\n└─ Quantile(all, Distributions.Normal{Float64}(μ=0.0, σ=1.0))\n\n\nThe operator → creates a special SequentialTransform, which can be applied like any other transform in the framework:\n\ngt |&gt; pipeline\n\n\n10000×4 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\na\nb\nc\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n1.65463\n0.437981\n1.74491\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n0.133497\n-1.25192\n2.12245\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n1.79785\n-0.848427\n-0.444889\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n1.25853\n-2.36152\n0.856358\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n1.4166\n-0.524976\n2.20864\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n0.85419\n-1.25137\n-0.284014\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n-0.0300841\n-0.593271\n1.57351\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n0.358726\n0.129452\n-1.71036\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n0.364613\n0.217267\n-0.184017\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n1.39904\n2.15707\n0.161119\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nIt will perform optimizations whenever possible. For instance, we know a priori that adding the Identity transform anywhere in the pipeline doesn’t have any effect:\n\npipeline → Identity()\n\nSequentialTransform\n├─ Select([:a, :b, :c], nothing)\n└─ Quantile(all, Distributions.Normal{Float64}(μ=0.0, σ=1.0))"
  },
  {
    "objectID": "07-pipelines.html#operator-1",
    "href": "07-pipelines.html#operator-1",
    "title": "7  Building pipelines",
    "section": "7.3 Operator ⊔",
    "text": "7.3 Operator ⊔\nThe operator ⊔ (\\sqcup) can be used to create lazy parallel transforms. There is no equivalent in Julia as this operator is very specific to tables. It combines the geotables produced by two or more pipelines into a single geotable with the disjoint union of all columns.\nLet’s illustrate this concept with two pipelines:\n\npipeline1 = Select(\"a\") → Indicator(\"a\", k=3)\n\nSequentialTransform\n├─ Select([:a], nothing)\n└─ Indicator(:a, 3, :quantile, false)\n\n\n\npipeline2 = Select(\"b\", \"c\", \"d\") → PCA(maxdim=2)\n\nSequentialTransform\n├─ Select([:b, :c, :d], nothing)\n├─ ZScore(all)\n└─ EigenAnalysis(:V, 2, 1.0)\n\n\nThe first pipeline creates 3 indicator variables from variable “a”:\n\ngt |&gt; pipeline1\n\n\n10000×4 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\na_1\na_2\na_3\ngeometry\n\n\nCount\nCount\nCount\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\nfalse\nfalse\ntrue\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\nfalse\ntrue\ntrue\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\nfalse\nfalse\ntrue\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\nfalse\nfalse\ntrue\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\nfalse\nfalse\ntrue\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\nfalse\nfalse\ntrue\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\nfalse\ntrue\ntrue\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\nfalse\ntrue\ntrue\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\nfalse\ntrue\ntrue\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\nfalse\nfalse\ntrue\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nThe second pipeline runs principal component analysis with variables “b”, “c” and “d” and produces 2 principal components:\n\ngt |&gt; pipeline2\n\n\n10000×3 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\nPC1\nPC2\ngeometry\n\n\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n-2.7209\n0.450194\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n-3.09885\n-1.17378\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n0.0480325\n-0.797561\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n-0.746417\n-2.48645\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n-3.01409\n-0.428674\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n0.998936\n-1.24426\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n-2.42479\n-0.500264\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n2.48565\n0.0893891\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n0.149614\n0.204686\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n-0.493878\n2.19952\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nWe can combine the two pipelines into a single pipeline that executes in parallel:\n\npipeline = pipeline1 ⊔ pipeline2\n\nParallelTableTransform\n├─ SequentialTransform\n│  ├─ Select([:a], nothing)\n│  └─ Indicator(:a, 3, :quantile, false)\n└─ SequentialTransform\n   ├─ Select([:b, :c, :d], nothing)\n   ├─ ZScore(all)\n   └─ EigenAnalysis(:V, 2, 1.0)\n\n\n\ngt |&gt; pipeline\n\n\n10000×6 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\na_1\na_2\na_3\nPC1\nPC2\ngeometry\n\n\nCount\nCount\nCount\nContinuous\nContinuous\nQuadrangle\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\nfalse\nfalse\ntrue\n-2.7209\n0.450194\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\nfalse\ntrue\ntrue\n-3.09885\n-1.17378\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\nfalse\nfalse\ntrue\n0.0480325\n-0.797561\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\nfalse\nfalse\ntrue\n-0.746417\n-2.48645\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\nfalse\nfalse\ntrue\n-3.01409\n-0.428674\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\nfalse\nfalse\ntrue\n0.998936\n-1.24426\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\nfalse\ntrue\ntrue\n-2.42479\n-0.500264\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\nfalse\ntrue\ntrue\n2.48565\n0.0893891\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\nfalse\ntrue\ntrue\n0.149614\n0.204686\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\nfalse\nfalse\ntrue\n-0.493878\n2.19952\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nAll 5 columns are present in the final geotable."
  },
  {
    "objectID": "07-pipelines.html#revertibility",
    "href": "07-pipelines.html#revertibility",
    "title": "7  Building pipelines",
    "section": "7.4 Revertibility",
    "text": "7.4 Revertibility\nAn important concept related to pipelines that is very useful in geospatial data science is revertibility. The concept is useful whenever we need to answer geoscientific questions in terms of variables that have been transformed for geostatistical analysis.\nLet’s illustrate the concept with the following geotable and pipeline:\n\na = [-1.0, 4.0, 1.6, 3.4]\nb = [1.6, 3.4, -1.0, 4.0]\nc = [3.4, 2.0, 3.6, -1.0]\ntable = (; a, b, c) \n\ngeotable = georef(table, rand(2, 4))\n\n\n4×4 GeoTable over 4 PointSet{2,Float64}\n\n\na\nb\nc\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nPoint2\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n-1.0\n1.6\n3.4\n(0.684618, 0.26386)\n\n\n4.0\n3.4\n2.0\n(0.331032, 0.420939)\n\n\n1.6\n-1.0\n3.6\n(0.0368274, 0.500792)\n\n\n3.4\n4.0\n-1.0\n(0.408369, 0.614134)\n\n\n\n\n\n\npipeline = Select(\"a\") → Center()\n\nSequentialTransform\n├─ Select([:a], nothing)\n└─ Center(all)\n\n\nWe saw that our pipelines can be evaluated with Julia’s pipe operator:\n\ngeotable |&gt; pipeline\n\n\n4×2 GeoTable over 4 PointSet{2,Float64}\n\n\na\ngeometry\n\n\nContinuous\nPoint2\n\n\n[NoUnits]\n\n\n\n\n\n-3.0\n(0.684618, 0.26386)\n\n\n2.0\n(0.331032, 0.420939)\n\n\n-0.4\n(0.0368274, 0.500792)\n\n\n1.4\n(0.408369, 0.614134)\n\n\n\n\n\nIn order to revert a pipeline, however; we need to save auxiliary constants that were used to transform the data (e.g., mean of selected columns). The apply function serves this purpose:\n\nnewtable, cache = apply(pipeline, geotable)\n\nnewtable\n\n\n4×2 GeoTable over 4 PointSet{2,Float64}\n\n\na\ngeometry\n\n\nContinuous\nPoint2\n\n\n[NoUnits]\n\n\n\n\n\n-3.0\n(0.684618, 0.26386)\n\n\n2.0\n(0.331032, 0.420939)\n\n\n-0.4\n(0.0368274, 0.500792)\n\n\n1.4\n(0.408369, 0.614134)\n\n\n\n\n\nThe function produces the new geotable as usual and an additional cache with all the information needed to revert the transforms in the pipeline. We say that a pipeline isrevertible, if there is an efficient way to revert its transforms starting from any geotable that has the same schema of the geotable produced by the apply function:\n\nisrevertible(pipeline)\n\ntrue\n\n\n\nrevert(pipeline, newtable, cache)\n\n\n4×4 GeoTable over 4 PointSet{2,Float64}\n\n\na\nb\nc\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nPoint2\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n-1.0\n1.6\n3.4\n(0.684618, 0.26386)\n\n\n4.0\n3.4\n2.0\n(0.331032, 0.420939)\n\n\n1.6\n-1.0\n3.6\n(0.0368274, 0.500792)\n\n\n3.4\n4.0\n-1.0\n(0.408369, 0.614134)\n\n\n\n\n\nA very common workflow in geospatial data science consists of:\n\nTransforming the data to an appropriate sample space for geostatistical analysis\nDoing additional modeling to predict variables in new geospatial locations\nReverting the modeling results with the saved pipeline and cache\n\nWe will see examples of this workflow in Part V of the book."
  },
  {
    "objectID": "07-pipelines.html#congratulations",
    "href": "07-pipelines.html#congratulations",
    "title": "7  Building pipelines",
    "section": "7.5 Congratulations!",
    "text": "7.5 Congratulations!\nCongratulations on finishing Part II of the book. Let’s quickly review what we learned so far:\n\nTransforms and pipelines are powerful tools to achieve reproducible geospatial data science.\nThe operators → and ⊔ can be used to build lazy pipelines. After a pipeline is built, it can be applied to different geotables, which may have different types of geospatial domain.\nLazy pipelines can always be optimized for computational performance, and the Julia language really thrives to dispatch the appropriate optimizations when they are available.\nMap projections are specific types of coordinate transforms. They can be combined with many other transforms in the framework to produce advanced geostatistical visualizations.\n\nThere is a long journey until the technology reaches its full potential. The good news is that Julia code is really easy to read and modify, and you can become an active contributor after just a few weeks working with the language. We invite you to contribute new transforms and optimizations as soon as you feel comfortable with the framework."
  },
  {
    "objectID": "08-splitcombine.html#motivation",
    "href": "08-splitcombine.html#motivation",
    "title": "8  Split-apply-combine",
    "section": "8.1 Motivation",
    "text": "8.1 Motivation\nIn geospatial data science, geoscientific questions are often posed in terms of both the values and the domain of a geotable. For example:\n\nWhere are the areas with high probability of landslide?\nWhat is the average rainfall per watershed over the last year?\nHow much lithium will be mined from each geological unit?\nWhat is the variation of log-permeability per depositional facies?\n\nThe word “where” is often present in these questions to indicate that answers must be georeferenced. If the variable of interest is already present in the geotable, then we can effectively answer “where” questions using the viewer and the Filter transform from previous chapters:\ngeotable |&gt; Filter(row -&gt; row.probability &gt; 0.9) |&gt; viewer\nIf the variable of interest is not present in the geotable, or if the “where” word is not present in the original question, then there will be some reference to “geospatial units” on which geostatistics must be computed. These questions can be answered with a geospatial version of the split-apply-combine strategy (Wickham 2011) from data science. Our framework provides the @groupby, @transform and @combine macros to split-apply-combine geotables."
  },
  {
    "objectID": "08-splitcombine.html#bonnie-data-set",
    "href": "08-splitcombine.html#bonnie-data-set",
    "title": "8  Split-apply-combine",
    "section": "8.2 Bonnie data set",
    "text": "8.2 Bonnie data set\nWe will use the Bonnie data set to illustrate our geospatial split-apply-combine:\n\nThe Bonnie Project Example is under copyright of Transmin Metallurgical Consultants, 2019. It is issued under the Creative Commons Attribution-ShareAlike 4.0 International Public License.\n\n\nusing CSV\n\ngt = georef(CSV.File(\"data/bonnie.csv\"), (:EAST, :NORTH, :RL))\n\n\n19618×9 GeoTable over 19618 PointSet{3,Float64}\n\n\nAuppm\nAgppm\nCuppm\nAsppm\nSper\nCODE\nOX\nISBD\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nTextual\nTextual\nContinuous\nPoint3\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n0.407\n2.335\n1311.0\n27.0\n0.01\nC1\nTR1\n2.42\n(243940.0, 1.00223e6, 1855.0)\n\n\n0.407\n2.335\n1311.0\n27.0\n0.01\nC1\nTR1\n1.98\n(243945.0, 1.00223e6, 1855.0)\n\n\n0.407\n2.335\n1311.0\n27.0\n0.01\nC1\nTR1\n2.068\n(243950.0, 1.00226e6, 1855.0)\n\n\n0.385\n2.1\n572.0\n0.0\n0.0\nC1\nTR1\n2.222\n(243965.0, 1.00226e6, 1855.0)\n\n\n0.385\n2.1\n572.0\n0.0\n0.0\nC1\nTR1\n2.156\n(243970.0, 1.00226e6, 1855.0)\n\n\n0.385\n2.1\n572.0\n0.0\n0.0\nC1\nOX1\n2.08\n(243960.0, 1.00227e6, 1855.0)\n\n\n0.385\n2.1\n572.0\n0.0\n0.0\nC1\nOX1\n2.06\n(243965.0, 1.00227e6, 1855.0)\n\n\n0.385\n2.1\n572.0\n0.0\n0.0\nC1\nOX1\n1.9\n(243970.0, 1.00227e6, 1855.0)\n\n\n0.42152\n1.422\n852.36\n22.85\n2.4078\nC1\nTR1\n2.024\n(243930.0, 1.00222e6, 1860.0)\n\n\n0.41747\n1.429\n832.36\n21.87\n1.9388\nC1\nTR1\n2.112\n(243935.0, 1.00222e6, 1860.0)\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nIt represents a 3D mineral deposit with grades in parts per million (ppm), sulfur contaminant in percent, and other categorical variables with geological and lithological units:\n\nnames(gt)\n\n9-element Vector{String}:\n \"Auppm\"\n \"Agppm\"\n \"Cuppm\"\n \"Asppm\"\n \"Sper\"\n \"CODE\"\n \"OX\"\n \"ISBD\"\n \"geometry\"\n\n\nThe “EAST”, “NORTH” and “RL” coordinates used to georef the CSV file represent the centroids of the mining blocks. The sides of these blocks are provided as metadata (e.g., 5x5x5):\n\ngt |&gt; viewer\n\n\n\n\nLet’s clean the geotable using what we learned in previous chapters. We will reject the column with sulfur, will drop missing values, will rename the variables for greater readability, and will change the scientific type of geological and lithological units:\n\nclean = Reject(\"Sper\") →\n        DropMissing() →\n        Rename(\"Auppm\" =&gt; \"Au\", \"Agppm\" =&gt; \"Ag\",\n               \"Cuppm\" =&gt; \"Cu\", \"Asppm\" =&gt; \"As\",\n               \"CODE\" =&gt; \"geo\", \"OX\" =&gt; \"litho\",\n               \"ISBD\" =&gt; \"ρ\") →\n        Coerce(\"geo\" =&gt; Multiclass,\n               \"litho\" =&gt; Multiclass)\n\ngt = gt |&gt; clean\n\n\n19548×8 GeoTable over 19548 view(::PointSet{3,Float64}, [1, 2, 3, 4, ..., 19615, 19616, 19617, 19618])\n\n\nAu\nAg\nCu\nAs\ngeo\nlitho\nρ\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nMulticlass\nMulticlass\nContinuous\nPoint3\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n0.407\n2.335\n1311.0\n27.0\nC1\nTR1\n2.42\n(243940.0, 1.00223e6, 1855.0)\n\n\n0.407\n2.335\n1311.0\n27.0\nC1\nTR1\n1.98\n(243945.0, 1.00223e6, 1855.0)\n\n\n0.407\n2.335\n1311.0\n27.0\nC1\nTR1\n2.068\n(243950.0, 1.00226e6, 1855.0)\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nTR1\n2.222\n(243965.0, 1.00226e6, 1855.0)\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nTR1\n2.156\n(243970.0, 1.00226e6, 1855.0)\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nOX1\n2.08\n(243960.0, 1.00227e6, 1855.0)\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nOX1\n2.06\n(243965.0, 1.00227e6, 1855.0)\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nOX1\n1.9\n(243970.0, 1.00227e6, 1855.0)\n\n\n0.42152\n1.422\n852.36\n22.85\nC1\nTR1\n2.024\n(243930.0, 1.00222e6, 1860.0)\n\n\n0.41747\n1.429\n832.36\n21.87\nC1\nTR1\n2.112\n(243935.0, 1.00222e6, 1860.0)\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nThat is a lot better! Let’s assume that we want to answer the following business question:\nWhat is the total mass of gold that will be mined from each geological unit?"
  },
  {
    "objectID": "08-splitcombine.html#splitting-geotables",
    "href": "08-splitcombine.html#splitting-geotables",
    "title": "8  Split-apply-combine",
    "section": "8.3 Splitting geotables",
    "text": "8.3 Splitting geotables\nWe can split geotables into lazy geospatial partitions based on values stored in a column. In this case, we want to split the mineral deposit in geological units stored in the geo column:\n\ngroups = @groupby(gt, \"geo\")\n\n2 Partition\n├─ 17153×8 SubGeoTable over 17153 view(::PointSet{3,Float64}, [1, 2, 3, 4, ..., 17203, 17204, 17205, 17206])\n└─ 2395×8 SubGeoTable over 2395 view(::PointSet{3,Float64}, [17207, 17208, 17209, 17210, ..., 19615, 19616, 19617, 19618])\nmetadata: rows, names\n\n\nThere are two geological units in this deposit, represented as SubGeoTable. We can access these units by indexing into the geospatial partition:\n\ngroups[1]\n\n\n17153×8 SubGeoTable over 17153 view(::PointSet{3,Float64}, [1, 2, 3, 4, ..., 17203, 17204, 17205, 17206])\n\n\nAu\nAg\nCu\nAs\ngeo\nlitho\nρ\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nMulticlass\nMulticlass\nContinuous\nPoint3\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n0.407\n2.335\n1311.0\n27.0\nC1\nTR1\n2.42\n(243940.0, 1.00223e6, 1855.0)\n\n\n0.407\n2.335\n1311.0\n27.0\nC1\nTR1\n1.98\n(243945.0, 1.00223e6, 1855.0)\n\n\n0.407\n2.335\n1311.0\n27.0\nC1\nTR1\n2.068\n(243950.0, 1.00226e6, 1855.0)\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nTR1\n2.222\n(243965.0, 1.00226e6, 1855.0)\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nTR1\n2.156\n(243970.0, 1.00226e6, 1855.0)\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nOX1\n2.08\n(243960.0, 1.00227e6, 1855.0)\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nOX1\n2.06\n(243965.0, 1.00227e6, 1855.0)\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nOX1\n1.9\n(243970.0, 1.00227e6, 1855.0)\n\n\n0.42152\n1.422\n852.36\n22.85\nC1\nTR1\n2.024\n(243930.0, 1.00222e6, 1860.0)\n\n\n0.41747\n1.429\n832.36\n21.87\nC1\nTR1\n2.112\n(243935.0, 1.00222e6, 1860.0)\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\nviz(groups[1].geometry, color = \"teal\")\nviz!(groups[2].geometry, color = \"slategray3\")\nMke.current_figure()"
  },
  {
    "objectID": "08-splitcombine.html#applying-expressions",
    "href": "08-splitcombine.html#applying-expressions",
    "title": "8  Split-apply-combine",
    "section": "8.4 Applying expressions",
    "text": "8.4 Applying expressions\nThe mass of gold in a mining block is a function of the gold grade (Au), the rock density (ρ), and the volume of the block:\n\\[\nm = Au \\times \\rho \\times V\n\\]\nLet’s use an auxiliary function to convert the Points in the geometry column into Boxes of sides 5x5x5. The function takes a centroid point as input and produces a box centered at the point with corners that are 2.5x2.5x2.5 units away in both directions:\n\nbox(point) = Box(point - Vec(2.5, 2.5, 2.5), point + Vec(2.5, 2.5, 2.5))\n\nbox (generic function with 1 method)\n\n\n\nbox.(gt.geometry)\n\n19548-element Vector{Box{3, Float64}}:\n Box(min: (2.43938e5, 1.00223e6, 1852.5), max: (2.43942e5, 1.00223e6, 1857.5))\n Box(min: (2.43942e5, 1.00223e6, 1852.5), max: (2.43948e5, 1.00223e6, 1857.5))\n Box(min: (2.43948e5, 1.00226e6, 1852.5), max: (2.43952e5, 1.00226e6, 1857.5))\n Box(min: (2.43962e5, 1.00226e6, 1852.5), max: (2.43968e5, 1.00226e6, 1857.5))\n Box(min: (2.43968e5, 1.00226e6, 1852.5), max: (2.43972e5, 1.00226e6, 1857.5))\n Box(min: (2.43958e5, 1.00227e6, 1852.5), max: (2.43962e5, 1.00227e6, 1857.5))\n Box(min: (2.43962e5, 1.00227e6, 1852.5), max: (2.43968e5, 1.00227e6, 1857.5))\n Box(min: (2.43968e5, 1.00227e6, 1852.5), max: (2.43972e5, 1.00227e6, 1857.5))\n Box(min: (2.43928e5, 1.00222e6, 1857.5), max: (2.43932e5, 1.00222e6, 1862.5))\n Box(min: (2.43932e5, 1.00222e6, 1857.5), max: (2.43938e5, 1.00222e6, 1862.5))\n Box(min: (2.43938e5, 1.00222e6, 1857.5), max: (2.43942e5, 1.00222e6, 1862.5))\n Box(min: (2.43942e5, 1.00222e6, 1857.5), max: (2.43948e5, 1.00222e6, 1862.5))\n Box(min: (2.43912e5, 1.00223e6, 1857.5), max: (2.43918e5, 1.00223e6, 1862.5))\n ⋮\n Box(min: (2.43782e5, 1.0022e6, 2027.5), max: (2.43788e5, 1.0022e6, 2032.5))\n Box(min: (2.43788e5, 1.0022e6, 2027.5), max: (2.43792e5, 1.0022e6, 2032.5))\n Box(min: (2.43792e5, 1.0022e6, 2027.5), max: (2.43798e5, 1.0022e6, 2032.5))\n Box(min: (2.43752e5, 1.00221e6, 2027.5), max: (2.43758e5, 1.00221e6, 2032.5))\n Box(min: (2.43758e5, 1.00221e6, 2027.5), max: (2.43762e5, 1.00221e6, 2032.5))\n Box(min: (2.43762e5, 1.00221e6, 2027.5), max: (2.43768e5, 1.00221e6, 2032.5))\n Box(min: (2.43768e5, 1.00221e6, 2027.5), max: (2.43772e5, 1.00221e6, 2032.5))\n Box(min: (2.43772e5, 1.00221e6, 2027.5), max: (2.43778e5, 1.00221e6, 2032.5))\n Box(min: (2.43778e5, 1.00221e6, 2027.5), max: (2.43782e5, 1.00221e6, 2032.5))\n Box(min: (2.43782e5, 1.00221e6, 2027.5), max: (2.43788e5, 1.00221e6, 2032.5))\n Box(min: (2.43788e5, 1.00221e6, 2027.5), max: (2.43792e5, 1.00221e6, 2032.5))\n Box(min: (2.43792e5, 1.00221e6, 2027.5), max: (2.43798e5, 1.00221e6, 2032.5))\n\n\nThe @transform macro modifies or creates new columns in the geotable based on expressions with existing column names. In this case, we want to replace the geometry column by calling the auxiliary function above:\n\ngt = @transform(gt, :geometry = box(:geometry))\n\n\n19548×8 GeoTable over 19548 GeometrySet{3,Float64}\n\n\nAu\nAg\nCu\nAs\ngeo\nlitho\nρ\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nMulticlass\nMulticlass\nContinuous\nBox\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n0.407\n2.335\n1311.0\n27.0\nC1\nTR1\n2.42\nBox(min: (2.43938e5, 1.00223e6, 1852.5), max: (2.43942e5, 1.00223e6, 1857.5))\n\n\n0.407\n2.335\n1311.0\n27.0\nC1\nTR1\n1.98\nBox(min: (2.43942e5, 1.00223e6, 1852.5), max: (2.43948e5, 1.00223e6, 1857.5))\n\n\n0.407\n2.335\n1311.0\n27.0\nC1\nTR1\n2.068\nBox(min: (2.43948e5, 1.00226e6, 1852.5), max: (2.43952e5, 1.00226e6, 1857.5))\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nTR1\n2.222\nBox(min: (2.43962e5, 1.00226e6, 1852.5), max: (2.43968e5, 1.00226e6, 1857.5))\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nTR1\n2.156\nBox(min: (2.43968e5, 1.00226e6, 1852.5), max: (2.43972e5, 1.00226e6, 1857.5))\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nOX1\n2.08\nBox(min: (2.43958e5, 1.00227e6, 1852.5), max: (2.43962e5, 1.00227e6, 1857.5))\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nOX1\n2.06\nBox(min: (2.43962e5, 1.00227e6, 1852.5), max: (2.43968e5, 1.00227e6, 1857.5))\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nOX1\n1.9\nBox(min: (2.43968e5, 1.00227e6, 1852.5), max: (2.43972e5, 1.00227e6, 1857.5))\n\n\n0.42152\n1.422\n852.36\n22.85\nC1\nTR1\n2.024\nBox(min: (2.43928e5, 1.00222e6, 1857.5), max: (2.43932e5, 1.00222e6, 1862.5))\n\n\n0.41747\n1.429\n832.36\n21.87\nC1\nTR1\n2.112\nBox(min: (2.43932e5, 1.00222e6, 1857.5), max: (2.43938e5, 1.00222e6, 1862.5))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nThe macro will broadcast the expression to all rows of the geotable.\n\n\n\n\n\n\nNote\n\n\n\nWe used the :geometry symbol to refer to the geometry column instead of the usual \"geometry\" string. The @transform macro understands that strings can also appear as valid values in the right-hand-side of the expression, which are not columns in the geotable. To mark a string as a column name, we need to use curly braces:\n@transform(gt, {\"geometry\"} = box({\"geometry\"}))\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nThe use of symbols to represent column names is preferred in macros.\n\n\nThe mass of gold on each mining block can be computed now that the geometries have volume:\n\n@transform(gt, :m = :Au * :ρ * volume(:geometry))\n\n\n19548×9 GeoTable over 19548 GeometrySet{3,Float64}\n\n\nAu\nAg\nCu\nAs\ngeo\nlitho\nρ\nm\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nMulticlass\nMulticlass\nContinuous\nContinuous\nBox\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n0.407\n2.335\n1311.0\n27.0\nC1\nTR1\n2.42\n123.117\nBox(min: (2.43938e5, 1.00223e6, 1852.5), max: (2.43942e5, 1.00223e6, 1857.5))\n\n\n0.407\n2.335\n1311.0\n27.0\nC1\nTR1\n1.98\n100.732\nBox(min: (2.43942e5, 1.00223e6, 1852.5), max: (2.43948e5, 1.00223e6, 1857.5))\n\n\n0.407\n2.335\n1311.0\n27.0\nC1\nTR1\n2.068\n105.209\nBox(min: (2.43948e5, 1.00226e6, 1852.5), max: (2.43952e5, 1.00226e6, 1857.5))\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nTR1\n2.222\n106.934\nBox(min: (2.43962e5, 1.00226e6, 1852.5), max: (2.43968e5, 1.00226e6, 1857.5))\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nTR1\n2.156\n103.758\nBox(min: (2.43968e5, 1.00226e6, 1852.5), max: (2.43972e5, 1.00226e6, 1857.5))\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nOX1\n2.08\n100.1\nBox(min: (2.43958e5, 1.00227e6, 1852.5), max: (2.43962e5, 1.00227e6, 1857.5))\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nOX1\n2.06\n99.1375\nBox(min: (2.43962e5, 1.00227e6, 1852.5), max: (2.43968e5, 1.00227e6, 1857.5))\n\n\n0.385\n2.1\n572.0\n0.0\nC1\nOX1\n1.9\n91.4375\nBox(min: (2.43968e5, 1.00227e6, 1852.5), max: (2.43972e5, 1.00227e6, 1857.5))\n\n\n0.42152\n1.422\n852.36\n22.85\nC1\nTR1\n2.024\n106.645\nBox(min: (2.43928e5, 1.00222e6, 1857.5), max: (2.43932e5, 1.00222e6, 1862.5))\n\n\n0.41747\n1.429\n832.36\n21.87\nC1\nTR1\n2.112\n110.212\nBox(min: (2.43932e5, 1.00222e6, 1857.5), max: (2.43938e5, 1.00222e6, 1862.5))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe @transform macro can be used with both geotables and geospatial partitions."
  },
  {
    "objectID": "08-splitcombine.html#combining-results",
    "href": "08-splitcombine.html#combining-results",
    "title": "8  Split-apply-combine",
    "section": "8.5 Combining results",
    "text": "8.5 Combining results\nWe can use the @combine macro to reduce columns of geotables in a geospatial partition obtained with the @groupby macro. The macro is similar to the @transform macro, but expects valid reduction functions such as sum, mean, std. Reduction functions take a vector of values as input and produce a single scalar as output:\n\ngroups = @groupby(gt, :geo)\n\n@combine(groups, :μ = mean(:Au), :σ = std(:Au))\n\n\n2×4 GeoTable over 2 GeometrySet{3,Float64}\n\n\ngeo\nμ\nσ\ngeometry\n\n\nMulticlass\nContinuous\nContinuous\nMulti\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\nC1\n0.581937\n0.136264\nMulti(17153×Box)\n\n\nC2\n0.484622\n0.095799\nMulti(2395×Box)\n\n\n\n\n\nNote that the macro reduces the geometry column and produces a new complex Multi geometry with all the Boxes that are inside each geological unit. This is a very advanced feature of the framework that cannot be represented with the simple features standard. It is also possible to use a custom reduction function for the geometry column:\n\ngroups = @groupby(gt, :geo)\n\n@combine(groups, :μ = mean(:Au), :σ = std(:Au), :geometry = first(:geometry))\n\n\n2×4 GeoTable over 2 GeometrySet{3,Float64}\n\n\ngeo\nμ\nσ\ngeometry\n\n\nMulticlass\nContinuous\nContinuous\nBox\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\nC1\n0.581937\n0.136264\nBox(min: (2.43938e5, 1.00223e6, 1852.5), max: (2.43942e5, 1.00223e6, 1857.5))\n\n\nC2\n0.484622\n0.095799\nBox(min: (2.43792e5, 1.00214e6, 1872.5), max: (2.43798e5, 1.00214e6, 1877.5))"
  },
  {
    "objectID": "08-splitcombine.html#answering-questions",
    "href": "08-splitcombine.html#answering-questions",
    "title": "8  Split-apply-combine",
    "section": "8.6 Answering questions",
    "text": "8.6 Answering questions\nLet’s recall our original business question:\nWhat is the total mass of gold that will be mined from each geological unit?\nWe can now answer this question with three lines of code:\n\ngroups = @groupby(gt, :geo)\n\nmass = @transform(groups, :m = :Au * :ρ * volume(:geometry))\n\nanswer = @combine(mass, :m = sum(:m))\n\n\n2×3 GeoTable over 2 GeometrySet{3,Float64}\n\n\ngeo\nm\ngeometry\n\n\nMulticlass\nContinuous\nMulti\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\nC1\n2.53302e6\nMulti(17153×Box)\n\n\nC2\n3.29241e5\nMulti(2395×Box)\n\n\n\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nWe can simplify the code further using the @chain macro. It forwards the resulting geotable or geospatial partition to the next macro:\n\n@chain gt begin\n  @groupby(:geo)\n  @transform(:m = :Au * :ρ * volume(:geometry))\n  @combine(:m = sum(:m))\nend\n\n\n2×3 GeoTable over 2 GeometrySet{3,Float64}\n\n\ngeo\nm\ngeometry\n\n\nMulticlass\nContinuous\nMulti\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\nC1\n2.53302e6\nMulti(17153×Box)\n\n\nC2\n3.29241e5\nMulti(2395×Box)\n\n\n\n\n\n\n\n\n\n\n\nWickham, Hadley. 2011. “The Split-Apply-Combine Strategy for Data Analysis.” Journal of Statistical Software 40 (1): 1–29. https://doi.org/10.18637/jss.v040.i01."
  },
  {
    "objectID": "09-geojoins.html#motivation",
    "href": "09-geojoins.html#motivation",
    "title": "9  Geospatial joins",
    "section": "9.1 Motivation",
    "text": "9.1 Motivation\nThe split-apply-combine pattern that we learned in the previous chapter requires a single geotable with all the relevant information in it. However, many questions in geospatial data science can only be answered with information that is spread across multiple geotables. Hence, the need to join these geotables before attempting to @groupby, @transform and @combine the information.\nLet’s consider a simple example where we are given two geotables, one containing people who shared their latitude and longitude coordinates:\n\ntable = (\n  NAME=[\"John\", \"Mary\", \"Paul\", \"Anne\", \"Kate\"],\n  AGE=[34, 12, 23, 39, 28]u\"yr\",\n  HEIGHT=[1.78, 1.56, 1.70, 1.80, 1.72]u\"m\",\n  LATITUDE=[-22.96710361241228, 37.42773662442142, -27.486220858775997, 39.90358408375064, -3.847311538763359],\n  LONGITUDE=[-43.17891118844475, -122.17007072663823, 153.04380578036657, 116.40764745941036, -32.411372812211226]\n)\n\npeople = georef(table, (:LONGITUDE, :LATITUDE))\n\n\n5×4 GeoTable over 5 PointSet{2,Float64}\n\n\nNAME\nAGE\nHEIGHT\ngeometry\n\n\nTextual\nContinuous\nContinuous\nPoint2\n\n\n[NoUnits]\n[yr]\n[m]\n\n\n\n\n\nJohn\n34 yr\n1.78 m\n(-43.1789, -22.9671)\n\n\nMary\n12 yr\n1.56 m\n(-122.17, 37.4277)\n\n\nPaul\n23 yr\n1.7 m\n(153.044, -27.4862)\n\n\nAnne\n39 yr\n1.8 m\n(116.408, 39.9036)\n\n\nKate\n28 yr\n1.72 m\n(-32.4114, -3.84731)\n\n\n\n\n\nAnd another containing countries in the world according to the Natural Earth project:\n\nusing GeoIO\n\ncountries = GeoIO.load(\"data/countries.geojson\", numbertype = Float64)\n\n\n177×3 GeoTable over 177 GeometrySet{2,Float64}\n\n\nCOUNTRY\nREGION\ngeometry\n\n\nTextual\nTextual\nMultiPolygon\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\nFiji\nMelanesia\nMulti(3×PolyArea)\n\n\nTanzania\nEastern Africa\nMulti(1×PolyArea)\n\n\nW. Sahara\nNorthern Africa\nMulti(1×PolyArea)\n\n\nCanada\nNorthern America\nMulti(30×PolyArea)\n\n\nUnited States of America\nNorthern America\nMulti(10×PolyArea)\n\n\nKazakhstan\nCentral Asia\nMulti(1×PolyArea)\n\n\nUzbekistan\nCentral Asia\nMulti(1×PolyArea)\n\n\nPapua New Guinea\nMelanesia\nMulti(4×PolyArea)\n\n\nIndonesia\nSouth-Eastern Asia\nMulti(13×PolyArea)\n\n\nArgentina\nSouth America\nMulti(2×PolyArea)\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe georef function has a method that accepts the names of columns with geospatial coordinates. In this example, the table already has the LATITUDE and LONGITUDE coordinates.\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nIt is always a good idea to provide units to all values in a geotable. The GeoStats.jl framework is integrated with the Unitful.jl project. To add the unit “meter” to the numeric value 1, we can write 1u\"m\". Similarly, we can add the unit to a vector of values:\n\n[1.0, 2.0, 3.0]u\"m\"\n\n3-element Vector{Quantity{Float64, 𝐋, Unitful.FreeUnits{(m,), 𝐋, nothing}}}:\n 1.0 m\n 2.0 m\n 3.0 m\n\n\n\n\nLet’s visualize the geometries of these two geotables:\n\nfig = Mke.Figure()\nax = Mke.Axis(fig[1,1], title = \"People and countries\",\n              xlabel = \"longitude\", ylabel = \"latitude\")\nviz!(countries.geometry)\nviz!(people.geometry, color = \"teal\")\nfig\n\n\n\n\nOur goal in this example is to attach the “COUNTRY” and “REGION” information to each individual based on their location, represented as a point. In other words, we want to find the countries that contain the location, and then copy the columns to the people."
  },
  {
    "objectID": "09-geojoins.html#joining-geotables",
    "href": "09-geojoins.html#joining-geotables",
    "title": "9  Geospatial joins",
    "section": "9.2 Joining geotables",
    "text": "9.2 Joining geotables\nThe geojoin function can be used to join two geotables using a geometric predicate function:\n\ngeojoin(people, countries, pred = ∈)\n\n\n5×6 GeoTable over 5 PointSet{2,Float64}\n\n\nNAME\nAGE\nHEIGHT\nCOUNTRY\nREGION\ngeometry\n\n\nTextual\nContinuous\nContinuous\nTextual\nTextual\nPoint2\n\n\n[NoUnits]\n[yr]\n[m]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\nJohn\n34 yr\n1.78 m\nBrazil\nSouth America\n(-43.1789, -22.9671)\n\n\nMary\n12 yr\n1.56 m\nUnited States of America\nNorthern America\n(-122.17, 37.4277)\n\n\nPaul\n23 yr\n1.7 m\nAustralia\nAustralia and New Zealand\n(153.044, -27.4862)\n\n\nAnne\n39 yr\n1.8 m\nChina\nEastern Asia\n(116.408, 39.9036)\n\n\nKate\n28 yr\n1.72 m\nmissing\nmissing\n(-32.4114, -3.84731)\n\n\n\n\n\nIn the example above, we used the ∈ predicate to check if a Point in the people geotable is in a MultiPolygon in the countries geotable. The default predicate in geojoin is the intersects function that we covered in previous chapters.\nNotice that Kate’s “COUNTRY” and “REGION” are missing. That is because Kate lives in the Fernando de Noronha island, which is not present in the countries geotable. To retain just those people for which the geometric predicate evaluates true, we can use a different kind of geojoin known as inner:\n\ngeojoin(people, countries, kind = :inner)\n\n\n4×6 GeoTable over 4 view(::PointSet{2,Float64}, [1, 2, 3, 4])\n\n\nNAME\nAGE\nHEIGHT\nCOUNTRY\nREGION\ngeometry\n\n\nTextual\nContinuous\nContinuous\nTextual\nTextual\nPoint2\n\n\n[NoUnits]\n[yr]\n[m]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\nJohn\n34 yr\n1.78 m\nBrazil\nSouth America\n(-43.1789, -22.9671)\n\n\nMary\n12 yr\n1.56 m\nUnited States of America\nNorthern America\n(-122.17, 37.4277)\n\n\nPaul\n23 yr\n1.7 m\nAustralia\nAustralia and New Zealand\n(153.044, -27.4862)\n\n\nAnne\n39 yr\n1.8 m\nChina\nEastern Asia\n(116.408, 39.9036)\n\n\n\n\n\nBy default, the left kind is used. Like in standard join, the geojoin is not commutative. If we swap the order of the geotables, the result will be different:\n\ngeojoin(countries, people, kind = :inner)\n\n\n4×6 GeoTable over 4 view(::GeometrySet{2,Float64}, [5, 30, 138, 140])\n\n\nCOUNTRY\nREGION\nNAME\nAGE\nHEIGHT\ngeometry\n\n\nTextual\nTextual\nTextual\nContinuous\nContinuous\nMultiPolygon\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[yr]\n[m]\n\n\n\n\n\nUnited States of America\nNorthern America\nMary\n12 yr\n1.56 m\nMulti(10×PolyArea)\n\n\nBrazil\nSouth America\nJohn\n34 yr\n1.78 m\nMulti(1×PolyArea)\n\n\nAustralia\nAustralia and New Zealand\nPaul\n23 yr\n1.7 m\nMulti(2×PolyArea)\n\n\nChina\nEastern Asia\nAnne\n39 yr\n1.8 m\nMulti(2×PolyArea)\n\n\n\n\n\nTo learn about the different kinds of join, check DataFrames.jl’s documentation on joins.\n\n\n\n\n\n\nNote\n\n\n\nIn database-style join, the predicate function isequal is applied to arbitrary columns of tables. In geojoin, geometric predicate functions are applied to the geometry column of geotables."
  },
  {
    "objectID": "09-geojoins.html#common-predicates",
    "href": "09-geojoins.html#common-predicates",
    "title": "9  Geospatial joins",
    "section": "9.3 Common predicates",
    "text": "9.3 Common predicates\nIn geospatial data science, the most common geometric predicates used in geojoin are ∈, ⊆, ==, ≈ and intersects as illustrated in Table 9.1. Specific applications may require custom predicates, which can be easily defined in pure Julia with the Meshes.jl module. For example, it is sometimes convenient to define geometric predicates in terms of a distance and a threshold:\npred(g1, g2) = distance(g1, g2) ≤ 1u\"m\"`\n\n\nTable 9.1: Common geometric predicates in geospatial join\n\n\nPREDICATE\nEXAMPLE\n\n\n\n\n∈\n\n\n\n⊆\n\n\n\n==\n\n\n\n≈\n\n\n\nintersects"
  },
  {
    "objectID": "09-geojoins.html#multiple-matches",
    "href": "09-geojoins.html#multiple-matches",
    "title": "9  Geospatial joins",
    "section": "9.4 Multiple matches",
    "text": "9.4 Multiple matches\nSometimes the predicate function will evaluate true for multiple rows of the geotables. In this case, we need to decide which value will be copied to the resulting geotable. The geojoin accepts reduction functions for each column. For example, suppose that Kate decided to move to the continent:\n\ntable = (\n  NAME=[\"John\", \"Mary\", \"Paul\", \"Anne\", \"Kate\"],\n  AGE=[34, 12, 23, 39, 28]u\"yr\",\n  HEIGHT=[1.78, 1.56, 1.70, 1.80, 1.72]u\"m\",\n  LATITUDE=[-22.96710361241228, 37.42773662442142, -27.486220858775997, 39.90358408375064, -9.66628224039543],\n  LONGITUDE=[-43.17891118844475, -122.17007072663823, 153.04380578036657, 116.40764745941036, -35.71261407423411]\n)\n\npeople = georef(table, (:LONGITUDE, :LATITUDE))\n\n\n5×4 GeoTable over 5 PointSet{2,Float64}\n\n\nNAME\nAGE\nHEIGHT\ngeometry\n\n\nTextual\nContinuous\nContinuous\nPoint2\n\n\n[NoUnits]\n[yr]\n[m]\n\n\n\n\n\nJohn\n34 yr\n1.78 m\n(-43.1789, -22.9671)\n\n\nMary\n12 yr\n1.56 m\n(-122.17, 37.4277)\n\n\nPaul\n23 yr\n1.7 m\n(153.044, -27.4862)\n\n\nAnne\n39 yr\n1.8 m\n(116.408, 39.9036)\n\n\nKate\n28 yr\n1.72 m\n(-35.7126, -9.66628)\n\n\n\n\n\nNow, both John and Kate live in Brazil according the countries geotable:\n\ngeojoin(people, countries)\n\n\n5×6 GeoTable over 5 PointSet{2,Float64}\n\n\nNAME\nAGE\nHEIGHT\nCOUNTRY\nREGION\ngeometry\n\n\nTextual\nContinuous\nContinuous\nTextual\nTextual\nPoint2\n\n\n[NoUnits]\n[yr]\n[m]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\nJohn\n34 yr\n1.78 m\nBrazil\nSouth America\n(-43.1789, -22.9671)\n\n\nMary\n12 yr\n1.56 m\nUnited States of America\nNorthern America\n(-122.17, 37.4277)\n\n\nPaul\n23 yr\n1.7 m\nAustralia\nAustralia and New Zealand\n(153.044, -27.4862)\n\n\nAnne\n39 yr\n1.8 m\nChina\nEastern Asia\n(116.408, 39.9036)\n\n\nKate\n28 yr\n1.72 m\nBrazil\nSouth America\n(-35.7126, -9.66628)\n\n\n\n\n\nIf we swap the order of the geotables in the geojoin, we need to decide how to reduce the multiple values of “NAME”, “AGE” and “HEIGHT” in the resulting geotable. By default, the mean function is used to reduce Continuous variables, and the first function is used otherwise:\n\ngeojoin(countries, people, kind = :inner)\n\n\n4×6 GeoTable over 4 view(::GeometrySet{2,Float64}, [5, 30, 138, 140])\n\n\nCOUNTRY\nREGION\nNAME\nAGE\nHEIGHT\ngeometry\n\n\nTextual\nTextual\nTextual\nContinuous\nContinuous\nMultiPolygon\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[]\n[m]\n\n\n\n\n\nUnited States of America\nNorthern America\nMary\n12 yr\n1.56 m\nMulti(10×PolyArea)\n\n\nBrazil\nSouth America\nJohn\n31.0 yr\n1.75 m\nMulti(1×PolyArea)\n\n\nAustralia\nAustralia and New Zealand\nPaul\n23 yr\n1.7 m\nMulti(2×PolyArea)\n\n\nChina\nEastern Asia\nAnne\n39 yr\n1.8 m\nMulti(2×PolyArea)\n\n\n\n\n\nWe can specify custom reduction functions using the following syntax:\n\ngeojoin(countries, people, \"AGE\" =&gt; maximum, \"HEIGHT\" =&gt; mean, kind = :inner)\n\n\n4×6 GeoTable over 4 view(::GeometrySet{2,Float64}, [5, 30, 138, 140])\n\n\nCOUNTRY\nREGION\nNAME\nAGE\nHEIGHT\ngeometry\n\n\nTextual\nTextual\nTextual\nContinuous\nContinuous\nMultiPolygon\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[yr]\n[m]\n\n\n\n\n\nUnited States of America\nNorthern America\nMary\n12 yr\n1.56 m\nMulti(10×PolyArea)\n\n\nBrazil\nSouth America\nJohn\n34 yr\n1.75 m\nMulti(1×PolyArea)\n\n\nAustralia\nAustralia and New Zealand\nPaul\n23 yr\n1.7 m\nMulti(2×PolyArea)\n\n\nChina\nEastern Asia\nAnne\n39 yr\n1.8 m\nMulti(2×PolyArea)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe keyword arguments kind and pred must appear at the end of the geojoin:\ngeojoin(gt1, gt2, var1 =&gt; red1, ..., varn =&gt; redn; kind = :left, pred = intersects)"
  },
  {
    "objectID": "09-geojoins.html#congratulations",
    "href": "09-geojoins.html#congratulations",
    "title": "9  Geospatial joins",
    "section": "9.5 Congratulations!",
    "text": "9.5 Congratulations!\nCongratulations on finishing Part III of the book. Let’s quickly review what we learned so far:\n\nIn order to answer geoscientific questions with @groupby, @transform and @combine, we need a single geotable with all the relevant information. This single geotable is often the result of a geojoin with multiple geotables from different sources of information.\nThere are various kinds of geojoin such as inner and left, which match the behavior of standard join in databases. We recommend the DataFrames.jl documentation to learn more.\nThe geojoin produces matches with geometric predicate functions. The most common are illustrated in Table 9.1, but custom predicates can be easily defined in pure Julia using functions defined in the Meshes.jl module.\n\nIn the next part of the book, you will learn a final important tool that is missing in our toolkit for advanced geospatial data science. The concepts in the following chapters are extremely important."
  },
  {
    "objectID": "10-correlation.html#variography",
    "href": "10-correlation.html#variography",
    "title": "10  Geospatial correlation",
    "section": "10.1 Variography",
    "text": "10.1 Variography\n\n\n\n\n\n\nDefinition\n\n\n\nThe variogram function is a more general alternative to the correlogram and covariance functions that does not rely on the mean values \\(\\bar{x}\\) and \\(\\bar{y}\\). It is given by\n\\[\n\\gamma_x(h) \\approx \\frac{1}{2|N(h)|}\\sum_{N(h)}(x_i-x_j)^2\n\\]\nwhere \\(N(h) = \\Big\\{(i,j): i\\underbrace{\\longrightarrow}_{h \\text{ units}} j\\Big\\}\\) is the set of pairs of locations that are \\(h\\) units apart.\nIn the multivariate case, we can also define the cross-variogram:\n\\[\n\\gamma_{xy}(h) \\approx \\frac{1}{2|N(h)|}\\sum_{N(h)}(x_i-x_j)(y_i-y_j)\n\\]\n\n\nThe value \\(\\gamma(h)\\) measures the “spread” of the hscatter plot. Usually, at \\(h=0\\) there is no spread, and hence \\(\\gamma(0) = 0\\). In most practical cases \\(\\gamma(h) \\to \\sigma^2\\) as \\(h \\to \\infty\\) where \\(\\sigma^2\\) is the maximum variance of the process. When this maximum variance exists, we can write the following relation:\n\\[\n\\gamma(h) = \\sigma^2 - cov(h)\n\\]\n\n\n\n\n\nwhere \\(cov(h)\\) is the covariance function, a version of the correlogram function that is scaled by the standard deviations of X and Y:\n\\[\ncor(h) = \\frac{cov(h)}{\\sigma_x \\sigma_y}\n\\]\nExplaining why the variogram is more general than the covariance is out of scope for this book, but it has to do with the fact that variograms operate on the “difference process” \\((x_i - x_j)\\) as opposed to the centered process \\((x_i - \\bar{x})\\). In particular, it does not require a finite maximum variance \\(\\sigma^2\\).\n\n\n\n\n\n\nNote\n\n\n\nThe theory of intrinsic random functions of order k (IRF-k) is an advanced concept from geostatistical theory that explains the generality of the variogram function (Chilès and Delfiner 2012).\n\n\nOur main goal here is to gain intuition about the variogram function for interpolation purposes. It suffices to learn its four basic elements: range, sill, nugget and model.\n\n\n\n\n\n\n10.1.1 range\nThe range (a.k.a. correlation length) of the variogram determines the average size of “blobs” in the image. Let’s consider two synthetic images with ranges 10 and 30, respectively:\n\n\n\n\n\nIn the first image, we can clearly visualize the average size of yellow and blue blobs around 10 pixels (i.e. quadrangles). In the second image, the blobs have an average size of 30 pixels, which is greater than one of the sides of the grid (100x25 pixels).\n\n\n10.1.2 sill\nTo understand the sill of the variogram, let’s consider a 1D grid as our domain, and let’s represent the values of the variable with height instead of color:\n\n\n\n\n\nThe sill determines the maximum variance of the process. If the sill is \\(\\sigma^2\\), then a process with mean \\(\\mu\\) will oscillate within \\(\\mu\\pm3\\sigma\\) with 99.7% probability. The vertical amplitude in the second plot is (3x) larger than that of the first plot. In both plots, we have \\(\\mu=0\\).\n\n\n10.1.3 nugget\nThe nugget can be used to insert additional variance at scales that are smaller than the scale of measurements (i.e. pixel). It is known in the image processing literature as salt-and-pepper noise:\n\n\n\n\n\nWe can visualize the nugget effect in our 2D grid with colors as before:\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe name “nugget” comes from gold nuggets in mining geostatistics. These are often much smaller than selective mining units (SMUs), and show as bright values in the 3D model of the mineral deposit.\n\n\n\n\n10.1.4 model\nFinally, the model of the variogram determines how the function increases near the origin. The GeoStats.jl framework provides dozens of such models of geospatial correlation. The most widely used are the GaussianVariogram, the SphericalVariogram and the ExponentialVariogram:\n\n\n\n\n\nThe faster is the increase of the function near the origin, the more “erratic” is the process:\n\n\n\n\n\nAll the four elements of the variogram function can be easily set at construction time:\n\nγ = GaussianVariogram(range=10.0, sill=2.0, nugget=0.1)\n\nGaussianVariogram\n└─sill: 2.0\n└─nugget: 0.1\n└─range: 10.0\n└─metric: Euclidean\n\n\nAnd queried later with the corresponding functions:\n\nrange(γ), sill(γ), nugget(γ)\n\n(10.0, 2.0, 0.1)\n\n\nWe can evaluate the variogram at any given lag:\n\nγ(1.0)\n\n0.15615445670336806\n\n\nOr evaluate the variogram between any two points:\n\nγ(Point(0, 0), Point(1, 0))\n\n0.15615445670336806\n\n\nIn this case, the Euclidean metric is used by default to compute the lag. More generally, we can evaluate the variogram between any two geometries:\n\nγ(Point(0, 0), Triangle((0, 0), (1, 0), (1, 1)))\n\n0.1370712764063879\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe evaluation of the variogram function between two geometries is known as variogram regularization, and implemented in terms of numerical integration.\n\n\nRemind that the variogram value \\(\\gamma(h)\\) is a measure of spread in the hscatter plot. It tells how much variation is expected for a variable at a distance \\(h\\) from a reference point."
  },
  {
    "objectID": "10-correlation.html#fitting-models",
    "href": "10-correlation.html#fitting-models",
    "title": "10  Geospatial correlation",
    "section": "10.2 Fitting models",
    "text": "10.2 Fitting models\nGiven geospatial data, how do we fit an appropriate variogram model for it? This practical question is traditionally answered in two steps as follows.\n\n10.2.1 Empirical estimate\nLet’s recap the synthetic image from the beginning of the chapter:\n\nimg |&gt; viewer\n\n\n\n\nWe can use the EmpiricalVariogram to estimate the function at specific lag values:\n\ng = EmpiricalVariogram(img, :Z, maxlag = 50.0)\n\nEmpiricalVariogram\n  abscissa: (1.7738343760403918, 48.73607108504686)\n  ordinate: (0.050208707452342134, 0.9030972117970858)\n  N° pairs: 24138788\n\n\n\nMke.plot(g)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe numbers and bars in the empirical variogram plot represent the number of pairs used to estimate the value of the variogram at the corresponding bin. The larger the number, the more confident we can be in the estimate.\n\n\nThe DirectionalVariogram can be used to estimate the function along specific directions:\n\ngₕ = DirectionalVariogram((1.0, 0.0), img, :Z, maxlag = 50.0)\ngᵥ = DirectionalVariogram((0.0, 1.0), img, :Z, maxlag = 50.0)\n\nMke.plot(gₕ, hshow = false, vcolor = \"maroon\")\nMke.plot!(gᵥ, hshow = false, vcolor = \"slategray\")\nMke.current_figure()\n\n\n\n\nIn this example, we observe that the blobs are elongated with a horizontal range of 30 pixels and a vertical range of 10 pixels. This is known as geometric anisotropy.\nWe can also estimate the variogram in all directions on a plane with the EmpiricalVarioplane:\n\ngₚ = EmpiricalVarioplane(img, :Z, maxlag = 50.0)\n\nEmpiricalVarioplane\n  N° pairs\n  └─0.00° → 372500\n  └─3.67° → 304782\n  └─7.35° → 298306\n  └─11.02° → 297432\n  └─14.69° → 297243\n  ⋮\n  └─165.31° → 293643\n  └─168.98° → 295850\n  └─172.65° → 296931\n  └─176.33° → 306528\n  └─180.00° → 372500\n\n\nThe varioplane is usually plotted on a polar axis to highlight the different ranges as a function of the polar angle. These ranges are illustrated with a solid curve over the heatmap:\n\nfig = Mke.Figure()\nax = Mke.PolarAxis(fig[1,1])\nMke.plot!(ax, gₚ)\nfig\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe book by Webster and Oliver (2007) and the article by Cressie and Hawkins (1980) are good resources to learn more about robust variogram estimation.\n\n\n\n\n10.2.2 Least-squares fit\nAfter empirical variogram estimation, the next step consists of fitting a theoretical model. This step is necessary for interpolation given that we need to be able to evaluate the variogram function at any lag \\(h\\), not just the specific lags of the empirical variogram.\n\n\n\n\n\n\nNote\n\n\n\nAnother reason to fit theoretical models is to ensure that variances of linear combinations of variables are always non-negative as discussed in Myers (1992).\n\n\nTo fit a specific theoretical model, we can use the fit function with the model as the first argument:\n\nfit(SphericalVariogram, g)\n\nSphericalVariogram\n└─sill: 0.8863386213342846\n└─nugget: 6.484924860169837e-11\n└─range: 18.350599790889927\n└─metric: Euclidean\n\n\nWe can also let the framework select the model with minimum weighted least-squares error by passing the generic Variogram model to the function:\n\nγ = fit(Variogram, g)\n\nGaussianVariogram\n└─sill: 0.8864324257941406\n└─nugget: 0.062356834376029395\n└─range: 14.888520805892924\n└─metric: Euclidean"
  },
  {
    "objectID": "10-correlation.html#remarks",
    "href": "10-correlation.html#remarks",
    "title": "10  Geospatial correlation",
    "section": "10.3 Remarks",
    "text": "10.3 Remarks\nThis chapter is definitely one of the most challenging ones for those with little background in geostatistics. Let’s make a few important remarks to summarize what we learned:\n\nGeospatial correlation can be represented with different functions, including the correlogram, the covariance and the variogram functions. Among these functions the variogram is the most general and easy to interpret as a measure of “spread” in the hscatter plot.\nThe variogram value \\(\\gamma(h)\\) represents the expected variation of a variable that is \\(h\\) units of distance from a reference point. It usually starts at \\(\\gamma(0) = 0\\), reaches a sill value \\(\\sigma^2\\) near the range and stays at this value as \\(h \\to \\infty\\).\nThe selection of an appropriate theoretical variogram model for interpolation of geospatial data is often based on a two-step procedure. First, we estimate the EmpiricalVariogram, and then we fit a theoretical model. The most widely used models are the GaussianVariogram, the SphericalVariogram and the ExponentialVariogram.\n\nIn the next chapter, we will learn how to perform geospatial interpolation with the selected theoretical variogram model.\n\n\n\n\nChilès, Jean-Paul, and Pierre Delfiner. 2012. Geostatistics. Wiley. https://doi.org/10.1002/9781118136188.\n\n\nCressie, Noel, and Douglas M. Hawkins. 1980. “Robust Estimation of the Variogram: i.” Journal of the International Association for Mathematical Geology 12 (2): 115–25. https://doi.org/10.1007/bf01035243.\n\n\nMyers, Donald E. 1992. “Kriging, Cokriging, Radial Basis Functions and the Role of Positive Definiteness.” Computers & Mathematics with Applications 24 (12): 139–48. https://doi.org/https://doi.org/10.1016/0898-1221(92)90176-I.\n\n\nWebster, Richard, and Margaret A. Oliver. 2007. Geostatistics for Environmental Scientists. Wiley. https://doi.org/10.1002/9780470517277."
  },
  {
    "objectID": "11-interpolation.html#idw",
    "href": "11-interpolation.html#idw",
    "title": "11  Simple interpolation",
    "section": "11.1 IDW",
    "text": "11.1 IDW\nIn Inverse Distance Weighting (IDW), the weights are computed in terms of distances \\(d(u, u_i)\\) to the neighboring geometries:\n\\[\n\\lambda_i = \\frac{1}{{d(u, u_i)}^\\beta}\n\\]\nThis basic idea was proposed by Shepard (1968), who also studied the effect of the exponent \\(\\beta\\) in the interpolation results. Here, we will visualize the results using synthetic data:\n\ndata = georef((z=[1, 0, 1],), [(25, 25), (50, 75), (75, 50)])\n\n\n3×2 GeoTable over 3 PointSet{2,Float64}\n\n\nz\ngeometry\n\n\nCount\nPoint2\n\n\n[NoUnits]\n\n\n\n\n\n1\n(25.0, 25.0)\n\n\n0\n(50.0, 75.0)\n\n\n1\n(75.0, 50.0)\n\n\n\n\n\n\ndata |&gt; viewer\n\n\n\n\nFirst, we need to the define the domain of interpolation, i.e., the geometries where we want to estimate the variable z. In this case, we will perform interpolation on a 2D CartesianGrid:\n\ngrid = CartesianGrid(100, 100)\n\n100×100 CartesianGrid{2,Float64}\n  minimum: Point(0.0, 0.0)\n  maximum: Point(100.0, 100.0)\n  spacing: (1.0, 1.0)\n\n\nWith the measurements of the variable z in the geotable, and the domain of interpolation, we can use the Interpolate transform with the IDW model:\n\ninterp = data |&gt; Interpolate(grid, IDW())\n\n\n10000×2 GeoTable over 100×100 CartesianGrid{2,Float64}\n\n\nz\ngeometry\n\n\nContinuous\nQuadrangle\n\n\n[NoUnits]\n\n\n\n\n\n0.781732\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n0.783631\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n0.785528\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n0.787419\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n0.789298\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n0.79116\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n0.792998\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n0.794805\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n0.796573\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n0.798295\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n\n\n\n\n\n\ninterp |&gt; viewer\n\n\n\n\nTo visualize the effect of the exponent, let’s extract the interpolation results along the line segment between two of the measurements, and visualize it:\n\nseg = Segment((25, 25), (50, 75))\n\nSegment{2,Float64}\n├─ Point(25.0, 25.0)\n└─ Point(50.0, 75.0)\n\n\n\nz = interp[seg, \"z\"]\n\n51-element Vector{Float64}:\n 0.9878058074478854\n 0.9876143292632583\n 0.972495221818037\n 0.9564199524248658\n 0.9361611041027588\n 0.9216832603980624\n 0.9021987666253538\n 0.8888032891965897\n 0.870354691640647\n 0.8577880405850806\n 0.8403212677723804\n 0.828402085571967\n 0.8118014293422096\n ⋮\n 0.409930020727715\n 0.3827414007527533\n 0.3610487511864091\n 0.32990370885751297\n 0.3057282754699494\n 0.26975994006108955\n 0.24282226179926458\n 0.20095741787691726\n 0.17114300512175212\n 0.1219443018616857\n 0.09029188985211117\n 0.03175705173700492\n\n\n\nMke.lines(z, label = \"β=1\")\n\n\n\n\nWe observe that the exponent \\(\\beta=1\\) leads to a gradual transition from the value \\(z=1\\) to the value \\(z=0\\). Let’s repeat the process with increasing values of the exponent:\n\nfig = Mke.Figure()\nMke.Axis(fig[1,1])\nfor β in [1,2,3,4,5]\n  model = IDW(β)\n  interp = data |&gt; Interpolate(grid, model)\n  Mke.lines!(interp[seg, \"z\"], label = \"β=$β\")\nend\nMke.axislegend(position = :lb)\nMke.current_figure()\n\n\n\n\nThe larger is the exponent, the more abrupt is the transition of values between the two locations. In addition, the IDW solution will converge to the nearest neighbor solution as \\(\\beta \\to \\infty\\):\n\nmodel = IDW(100)\n\ndata |&gt; Interpolate(grid, model) |&gt; viewer\n\n\n\n\nCustom distances from Distances.jl may be used in place of the Euclidean distance to meet specific application requirements (e.g. Haversine distance on the sphere):\n\nmodel = IDW(1, Chebyshev())\n\ndata |&gt; Interpolate(grid, model) |&gt; viewer"
  },
  {
    "objectID": "11-interpolation.html#kriging",
    "href": "11-interpolation.html#kriging",
    "title": "11  Simple interpolation",
    "section": "11.2 Kriging",
    "text": "11.2 Kriging\nIn Kriging (Matheron 1971), the weights are computed using geospatial correlation. More specifically, they are the solution to a linear system of equations produced with a theoretical variogram model \\(\\gamma\\):\n\\[\n\\begin{bmatrix}\n\\mathbf{G} & \\mathbf{1} \\\\\n\\mathbf{1}^\\top & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\mathbf{\\lambda} \\\\\n\\nu\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\mathbf{g} \\\\\n1\n\\end{bmatrix}\n\\]\nwhere \\(\\mathbf{G}_{ij} = \\gamma(u_i, u_j)\\) and \\(\\mathbf{g}_i = \\gamma(u, u_i)\\) and \\(\\nu\\) is the Lagrange multiplier associated with the constraint \\(\\mathbf{1}^\\top \\mathbf{\\lambda} = 1\\). The system of equations above is known as Ordinary Kriging, but many other variants are supported by the framework.\n\n\n\n\n\n\nNote\n\n\n\nThe book by Olea (1999) is a good resource to learn the different systems of of equations associated with Kriging interpolation. Names such as Simple Kriging Ordinary Kriging, Universal Kriging are quite popular.\n\n\nUnlike IDW, the Kriging solution is a function of pairwise evaluations of distances between geometries with measurements, represented in the matrix \\(\\mathbf{G}\\). The pairwise evaluations account for possible redundancy in the measurements, which leads to improvements in the estimates:\n\nmodel = Kriging(GaussianVariogram(range=30.0))\n\ndata |&gt; Interpolate(grid, model) |&gt; viewer\n\n\n\n\nIn the previous chapter, we learned how the range of the variogram determines the average size of the “blobs” in the image. Let’s illustrate this concept again for increasing values of this parameter:\n\nfig = Mke.Figure()\nMke.Axis(fig[1,1])\nfor r in [10,20,30,40,50]\n  γ = GaussianVariogram(range=r)\n  model = Kriging(γ)\n  interp = data |&gt; Interpolate(grid, model)\n  Mke.lines!(interp[seg, \"z\"], label = \"range=$r\")\nend\nMke.axislegend(position = :lb)\nMke.current_figure()\n\n\n\n\nThe larger is the range, the less abrupt is the transition of values between the two locations. Similar visualizations can be produced by varying the sill, the nugget and the model of the variogram."
  },
  {
    "objectID": "11-interpolation.html#example",
    "href": "11-interpolation.html#example",
    "title": "11  Simple interpolation",
    "section": "11.3 Example",
    "text": "11.3 Example\nIn order to solidify the concepts learned so far, let’s look into an example. We will cover all the steps that a geospatial data scientist has to perform to extract geospatial correlation from samples and to use this information in geospatial interpolation. In this example, we will also learn how to model anisotropy with theoretical variograms.\nLet’s consider an image of the Walker Lake by Mariethoz and Caers (2014) as groundtruth. To avoid visualization of large images with CairoMakie.jl, we will consider a subdomain within a Box:\n\nusing GeoStatsImages\n\nimg = geostatsimage(\"WalkerLakeTruth\")\n\nimg = img[Box((0, 0), (200, 200)), :]\n\n\n40401×2 GeoTable over 40401 view(::CartesianGrid{2,Float64}, [1, 2, 3, 4, ..., 60198, 60199, 60200, 60201])\n\n\nZ\ngeometry\n\n\nContinuous\nQuadrangle\n\n\n[NoUnits]\n\n\n\n\n\n0.127143\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n0.126681\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n0.126143\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n0.125604\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n0.144938\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n0.169887\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n0.219131\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n0.302491\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n0.351556\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n0.365325\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n\n\n\n\n\n\nimg |&gt; viewer\n\n\n\n\nLet’s assume that we only have access to 10000 samples from the image:\n\nusing Random\n\nsamples = img |&gt; Sample(10000, replace=false, rng=MersenneTwister(123))\n\nsamples |&gt; viewer\n\n\n\n\nOur goal is to interpolate the variable Z over the original domain. Let’s start by estimating the EmpiricalVariogram from the samples. Because the distribution of values in the Walker Lake is skewed, the default :matheron estimator of the variogram shows a high nugget effect:\n\ng = EmpiricalVariogram(samples, \"Z\", maxlag = 100.0)\n\nEmpiricalVariogram\n  abscissa: (3.4245029430657765, 97.48906638639355)\n  ordinate: (0.02693638251365324, 0.09482860897894203)\n  N° pairs: 24150788\n\n\n\nMke.plot(g)\n\n\n\n\nA better alternative in this case is to use the robust :cressie estimator:\n\ng = EmpiricalVariogram(samples, \"Z\", maxlag = 100.0, estimator = :cressie)\n\nEmpiricalVariogram\n  abscissa: (3.4245029430657765, 97.48906638639355)\n  ordinate: (0.013224856770066285, 0.1023275351926679)\n  N° pairs: 24150788\n\n\n\nMke.plot(g)\n\n\n\n\nAfter estimating the empirical variogram, the next step consists of fitting a theoretical model. The behavior near the origin resembles a SphericalVariogram:\n\nγ = fit(SphericalVariogram, g)\n\nSphericalVariogram\n└─sill: 0.09816267113825099\n└─nugget: 3.640146399591588e-11\n└─range: 42.631545896834375\n└─metric: Euclidean\n\n\n\nMke.plot(γ, maxlag = 100.0)\n\n\n\n\nNow that we extracted the geospatial correlation from the samples, we can use this information in Kriging interpolation. Instead of fitting all the samples at once like it is done in the Interpolate transform, we will fit the Kriging model with a maximum number of neighbors with the InterpolateNeighbors transform:\n\ninterp = samples |&gt; InterpolateNeighbors(img.geometry, Kriging(γ))\n\n\n40401×2 GeoTable over 40401 view(::CartesianGrid{2,Float64}, [1, 2, 3, 4, ..., 60198, 60199, 60200, 60201])\n\n\nZ\ngeometry\n\n\nContinuous\nQuadrangle\n\n\n[NoUnits]\n\n\n\n\n\n0.127143\nQuadrangle((0.0, 0.0), ..., (0.0, 1.0))\n\n\n0.125893\nQuadrangle((1.0, 0.0), ..., (1.0, 1.0))\n\n\n0.126143\nQuadrangle((2.0, 0.0), ..., (2.0, 1.0))\n\n\n0.148675\nQuadrangle((3.0, 0.0), ..., (3.0, 1.0))\n\n\n0.177866\nQuadrangle((4.0, 0.0), ..., (4.0, 1.0))\n\n\n0.21315\nQuadrangle((5.0, 0.0), ..., (5.0, 1.0))\n\n\n0.248825\nQuadrangle((6.0, 0.0), ..., (6.0, 1.0))\n\n\n0.280572\nQuadrangle((7.0, 0.0), ..., (7.0, 1.0))\n\n\n0.314659\nQuadrangle((8.0, 0.0), ..., (8.0, 1.0))\n\n\n0.326309\nQuadrangle((9.0, 0.0), ..., (9.0, 1.0))\n\n\n⋮\n⋮\n\n\n\n\n\n\ninterp |&gt; viewer\n\n\n\n\n\n\n\n\n\n\nTip for all users\n\n\n\nThe InterpolateNeighbors is recommended in 3D applications with hundreds of thousands of measurements and very large grids."
  },
  {
    "objectID": "11-interpolation.html#congratulations",
    "href": "11-interpolation.html#congratulations",
    "title": "11  Simple interpolation",
    "section": "11.4 Congratulations!",
    "text": "11.4 Congratulations!\nCongratulations on finishing Part IV of the book. The interpolation models introduced here are simple, yet very useful. Before we start our journey with real-world applications of the framework, let’s review what we learned:\n\nGeospatial interpolation can be achieved with the Interpolate and InterpolateNeighbors transforms, and geostatistical models such as IDW and Kriging.\nModels such as Kriging exploit geospatial correlation to improve interpolation results. We can extract this information from samples using a two-step procedure:\n\nEstimate the EmpiricalVariogram from the available samples\nPerform fit of theoretical model with result from previous step\n\nInterpolate and InterpolateNeighbors are examples of geostatistical transforms. They can be easily inserted in more advanced pipelines as discussed in Part II.\n\nIn the next chapters, we will use the framework that we learned with real data to illustrate how advanced geospatial data science can be done with just a few lines of code. Once a solution is written in terms of the high-level tools covered in previous chapters, it is trivial to improve computational performance in pure Julia.\n\n\n\n\n\n\nNote\n\n\n\nFeature and performance requests are very welcome. We invite all users of the framework to submit issues and contribute with our open source software stack.\n\n\n\n\n\n\nMariethoz, Gregoire, and Jef Caers. 2014. Multiple-Point Geostatistics: Stochastic Modeling with Training Images. https://www.wiley.com/en-gb/Multiple+point+Geostatistics%3A+Stochastic+Modeling+with+Training+Images-p-9781118662755.\n\n\nMatheron, Georges François Paul Marie. 1971. The Theory of Regionalized Variables and Its Applications.\n\n\nOlea, Ricardo A. 1999. Geostatistics for Engineers and Earth Scientists. Springer US. https://doi.org/10.1007/978-1-4615-5001-3.\n\n\nShepard, Donald S. 1968. “A Two-Dimensional Interpolation Function for Irregularly-Spaced Data.” Proceedings of the 1968 23rd ACM National Conference. https://api.semanticscholar.org/CorpusID:42723195."
  },
  {
    "objectID": "12-mining.html#data",
    "href": "12-mining.html#data",
    "title": "12  Mineral deposits",
    "section": "12.1 Data",
    "text": "12.1 Data\nThe GeoMet dataset (Hoffimann et al. 2022a) consists of three geospatial tables stored as CSV files. In this chapter, we will only use the drillholes.csv table.\nDrill hole samples are always available in mining projects. They contain chemical information for each rock sample (a cylinder) along the drill hole trajectories. In this case, the data has been processed, and only the “X”, “Y”, “Z” coordinates of the centroids of the cylinders were stored:\n\nurl = \"https://zenodo.org/record/7051975/files/drillholes.csv?download=1\"\n\ndtable = georef(CSV.File(download(url)), (\"X\", \"Y\", \"Z\"))\n\nviewer(dtable, pointsize = 4)\n\n\n\n\n\ndtable |&gt; describe\n\nTable with 6 columns and 19 rows:\n      variable  mean      minimum  median    maximum   nmissing\n    ┌──────────────────────────────────────────────────────────\n 1  │ HOLEID    60.265    1        62.0      119       0\n 2  │ Ag ppm    1.86199   0.01     1.14      15.38     0\n 3  │ Al ppm    52374.8   2400.0   56100.0   103300.0  0\n 4  │ Au ppm    0.470965  0.0      0.21      5.89      0\n 5  │ C ppm     1117.7    100.0    700.0     20700.0   0\n 6  │ Ca ppm    9900.6    100.0    6400.0    73700.0   0\n 7  │ Cl ppm    2303.75   5.48     1756.23   14273.8   0\n 8  │ Cu ppm    7540.4    0.0      5000.0    60200.0   0\n 9  │ F ppm     2528.58   20.89    1610.47   19786.3   0\n 10 │ Fe ppm    245452.0  9900.0   246000.0  500000.0  0\n 11 │ K ppm     13610.9   100.0    12450.0   45500.0   0\n 12 │ Mg ppm    17673.0   200.0    14000.0   88800.0   0\n 13 │ Mn ppm    4282.96   88.95    3685.35   24812.8   0\n 14 │ Na ppm    4404.8    100.0    1400.0    58900.0   0\n 15 │ P ppm     720.896   38.08    630.705   5576.14   0\n 16 │ Pb ppm    9.3938    0.8      6.005     247.83    0\n 17 │ S ppm     2712.95   100.0    1700.0    21500.0   0\n 18 │ Th ppm    8.37926   0.37     4.08      94.81     0\n 19 │ U ppm     19.0894   0.21     10.825    521.49    0\n\n\nThere are 18 chemical elements in the table, all measured in parts per million (ppm). The table also stores an integer identifier for each hole trajectory in the “HOLEID” column. There are 119 such trajectories as shown in the “maximum” column of the describe output.\n\n\n\n\n\n\nNote\n\n\n\nIn most mining projects, the drill hole samples are available as “SURVEY”, “COLLAR” and “INTERVAL” tables, which can be desurveyed and composited with DrillHoles.jl."
  },
  {
    "objectID": "12-mining.html#objectives",
    "href": "12-mining.html#objectives",
    "title": "12  Mineral deposits",
    "section": "12.2 Objectives",
    "text": "12.2 Objectives\nOur main objective is to estimate the economic value associated with each mining block in a 3D block model, i.e. a CartesianGrid with Hexahedron geometries (the blocks). This economic value in U$ dollars is estimated in terms of various other geospatial variables:\n\\[\nValue = \\underbrace{V \\times \\rho \\times Cu \\times f \\times P}_{\\text{revenue}} - \\underbrace{V \\times \\rho \\times (C_m + C_p)}_{\\text{cost}}\n\\]\nwhere\n\n\\(V\\) is the volume of the block in \\(m^3\\)\n\\(\\rho\\) is the rock density in \\(ton/m^3\\)\n\\(Cu\\) is the grade of copper in \\([0,1]\\)\n\\(f\\) is the recovery of copper in \\([0,1]\\)\n\\(P\\) is the selling price in \\(U\\$/ton\\)\n\\(C_m\\) is the mining cost in \\(U\\$/ton\\)\n\\(C_p\\) is the plant cost in \\(U\\$/ton\\)\n\nSecondary objectives include the localization (through 3D visualization) of blocks with high economic value, high grades of Au and Ag, and low grade of S.\nFor simplicity, we assume the following constants:\n\n\\(\\rho = 2.75\\ ton / m^3\\)\n\\(P = 4000\\ U\\$ / ton\\)\n\\(C_m = 4\\ U\\$ / ton\\)\n\\(C_p = 10\\ U\\$ / ton\\)"
  },
  {
    "objectID": "12-mining.html#methodology",
    "href": "12-mining.html#methodology",
    "title": "12  Mineral deposits",
    "section": "12.3 Methodology",
    "text": "12.3 Methodology\nIn order to estimate the economic value of each mining block, we need to interpolate the grade of Cu. Because we also want to localize the blocks with high grades of Au and Ag, and low grade of S, we will perform multivariate geostatistical interpolation of Cu, Au, Ag and S.\nThe proposed methodology has the following steps:\n\nPreliminary analysis and processing\nDefinition of interpolation domain\nMultivariate geostatistical interpolation\nEconomic assessment and visualizations\n\n\n12.3.1 Preliminary analysis\nWe recommend to start any application discarding all information that is not relevant for the stated objectives. In this case, the geotable contains measurements of various chemical elements that are not used in the economic assessment. We define a cleaning pipeline that selects and renames columns of interest, and adds units to the measurements:\n\nselectholeid = Select(\"HOLEID\") →\n               Coerce(\"HOLEID\" =&gt; Multiclass)\n\nselectgrades = Select(\"Cu ppm\" =&gt; \"Cu\",\n                      \"Au ppm\" =&gt; \"Au\",\n                      \"Ag ppm\" =&gt; \"Ag\",\n                      \"S ppm\"  =&gt; \"S\") →\n               Functional(x -&gt; 1e-4*x*u\"percent\") # 1 ppm = 1e-4 percent\n\ndclean = selectholeid ⊔ selectgrades\n\nParallelTableTransform\n├─ SequentialTransform\n│  ├─ Select([:HOLEID], nothing)\n│  └─ Coerce((:HOLEID=&gt;Multiclass,), false, 1)\n└─ SequentialTransform\n   ├─ Select([Symbol(\"Cu ppm\"), Symbol(\"Au ppm\"), Symbol(\"Ag ppm\"), Symbol(\"S ppm\")], [:Cu, :Au, :Ag, :S])\n   └─ Functional(all, #13)\n\n\n\ndtable = dclean(dtable)\n\n\n2000×6 GeoTable over 2000 PointSet{3,Float64}\n\n\nHOLEID\nCu\nAu\nAg\nS\ngeometry\n\n\nMulticlass\nContinuous\nContinuous\nContinuous\nContinuous\nPoint3\n\n\n[NoUnits]\n[%]\n[%]\n[%]\n[%]\n\n\n\n\n\n1\n0.72 %\n0.000104 %\n6.4e-5 %\n0.61 %\n(559.725, -513.31, 252.82)\n\n\n1\n0.1 %\n6.0e-6 %\n2.0e-5 %\n0.06 %\n(558.955, -515.23, 246.87)\n\n\n1\n2.18 %\n0.000202 %\n0.000344 %\n1.17 %\n(557.225, -519.61, 233.37)\n\n\n1\n2.29 %\n0.000343 %\n0.000488 %\n1.1 %\n(555.375, -524.3, 218.92)\n\n\n1\n0.59 %\n5.0e-5 %\n0.000125 %\n0.22 %\n(553.825, -528.21, 206.94)\n\n\n1\n0.56 %\n9.0e-5 %\n9.0e-5 %\n0.28 %\n(552.075, -532.56, 193.91)\n\n\n1\n2.0 %\n0.000356 %\n9.3e-5 %\n1.96 %\n(550.305, -537.08, 180.8)\n\n\n1\n0.28 %\n2.1e-5 %\n7.6e-5 %\n0.14 %\n(547.495, -544.31, 160.08)\n\n\n1\n0.61 %\n2.0e-5 %\n0.000112 %\n0.28 %\n(544.335, -552.43, 137.08)\n\n\n1\n0.25 %\n1.6e-5 %\n7.7e-5 %\n0.09 %\n(541.695, -559.19, 117.96)\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nIn order to better understand the multivariate distribution of chemical elements, we visualize the values of the drill hole samples with the pairplot:\n\ndtable |&gt; Select(\"Cu\", \"Au\", \"Ag\", \"S\") |&gt; DropUnits() |&gt; values |&gt; pairplot\n\n\n\n\nWe can observe that the distribution is very skewed.\n\n\n\n\n\n\nNote\n\n\n\nThe DropUnits transform can be useful to drop units from the columns of a table before calling functions that do not support units yet (e.g., pairplot).\n\n\n\n\n12.3.2 Domain of interpolation\nBefore we can interpolate these variables, we need to define our domain of interpolation. In this application, we will define a 3D CartesianGrid in terms of the drill hole trajectories alone. Some of the Hexahedron geometries will be disabled whenever they are outside the convexhull of the points.\nFirst, let’s create our full CartesianGrid using the boundingbox of the trajectories:\n\n# compute bounding box\nbbox = boundingbox(dtable.geometry)\n\n# size of blocks in meters\nbsize = (25.0, 25.0, 12.5)\n\n# define Cartesian grid\ngrid = CartesianGrid(extrema(bbox)..., bsize)\n\n85×66×66 CartesianGrid{3,Float64}\n  minimum: Point(-1150.004825000069, -882.9003199972212, -399.92)\n  maximum: Point(974.9951749999309, 767.0996800027788, 425.08)\n  spacing: (25.0, 25.0, 12.5)\n\n\n\nviz(dtable.geometry, color = \"black\", pointsize = 4)\nviz!(grid, alpha = 0.2)\nMke.current_figure()\n\n\n\n\nSecond, let’s compute the convexhull of points projected on the horizontal plane:\n\nfunction proj(point)\n  x, y, z = coordinates(point)\n  Point(x, y)\nend\n\npoints = proj.(dtable.geometry)\n\nchull = convexhull(points)\n\nPolyArea{2,Float64}\n  outer\n  └─ Ring((-1150.0, 641.23), ..., (-1120.56, 701.22))\n\n\n\nviz(chull)\nviz!(points, color = \"black\", pointsize = 4)\nMke.current_figure()\n\n\n\n\nWe can filter the grid to retain Hexahedrons for which the projected centroid is inside the convexhull:\n\nactive = findall(h -&gt; proj(centroid(h)) ∈ chull, grid)\n\nblocks = view(grid, active) \n\n136422 view(::CartesianGrid{3,Float64}, [76, 77, 78, 79, ..., 370102, 370103, 370104, 370186])\n├─ Hexahedron((724.995, -882.9, -399.92), ..., (724.995, -857.9, -387.42))\n├─ Hexahedron((749.995, -882.9, -399.92), ..., (749.995, -857.9, -387.42))\n├─ Hexahedron((774.995, -882.9, -399.92), ..., (774.995, -857.9, -387.42))\n├─ Hexahedron((799.995, -882.9, -399.92), ..., (799.995, -857.9, -387.42))\n├─ Hexahedron((824.995, -882.9, -399.92), ..., (824.995, -857.9, -387.42))\n⋮\n├─ Hexahedron((-900.005, 717.1, 412.58), ..., (-900.005, 742.1, 425.08))\n├─ Hexahedron((-875.005, 717.1, 412.58), ..., (-875.005, 742.1, 425.08))\n├─ Hexahedron((-850.005, 717.1, 412.58), ..., (-850.005, 742.1, 425.08))\n├─ Hexahedron((-825.005, 717.1, 412.58), ..., (-825.005, 742.1, 425.08))\n└─ Hexahedron((-900.005, 742.1, 412.58), ..., (-900.005, 767.1, 425.08))\n\n\nWe would also like to filter Hexahedrons that are above the terrain. Let’s create a simple terrain elevation model by interpolating the vertical “Z” coordinate of the first point of each trajectory:\n\nztable = @chain dtable begin\n  @groupby(:HOLEID)\n  @transform(:Z = last(coordinates(:geometry)), :geometry = proj(:geometry))\n  @combine(:Z = first(:Z), :geometry = first(:geometry))\nend\n\n\n119×3 GeoTable over 119 PointSet{2,Float64}\n\n\nHOLEID\nZ\ngeometry\n\n\nMulticlass\nContinuous\nPoint2\n\n\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n1\n252.82\n(559.725, -513.31)\n\n\n2\n280.94\n(745.345, -280.6)\n\n\n3\n281.09\n(-304.025, 318.13)\n\n\n4\n256.16\n(-416.575, 570.35)\n\n\n5\n324.65\n(198.815, -524.78)\n\n\n6\n317.1\n(493.605, -530.83)\n\n\n7\n245.13\n(-367.965, 394.78)\n\n\n8\n250.67\n(17.6752, 33.4297)\n\n\n9\n254.49\n(-514.305, 594.68)\n\n\n10\n294.44\n(-674.415, 596.84)\n\n\n⋮\n⋮\n⋮\n\n\n\n\n\nWe perform the interpolation of the “Z” coordinate on the projected centroids of the blocks:\n\ncentroids = unique(proj.(centroid.(blocks)))\n\nztable = ztable |&gt; Select(\"Z\") |&gt; Interpolate(centroids)\n\n\n2067×2 GeoTable over 2067 PointSet{2,Float64}\n\n\nZ\ngeometry\n\n\nContinuous\nPoint2\n\n\n[NoUnits]\n\n\n\n\n\n315.273\n(737.495, -870.4)\n\n\n318.783\n(762.495, -870.4)\n\n\n321.816\n(787.495, -870.4)\n\n\n324.655\n(812.495, -870.4)\n\n\n327.816\n(837.495, -870.4)\n\n\n309.922\n(687.495, -845.4)\n\n\n314.0\n(712.495, -845.4)\n\n\n318.755\n(737.495, -845.4)\n\n\n323.911\n(762.495, -845.4)\n\n\n327.361\n(787.495, -845.4)\n\n\n⋮\n⋮\n\n\n\n\n\n\nztable |&gt; viewer\n\n\n\n\nFinally, we can filter the blocks for which the “Z” coordinate is below the terrain:\n\np(h) = proj(centroid(h))\nZ(h) = last(coordinates(centroid(h)))\n\nzdict = Dict(ztable.geometry .=&gt; ztable.Z)\n\nactive = findall(h -&gt; Z(h) &lt; zdict[p(h)], blocks)\n\nblocks = view(blocks, active)\n\n110854 view(::CartesianGrid{3,Float64}, [76, 77, 78, 79, ..., 337107, 337109, 337193, 342719])\n├─ Hexahedron((724.995, -882.9, -399.92), ..., (724.995, -857.9, -387.42))\n├─ Hexahedron((749.995, -882.9, -399.92), ..., (749.995, -857.9, -387.42))\n├─ Hexahedron((774.995, -882.9, -399.92), ..., (774.995, -857.9, -387.42))\n├─ Hexahedron((799.995, -882.9, -399.92), ..., (799.995, -857.9, -387.42))\n├─ Hexahedron((824.995, -882.9, -399.92), ..., (824.995, -857.9, -387.42))\n⋮\n├─ Hexahedron((924.995, -682.9, 337.58), ..., (924.995, -657.9, 350.08))\n├─ Hexahedron((874.995, -757.9, 350.08), ..., (874.995, -732.9, 362.58))\n├─ Hexahedron((924.995, -757.9, 350.08), ..., (924.995, -732.9, 362.58))\n├─ Hexahedron((899.995, -732.9, 350.08), ..., (899.995, -707.9, 362.58))\n└─ Hexahedron((924.995, -757.9, 362.58), ..., (924.995, -732.9, 375.08))\n\n\n\nviz(blocks)\n\n\n\n\nThe filtered blocks constitute our domain of interpolation.\n\n\n12.3.3 Interpolation of grades\nWe saw that the distribution of chemical elements in the drill hole samples is very skewed. This is always the case in the mining industry. Another issue is that metal and mineral grades are examples of compositional data (Aitchison 1982). The values in these variables are constrained to live in the interval \\([0,1]\\) and to sum up to 100% if all chemical elements are considered.\n\n12.3.3.1 Preprocessing\nIn order to remove compositional data constraints, we will perform the centered log-ratio transform (CLR) from the CoDa.jl module:\n\ngrades = dtable |&gt; Select(\"Cu\", \"Au\", \"Ag\", \"S\") |&gt; DropUnits()\n\ngrades |&gt; CLR() |&gt; values |&gt; pairplot\n\n\n\n\nAfter the transform, the variables are free to vary in the unbounded interval \\([-\\infty,\\infty]\\). The theory behind this transform is beyond the scope of this book. Nevertheless, it is a simple mathematical expression in terms of logarithms of ratios (e.g., Cu/S).\nNext, we attempt to transform the multivariate distribution to a multivariate standard normal using the ProjectionPursuit transform:\n\ngrades |&gt; CLR() |&gt; ProjectionPursuit() |&gt; values |&gt; pairplot\n\n\n\n\nThe ProjectionPursuit is an advanced statistical transform that removes non-linear associations between variables using an iterative procedure (Friedman 1987). The result is a set of independent variables that can be interpolated separately.\nIn order to “undo” these transforms after the interpolation, we create a revertible pipeline:\n\npreproc = CLR() → ProjectionPursuit()\n\nsamples, cache = apply(preproc, grades)\n\nsamples\n\n\n2000×5 GeoTable over 2000 PointSet{3,Float64}\n\n\nCu\nAu\nAg\nS\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nPoint3\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n-0.892421\n1.34874\n-1.17571\n1.41326\n(559.725, -513.31, 252.82)\n\n\n-1.29173\n-0.428318\n-1.78427\n1.04532\n(558.955, -515.23, 246.87)\n\n\n-0.4053\n1.08376\n0.428799\n1.2991\n(557.225, -519.61, 233.37)\n\n\n-1.45413\n1.36052\n-0.302736\n-0.464057\n(555.375, -524.3, 218.92)\n\n\n-0.554641\n1.17999\n-0.585607\n-0.34912\n(553.825, -528.21, 206.94)\n\n\n-0.904494\n1.75457\n-0.583399\n0.647997\n(552.075, -532.56, 193.91)\n\n\n-0.798722\n1.28985\n-2.17889\n1.51407\n(550.305, -537.08, 180.8)\n\n\n-1.86277\n0.224009\n-0.56606\n0.615858\n(547.495, -544.31, 160.08)\n\n\n0.00608037\n-1.31451\n-1.09932\n1.21965\n(544.335, -552.43, 137.08)\n\n\n-1.28277\n-0.683946\n-0.206159\n-0.275457\n(541.695, -559.19, 117.96)\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\n\n12.3.3.2 Geospatial correlation\nLet’s fit a theoretical variogram for all four (independent) variables:\n\nns = setdiff(names(samples), [\"geometry\"])\n\ngs = [EmpiricalVariogram(samples, n, estimator = :cressie) for n in ns]\n\nγs = [fit(Variogram, g, h -&gt; exp(-h/100)) for g in gs]\n\n4-element Vector{Variogram}:\n ExponentialVariogram(sill=0.8817126853984878, nugget=0.2526543858255549, range=214.00098032583605, metric=Euclidean)\n MaternVariogram(sill=0.9502760254153282, nugget=0.5812815023713779, order=1.0, range=59.24377470800653, metric=Euclidean)\n ExponentialVariogram(sill=0.8813800051315803, nugget=0.445868587874822, range=130.86604438878854, metric=Euclidean)\n MaternVariogram(sill=0.9040062541287281, nugget=0.4983728801024044, order=1.0, range=84.36187340803974, metric=Euclidean)\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe performed the fit of the variogram model using the weighting function h -&gt; exp(-h/100) that penalizes the lag distance h with an exponential model. The constant 100 was chosen based on visual inspection of the EmpiricalVariogram estimates below.\n\n\n\nfunction gammaplot(n, g, γ)\n  Mke.plot(g, axis = (; title = n))\n  Mke.plot!(γ, maxlag = 300, vcolor = \"teal\")\n  Mke.current_figure()\nend\n\ngammaplot(ns[1], gs[1], γs[1])\n\n\n\n\n\ngammaplot(ns[2], gs[2], γs[2])\n\n\n\n\n\ngammaplot(ns[3], gs[3], γs[3])\n\n\n\n\n\ngammaplot(ns[4], gs[4], γs[4])\n\n\n\n\nAssuming that the variogram models are ok, we can proceed to interpolation.\n\n\n12.3.3.3 Geostatistical interpolation\nGiven the domain of interpolation, the samples and the variogram models, we can perform interpolation with InterpolateNeighbors:\n\nmodels = [n =&gt; Kriging(γ) for (n, γ) in zip(ns, γs)]\n\ninterp = samples |&gt; InterpolateNeighbors(blocks, models...)\n\n\n110854×5 GeoTable over 110854 view(::CartesianGrid{3,Float64}, [76, 77, 78, 79, ..., 337107, 337109, 337193, 342719])\n\n\nCu\nAu\nAg\nS\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nHexahedron\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n-0.297545\n-0.191618\n0.220786\n0.480499\nHexahedron((724.995, -882.9, -399.92), ..., (724.995, -857.9, -387.42))\n\n\n-0.0607828\n-0.00821222\n0.351907\n0.962611\nHexahedron((749.995, -882.9, -399.92), ..., (749.995, -857.9, -387.42))\n\n\n-0.0609221\n-0.00808407\n0.351916\n0.962398\nHexahedron((774.995, -882.9, -399.92), ..., (774.995, -857.9, -387.42))\n\n\n-0.0610213\n-0.00800458\n0.35192\n0.962235\nHexahedron((799.995, -882.9, -399.92), ..., (799.995, -857.9, -387.42))\n\n\n-0.0692372\n0.314719\n0.0148926\n-0.0528025\nHexahedron((824.995, -882.9, -399.92), ..., (824.995, -857.9, -387.42))\n\n\n-0.411406\n0.0502209\n0.422855\n0.473926\nHexahedron((674.995, -857.9, -399.92), ..., (674.995, -832.9, -387.42))\n\n\n-0.297572\n-0.191643\n0.220789\n0.480837\nHexahedron((699.995, -857.9, -399.92), ..., (699.995, -832.9, -387.42))\n\n\n-0.297619\n-0.191416\n0.220807\n0.480871\nHexahedron((724.995, -857.9, -399.92), ..., (724.995, -832.9, -387.42))\n\n\n-0.0609669\n-0.00799516\n0.351925\n0.962499\nHexahedron((749.995, -857.9, -399.92), ..., (749.995, -832.9, -387.42))\n\n\n-0.0611253\n-0.00783895\n0.351936\n0.96224\nHexahedron((774.995, -857.9, -399.92), ..., (774.995, -832.9, -387.42))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nLet’s confirm that the interpolated values follow the same standard normal distribution:\n\ninterp |&gt; Sample(10000) |&gt; values |&gt; pairplot\n\n\n\n\n\n\n12.3.3.4 Postprocessing\nIn order to get the interpolated values in the original compositional space, we need to revert the preprocessing pipeline:\n\nestim = revert(preproc, interp, cache)\n\n\n110854×5 GeoTable over 110854 view(::CartesianGrid{3,Float64}, [76, 77, 78, 79, ..., 337107, 337109, 337193, 342719])\n\n\nCu\nAu\nAg\nS\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nHexahedron\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n0.740714\n3.27804e-5\n0.000191661\n0.259062\nHexahedron((724.995, -882.9, -399.92), ..., (724.995, -857.9, -387.42))\n\n\n0.741772\n2.66245e-5\n0.00019621\n0.258005\nHexahedron((749.995, -882.9, -399.92), ..., (749.995, -857.9, -387.42))\n\n\n0.741772\n2.66271e-5\n0.000196211\n0.258005\nHexahedron((774.995, -882.9, -399.92), ..., (774.995, -857.9, -387.42))\n\n\n0.741772\n2.66282e-5\n0.000196212\n0.258006\nHexahedron((799.995, -882.9, -399.92), ..., (799.995, -857.9, -387.42))\n\n\n0.749871\n3.66817e-5\n0.000189567\n0.249903\nHexahedron((824.995, -882.9, -399.92), ..., (824.995, -857.9, -387.42))\n\n\n0.740122\n3.377e-5\n0.000195315\n0.259649\nHexahedron((674.995, -857.9, -399.92), ..., (674.995, -832.9, -387.42))\n\n\n0.740678\n3.2786e-5\n0.000191417\n0.259098\nHexahedron((699.995, -857.9, -399.92), ..., (699.995, -832.9, -387.42))\n\n\n0.7407\n3.28134e-5\n0.000191429\n0.259075\nHexahedron((724.995, -857.9, -399.92), ..., (724.995, -832.9, -387.42))\n\n\n0.741772\n2.66271e-5\n0.000196211\n0.258005\nHexahedron((749.995, -857.9, -399.92), ..., (749.995, -832.9, -387.42))\n\n\n0.741772\n2.66285e-5\n0.000196213\n0.258005\nHexahedron((774.995, -857.9, -399.92), ..., (774.995, -832.9, -387.42))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\n\nestim |&gt; Select(\"Cu\") |&gt; viewer\n\n\n\n\n\n\n\n12.3.4 Model of recovery\nWe introduce a simplistic model of metallurgical recovery using the grade of copper estimated at the mining blocks. We assume that the logistic function represents an ideal behavior for the recovery as the grade of copper increases:\n\nμ = mean(estim.Cu) - 0.1\nσ = std(estim.Cu)\n\nf(Cu) = 1 / (1 + exp(-(Cu - μ) / σ))\n\nf (generic function with 1 method)\n\n\n\nestim = estim |&gt; Map(\"Cu\" =&gt; f =&gt; \"f\")\n\n\n110854×6 GeoTable over 110854 view(::CartesianGrid{3,Float64}, [76, 77, 78, 79, ..., 337107, 337109, 337193, 342719])\n\n\nCu\nAu\nAg\nS\nf\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nHexahedron\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n0.740714\n3.27804e-5\n0.000191661\n0.259062\n0.962894\nHexahedron((724.995, -882.9, -399.92), ..., (724.995, -857.9, -387.42))\n\n\n0.741772\n2.66245e-5\n0.00019621\n0.258005\n0.964111\nHexahedron((749.995, -882.9, -399.92), ..., (749.995, -857.9, -387.42))\n\n\n0.741772\n2.66271e-5\n0.000196211\n0.258005\n0.96411\nHexahedron((774.995, -882.9, -399.92), ..., (774.995, -857.9, -387.42))\n\n\n0.741772\n2.66282e-5\n0.000196212\n0.258006\n0.96411\nHexahedron((799.995, -882.9, -399.92), ..., (799.995, -857.9, -387.42))\n\n\n0.749871\n3.66817e-5\n0.000189567\n0.249903\n0.972226\nHexahedron((824.995, -882.9, -399.92), ..., (824.995, -857.9, -387.42))\n\n\n0.740122\n3.377e-5\n0.000195315\n0.259649\n0.962196\nHexahedron((674.995, -857.9, -399.92), ..., (674.995, -832.9, -387.42))\n\n\n0.740678\n3.2786e-5\n0.000191417\n0.259098\n0.962852\nHexahedron((699.995, -857.9, -399.92), ..., (699.995, -832.9, -387.42))\n\n\n0.7407\n3.28134e-5\n0.000191429\n0.259075\n0.962879\nHexahedron((724.995, -857.9, -399.92), ..., (724.995, -832.9, -387.42))\n\n\n0.741772\n2.66271e-5\n0.000196211\n0.258005\n0.96411\nHexahedron((749.995, -857.9, -399.92), ..., (749.995, -832.9, -387.42))\n\n\n0.741772\n2.66285e-5\n0.000196213\n0.258005\n0.96411\nHexahedron((774.995, -857.9, -399.92), ..., (774.995, -832.9, -387.42))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nPlease check the paper by Hoffimann et al. (2022b) for a more elaborate model of metallurgical recovery in the locked-cycle-test.\n\n\n12.3.5 Economic assessment\nGiven the block model with the grade of copper and metallurgical recovery, we can proceed and apply the formula of economic value stated in our objectives:\n\nρ = 2.75 # ton / m^3\nP = 4000 # U$ / ton\nCₘ = 4 # U$ / ton\nCₚ = 10 # U$ / ton\n\nestim = @transform(estim,\n  :value = volume(:geometry) * ρ * ((:Cu / 100) * :f * P - (Cₘ + Cₚ))\n)\n\n\n110854×7 GeoTable over 110854 view(::CartesianGrid{3,Float64}, [76, 77, 78, 79, ..., 337107, 337109, 337193, 342719])\n\n\nCu\nAu\nAg\nS\nf\nvalue\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nHexahedron\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n0.740714\n3.27804e-5\n0.000191661\n0.259062\n0.962894\n3.1215e5\nHexahedron((724.995, -882.9, -399.92), ..., (724.995, -857.9, -387.42))\n\n\n0.741772\n2.66245e-5\n0.00019621\n0.258005\n0.964111\n3.13802e5\nHexahedron((749.995, -882.9, -399.92), ..., (749.995, -857.9, -387.42))\n\n\n0.741772\n2.66271e-5\n0.000196211\n0.258005\n0.96411\n3.13801e5\nHexahedron((774.995, -882.9, -399.92), ..., (774.995, -857.9, -387.42))\n\n\n0.741772\n2.66282e-5\n0.000196212\n0.258006\n0.96411\n3.138e5\nHexahedron((799.995, -882.9, -399.92), ..., (799.995, -857.9, -387.42))\n\n\n0.749871\n3.66817e-5\n0.000189567\n0.249903\n0.972226\n3.25741e5\nHexahedron((824.995, -882.9, -399.92), ..., (824.995, -857.9, -387.42))\n\n\n0.740122\n3.377e-5\n0.000195315\n0.259649\n0.962196\n3.11216e5\nHexahedron((674.995, -857.9, -399.92), ..., (674.995, -832.9, -387.42))\n\n\n0.740678\n3.2786e-5\n0.000191417\n0.259098\n0.962852\n3.12094e5\nHexahedron((699.995, -857.9, -399.92), ..., (699.995, -832.9, -387.42))\n\n\n0.7407\n3.28134e-5\n0.000191429\n0.259075\n0.962879\n3.12129e5\nHexahedron((724.995, -857.9, -399.92), ..., (724.995, -832.9, -387.42))\n\n\n0.741772\n2.66271e-5\n0.000196211\n0.258005\n0.96411\n3.13801e5\nHexahedron((749.995, -857.9, -399.92), ..., (749.995, -832.9, -387.42))\n\n\n0.741772\n2.66285e-5\n0.000196213\n0.258005\n0.96411\n3.138e5\nHexahedron((774.995, -857.9, -399.92), ..., (774.995, -832.9, -387.42))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n\n\n\nWe can then visualize all blocks with a positive economic value:\n\nestim |&gt; Filter(x -&gt; x.value &gt; 0) |&gt; Select(\"value\") |&gt; viewer\n\n\n\n\nOr any criterion of interest such as positive economic value and small fraction of contaminants:\n\nestim |&gt; Filter(x -&gt; x.value &gt; 0 && x.S &lt; 0.25)\n\n\n48957×7 GeoTable over 48957 view(::CartesianGrid{3,Float64}, [80, 165, 166, 167, ..., 337107, 337109, 337193, 342719])\n\n\nCu\nAu\nAg\nS\nf\nvalue\ngeometry\n\n\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nHexahedron\n\n\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n[NoUnits]\n\n\n\n\n\n0.749871\n3.66817e-5\n0.000189567\n0.249903\n0.972226\n3.25741e5\nHexahedron((824.995, -882.9, -399.92), ..., (824.995, -857.9, -387.42))\n\n\n0.749871\n3.66796e-5\n0.000189565\n0.249902\n0.972227\n3.25742e5\nHexahedron((824.995, -857.9, -399.92), ..., (824.995, -832.9, -387.42))\n\n\n0.74987\n3.66826e-5\n0.000189568\n0.249904\n0.972226\n3.2574e5\nHexahedron((849.995, -857.9, -399.92), ..., (849.995, -832.9, -387.42))\n\n\n0.749867\n3.66867e-5\n0.000189567\n0.249907\n0.972223\n325736.0\nHexahedron((874.995, -857.9, -399.92), ..., (874.995, -832.9, -387.42))\n\n\n0.749894\n3.67088e-5\n0.000189557\n0.249879\n0.972247\n3.25774e5\nHexahedron((849.995, -832.9, -399.92), ..., (849.995, -807.9, -387.42))\n\n\n0.749871\n3.66795e-5\n0.000189565\n0.249902\n0.972227\n3.25742e5\nHexahedron((874.995, -832.9, -399.92), ..., (874.995, -807.9, -387.42))\n\n\n0.749867\n3.66866e-5\n0.000189567\n0.249906\n0.972223\n3.25736e5\nHexahedron((899.995, -832.9, -399.92), ..., (899.995, -807.9, -387.42))\n\n\n0.74987\n3.66815e-5\n0.000189567\n0.249903\n0.972226\n3.25741e5\nHexahedron((899.995, -807.9, -399.92), ..., (899.995, -782.9, -387.42))\n\n\n0.751298\n5.41028e-5\n0.000227739\n0.24842\n0.973459\n3.27729e5\nHexahedron((574.995, -732.9, -399.92), ..., (574.995, -707.9, -387.42))\n\n\n0.75126\n5.41754e-5\n0.000227722\n0.248458\n0.973427\n3.27677e5\nHexahedron((549.995, -707.9, -399.92), ..., (549.995, -682.9, -387.42))\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮"
  },
  {
    "objectID": "12-mining.html#summary",
    "href": "12-mining.html#summary",
    "title": "12  Mineral deposits",
    "section": "12.4 Summary",
    "text": "12.4 Summary\nIn this chapter, we illustrated an application of the framework in the mining industry. Among other things, we learned how to\n\nPerform simple economic assessment based on grades and metallurgical recoveries estimated at mining blocks using simple interpolation of transformed variables from drill hole samples.\nUse the tools covered in previous chapters to localize regions of interest in the mineral deposit.\n\nAlthough the mathematical model presented here is simple, it is what most mining companies do. There is opportunity to improve these types of estimates with more sophisticated geospatial data science pipelines.\n\n\n\n\nAitchison, J. 1982. “The Statistical Analysis of Compositional Data.” Journal of the Royal Statistical Society. Series B (Methodological) 44 (2): 139–77. http://www.jstor.org/stable/2345821.\n\n\nFriedman, Jerome H. 1987. “Exploratory Projection Pursuit.” Journal of the American Statistical Association 82 (397): 249–66. http://www.jstor.org/stable/2289161.\n\n\nHoffimann, Júlio, José Augusto, Lucas Resende, Marlon Mathias, Douglas Mazzinghy, Matheus Bianchetti, Mônica Mendes, et al. 2022a. “GeoMet Dataset.” Zenodo. https://doi.org/10.5281/zenodo.7051975.\n\n\nHoffimann, Júlio, José Augusto, Lucas Resende, Marlon Mathias, Douglas Mazzinghy, Matheus Bianchetti, Mônica Mendes, et al. 2022b. “Modeling Geospatial Uncertainty of Geometallurgical Variables with Bayesian Models and Hilbertkriging.” Mathematical Geosciences 54 (7): 1227–53. https://doi.org/10.1007/s11004-022-10013-1."
  },
  {
    "objectID": "13-agriculture.html#coming-soon",
    "href": "13-agriculture.html#coming-soon",
    "title": "13  Agricultural fields 🚧",
    "section": "13.1 Coming soon…",
    "text": "13.1 Coming soon…"
  },
  {
    "objectID": "14-energy.html#coming-soon",
    "href": "14-energy.html#coming-soon",
    "title": "14  Petroleum reservoirs 🚧",
    "section": "14.1 Coming soon…",
    "text": "14.1 Coming soon…"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Aitchison, J. 1982. “The Statistical Analysis of Compositional\nData.” Journal of the Royal Statistical Society. Series B\n(Methodological) 44 (2): 139–77. http://www.jstor.org/stable/2345821.\n\n\nBezanson, Jeff, Alan Edelman, Stefan Karpinski, and Viral B Shah. 2017.\n“Julia: A Fresh Approach to Numerical Computing.” SIAM\nReview 59 (1): 65–98. https://doi.org/10.1137/141000671.\n\n\nBouchet-Valat, Milan, and Bogumił Kamiński. 2023. “DataFrames.jl:\nFlexible and Fast Tabular Data in Julia.” Journal of\nStatistical Software 107 (4): 1–32. https://doi.org/10.18637/jss.v107.i04.\n\n\nBreloff, Tom. 2023. “Plots.jl.” Zenodo. https://doi.org/10.5281/zenodo.8183938.\n\n\nChilès, Jean-Paul, and Pierre Delfiner. 2012. Geostatistics.\nWiley. https://doi.org/10.1002/9781118136188.\n\n\nCorreia, M.., J.. Hohendorff, A. T. Gaspar, and D.. Schiozer. 2015.\nUNISIM-II-D: Benchmark Case Proposal Based on a\nCarbonate Reservoir. Vol. Day 3 Fri, November 20, 2015. SPE\nLatin America and Caribbean Petroleum Engineering Conference. https://doi.org/10.2118/177140-MS.\n\n\nCressie, Noel, and Douglas M. Hawkins. 1980. “Robust Estimation of\nthe Variogram: i.” Journal of the International Association\nfor Mathematical Geology 12 (2): 115–25. https://doi.org/10.1007/bf01035243.\n\n\nDanisch, Simon, and Julius Krumbiegel. 2021. “Makie.jl: Flexible\nHigh-Performance Data Visualization for Julia.” Journal of\nOpen Source Software 6 (65): 3349. https://doi.org/10.21105/joss.03349.\n\n\nFloriani, L. De, and A. Hui. 2007. “Shape\nRepresentations Based on Simplicial and Cell Complexes.”\nIn Eurographics 2007 - State of the Art Reports, edited by\nDieter Schmalstieg and Jiri Bittner. The Eurographics Association. https://doi.org/10.2312/egst.20071055.\n\n\nFriedman, Jerome H. 1987. “Exploratory Projection Pursuit.”\nJournal of the American Statistical Association 82 (397):\n249–66. http://www.jstor.org/stable/2289161.\n\n\nHoffimann, Júlio, José Augusto, Lucas Resende, Marlon Mathias, Douglas\nMazzinghy, Matheus Bianchetti, Mônica Mendes, et al. 2022a.\n“GeoMet Dataset.” Zenodo. https://doi.org/10.5281/zenodo.7051975.\n\n\nHoffimann, Júlio, José Augusto, Lucas Resende, Marlon Mathias, Douglas\nMazzinghy, Matheus Bianchetti, Mônica Mendes, et al. 2022b.\n“Modeling Geospatial Uncertainty of Geometallurgical Variables\nwith Bayesian Models and Hilbertkriging.”\nMathematical Geosciences 54 (7): 1227–53. https://doi.org/10.1007/s11004-022-10013-1.\n\n\nHoffimann, Júlio, and Bianca Zadrozny. 2019. “Efficient\nVariography with Partition Variograms.” Computers &\nGeosciences 131: 52–59. https://doi.org/https://doi.org/10.1016/j.cageo.2019.06.013.\n\n\nHoffimann, Júlio, Maciel Zortea, Breno de Carvalho, and Bianca Zadrozny.\n2021. “Geostatistical Learning: Challenges and\nOpportunities.” Frontiers in Applied Mathematics and\nStatistics 7. https://doi.org/10.3389/fams.2021.689393.\n\n\nKoolen, Twan, Yuto Horikawa, Andy Ferris, Claire Foster, awbsmith,\nryanelandt, Jan Weidner, et al. 2023. “JuliaGeometry/Rotations.jl:\nV1.6.0.” Zenodo. https://doi.org/10.5281/zenodo.8366010.\n\n\nLauwens, Ben, and Allen Downey. 2018. Think Julia: How to Think Like\na Computer Scientist. https://benlauwens.github.io/ThinkJulia.jl/latest/book.html.\n\n\nLin, Dahua, David Widmann, Simon Byrne, John Myles White, Andreas Noack,\nMathieu Besançon, Douglas Bates, et al. 2023.\n“JuliaStats/Distributions.jl: V0.25.100.” Zenodo. https://doi.org/10.5281/zenodo.8224988.\n\n\nMariethoz, Gregoire, and Jef Caers. 2014. Multiple-Point\nGeostatistics: Stochastic Modeling with Training Images. https://www.wiley.com/en-gb/Multiple+point+Geostatistics%3A+Stochastic+Modeling+with+Training+Images-p-9781118662755.\n\n\nMatheron, Georges François Paul Marie. 1971. The Theory of\nRegionalized Variables and Its Applications.\n\n\nMyers, Donald E. 1992. “Kriging, Cokriging, Radial Basis Functions\nand the Role of Positive Definiteness.” Computers &\nMathematics with Applications 24 (12): 139–48. https://doi.org/https://doi.org/10.1016/0898-1221(92)90176-I.\n\n\nOlea, Ricardo A. 1999. Geostatistics for Engineers and Earth\nScientists. Springer US. https://doi.org/10.1007/978-1-4615-5001-3.\n\n\nQuinn, Jacob, Bogumił Kamiński, David Anthoff, Milan Bouchet-Valat,\nTamas K. Papp, Takafumi Arakaki, Rafael Schouten, et al. 2023.\n“JuliaData/Tables.jl: V1.10.1.” Zenodo. https://doi.org/10.5281/zenodo.7730968.\n\n\nShepard, Donald S. 1968. “A Two-Dimensional Interpolation Function\nfor Irregularly-Spaced Data.” Proceedings of the 1968 23rd\nACM National Conference. https://api.semanticscholar.org/CorpusID:42723195.\n\n\nThompson, William. 2023. “PairPlots.jl\nBeautiful and Flexible Visualizations of High Dimensional Data.”\nhttps://sefffal.github.io/PairPlots.jl/dev.\n\n\nWebster, Richard, and Margaret A. Oliver. 2007. Geostatistics for\nEnvironmental Scientists. Wiley. https://doi.org/10.1002/9780470517277.\n\n\nWickham, Hadley. 2011. “The Split-Apply-Combine Strategy for Data\nAnalysis.” Journal of Statistical Software 40 (1): 1–29.\nhttps://doi.org/10.18637/jss.v040.i01."
  }
]